{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b127ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b1e169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:\\\\Ayesha\\\\IBA Data Science\\\\Semester 3\\\\ML II\\\\pd_speech_features\\\\pd_speech_features.csv\",header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a1b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b5f310c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>PPE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>numPulses</th>\n",
       "      <th>numPeriodsPulses</th>\n",
       "      <th>meanPeriodPulses</th>\n",
       "      <th>stdDevPeriodPulses</th>\n",
       "      <th>locPctJitter</th>\n",
       "      <th>locAbsJitter</th>\n",
       "      <th>...</th>\n",
       "      <th>tqwt_kurtosisValue_dec_28</th>\n",
       "      <th>tqwt_kurtosisValue_dec_29</th>\n",
       "      <th>tqwt_kurtosisValue_dec_30</th>\n",
       "      <th>tqwt_kurtosisValue_dec_31</th>\n",
       "      <th>tqwt_kurtosisValue_dec_32</th>\n",
       "      <th>tqwt_kurtosisValue_dec_33</th>\n",
       "      <th>tqwt_kurtosisValue_dec_34</th>\n",
       "      <th>tqwt_kurtosisValue_dec_35</th>\n",
       "      <th>tqwt_kurtosisValue_dec_36</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.85247</td>\n",
       "      <td>0.71826</td>\n",
       "      <td>0.57227</td>\n",
       "      <td>240</td>\n",
       "      <td>239</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.00218</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5620</td>\n",
       "      <td>2.6445</td>\n",
       "      <td>3.8686</td>\n",
       "      <td>4.2105</td>\n",
       "      <td>5.1221</td>\n",
       "      <td>4.4625</td>\n",
       "      <td>2.6202</td>\n",
       "      <td>3.0004</td>\n",
       "      <td>18.9405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76686</td>\n",
       "      <td>0.69481</td>\n",
       "      <td>0.53966</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.00195</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5589</td>\n",
       "      <td>3.6107</td>\n",
       "      <td>23.5155</td>\n",
       "      <td>14.1962</td>\n",
       "      <td>11.0261</td>\n",
       "      <td>9.5082</td>\n",
       "      <td>6.5245</td>\n",
       "      <td>6.3431</td>\n",
       "      <td>45.1780</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.85083</td>\n",
       "      <td>0.67604</td>\n",
       "      <td>0.58982</td>\n",
       "      <td>232</td>\n",
       "      <td>231</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.00176</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5643</td>\n",
       "      <td>2.3308</td>\n",
       "      <td>9.4959</td>\n",
       "      <td>10.7458</td>\n",
       "      <td>11.0177</td>\n",
       "      <td>4.8066</td>\n",
       "      <td>2.9199</td>\n",
       "      <td>3.1495</td>\n",
       "      <td>4.7666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 754 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender      PPE      DFA     RPDE  numPulses  numPeriodsPulses  \\\n",
       "0       1  0.85247  0.71826  0.57227        240               239   \n",
       "1       1  0.76686  0.69481  0.53966        234               233   \n",
       "2       1  0.85083  0.67604  0.58982        232               231   \n",
       "\n",
       "   meanPeriodPulses  stdDevPeriodPulses  locPctJitter  locAbsJitter  ...  \\\n",
       "0          0.008064            0.000087       0.00218      0.000018  ...   \n",
       "1          0.008258            0.000073       0.00195      0.000016  ...   \n",
       "2          0.008340            0.000060       0.00176      0.000015  ...   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_28  tqwt_kurtosisValue_dec_29  \\\n",
       "0                     1.5620                     2.6445   \n",
       "1                     1.5589                     3.6107   \n",
       "2                     1.5643                     2.3308   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_30  tqwt_kurtosisValue_dec_31  \\\n",
       "0                     3.8686                     4.2105   \n",
       "1                    23.5155                    14.1962   \n",
       "2                     9.4959                    10.7458   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_32  tqwt_kurtosisValue_dec_33  \\\n",
       "0                     5.1221                     4.4625   \n",
       "1                    11.0261                     9.5082   \n",
       "2                    11.0177                     4.8066   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_34  tqwt_kurtosisValue_dec_35  \\\n",
       "0                     2.6202                     3.0004   \n",
       "1                     6.5245                     6.3431   \n",
       "2                     2.9199                     3.1495   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_36  class  \n",
       "0                    18.9405      1  \n",
       "1                    45.1780      1  \n",
       "2                     4.7666      1  \n",
       "\n",
       "[3 rows x 754 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f059544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost, RF, SVM and LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7e822b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop('class',axis=1)\n",
    "Y=data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b06a459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validationmetrics(model, testX, testY, verbose=True):  \n",
    "    global predictions\n",
    "    \n",
    "    predictions = model.predict(testX)\n",
    "    \n",
    "    if model.__class__.__module__.startswith('lightgbm'):\n",
    "        for i in range(0, predictions.shape[0]):\n",
    "            predictions[i]= 1 if predictions[i] >= 0.5 else 0\n",
    "    \n",
    "    #Accuracy\n",
    "    accuracy = accuracy_score(testY, predictions)*100\n",
    "    \n",
    "    result1 = classification_report(testY, predictions)\n",
    "    print(\"Classification Report:\",)\n",
    "    print (result1)\n",
    "    \n",
    "    #Precision\n",
    "    precision = precision_score(testY, predictions, pos_label=1, labels=[0,1])*100\n",
    "    \n",
    "    #Recall\n",
    "    recall = recall_score(testY, predictions,pos_label=1,labels=[0,1])*100\n",
    "    \n",
    "    #get FPR (specificity) and TPR (sensitivity)\n",
    "    fpr , tpr, _ = roc_curve(testY, predictions)\n",
    "    \n",
    "    #AUC\n",
    "    auc_val = auc(fpr, tpr)\n",
    "    \n",
    "    #F-Score\n",
    "    f_score = f1_score(testY, predictions)\n",
    "    \n",
    "\n",
    "    if verbose:\n",
    "        print(\"Prediction Vector: \\n\", predictions)\n",
    "        print(\"\\n Accuracy: \\n\", accuracy)\n",
    "        print(\"\\n Precision of event Happening: \\n\", precision)\n",
    "        print(\"\\n Recall of event Happening: \\n\", recall)\n",
    "        print(\"\\n AUC: \\n\",auc_val)\n",
    "        print(\"\\n F-Score:\\n\", f_score)\n",
    "        #confusion Matrix\n",
    "        print(\"\\n Confusion Matrix: \\n\", confusion_matrix(testY, predictions,labels=[0,1]))\n",
    "    \n",
    "    res_map = {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"auc_val\": auc_val,\n",
    "                \"f_score\": f_score,\n",
    "                \"model_obj\": model\n",
    "              }\n",
    "    \n",
    "    return res_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f38a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogReg(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf  = LogisticRegression()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def SVM(trainX, testX, trainY, testY, svmtype=\"SVC\", verbose=True, clf=None):\n",
    "    # for one vs all\n",
    "    if not clf:\n",
    "        if svmtype == \"Linear\":\n",
    "            clf = svm.LinearSVC()\n",
    "        else:\n",
    "            clf = svm.SVC()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def RandomForest(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf  = RandomForestClassifier()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def XgBoost(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf = XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "    clf.fit(trainX,trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81863842",
   "metadata": {},
   "source": [
    "# 1- Random Forest Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f23601a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "std_delta_delta_log_energy     0.016349\n",
       "tqwt_maxValue_dec_13           0.012700\n",
       "std_delta_log_energy           0.012587\n",
       "tqwt_TKEO_std_dec_12           0.011700\n",
       "tqwt_entropy_shannon_dec_13    0.010168\n",
       "                                 ...   \n",
       "tqwt_meanValue_dec_2           0.000000\n",
       "tqwt_meanValue_dec_1           0.000000\n",
       "tqwt_meanValue_dec_27          0.000000\n",
       "tqwt_meanValue_dec_28          0.000000\n",
       "gender                         0.000000\n",
       "Length: 753, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "model.fit(X,Y)\n",
    "pd.Series(model.feature_importances_,index=X.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77b873b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['apq11Shimmer', 'std_Log_energy', 'std_delta_log_energy',\n",
      "       'std_delta_delta_log_energy', 'std_9th_delta_delta'],\n",
      "      dtype='object')\n",
      "Logistic Regression From Random Forest Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.79      1.00      0.88       198\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.40      0.50      0.44       250\n",
      "weighted avg       0.63      0.79      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 79.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.2\n",
      "\n",
      " Recall of event Happening: \n",
      " 100.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.8839285714285714\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  0  52]\n",
      " [  0 198]]\n",
      "SVM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.79      0.99      0.88       198\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.40      0.50      0.44       250\n",
      "weighted avg       0.63      0.79      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.11646586345381\n",
      "\n",
      " Recall of event Happening: \n",
      " 99.4949494949495\n",
      "\n",
      " AUC: \n",
      " 0.49747474747474746\n",
      "\n",
      " F-Score:\n",
      " 0.8814317673378076\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  0  52]\n",
      " [  1 197]]\n",
      "RM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.38      0.43        52\n",
      "           1       0.85      0.89      0.87       198\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.67      0.64      0.65       250\n",
      "weighted avg       0.77      0.79      0.78       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 84.688995215311\n",
      "\n",
      " Recall of event Happening: \n",
      " 89.39393939393939\n",
      "\n",
      " AUC: \n",
      " 0.6392773892773893\n",
      "\n",
      " F-Score:\n",
      " 0.8697788697788698\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 20  32]\n",
      " [ 21 177]]\n",
      "Xgboost From Random Forest Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:10:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.52      0.47        52\n",
      "           1       0.87      0.82      0.84       198\n",
      "\n",
      "    accuracy                           0.76       250\n",
      "   macro avg       0.65      0.67      0.66       250\n",
      "weighted avg       0.78      0.76      0.76       250\n",
      "\n",
      "Prediction Vector: \n",
      " [0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 0 1\n",
      " 0 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 0 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1]\n",
      "\n",
      " Accuracy: \n",
      " 75.6\n",
      "\n",
      " Precision of event Happening: \n",
      " 86.63101604278076\n",
      "\n",
      " Recall of event Happening: \n",
      " 81.81818181818183\n",
      "\n",
      " AUC: \n",
      " 0.6687062937062938\n",
      "\n",
      " F-Score:\n",
      " 0.8415584415584416\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 27  25]\n",
      " [ 36 162]]\n",
      "Index(['apq11Shimmer', 'mean_MFCC_2nd_coef', 'std_Log_energy',\n",
      "       'std_delta_log_energy', 'std_delta_delta_log_energy',\n",
      "       'std_8th_delta_delta', 'tqwt_TKEO_mean_dec_12', 'tqwt_TKEO_std_dec_12',\n",
      "       'tqwt_TKEO_std_dec_13', 'tqwt_maxValue_dec_11'],\n",
      "      dtype='object')\n",
      "Logistic Regression From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55        52\n",
      "           1       0.87      0.91      0.89       198\n",
      "\n",
      "    accuracy                           0.83       250\n",
      "   macro avg       0.74      0.71      0.72       250\n",
      "weighted avg       0.82      0.83      0.82       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1\n",
      " 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 1 1\n",
      " 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 82.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 87.43961352657004\n",
      "\n",
      " Recall of event Happening: \n",
      " 91.41414141414141\n",
      "\n",
      " AUC: \n",
      " 0.7070707070707071\n",
      "\n",
      " F-Score:\n",
      " 0.8938271604938272\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 26  26]\n",
      " [ 17 181]]\n",
      "SVM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.31      0.41        52\n",
      "           1       0.84      0.95      0.89       198\n",
      "\n",
      "    accuracy                           0.82       250\n",
      "   macro avg       0.73      0.63      0.65       250\n",
      "weighted avg       0.79      0.82      0.79       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1\n",
      " 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 81.6\n",
      "\n",
      " Precision of event Happening: \n",
      " 83.92857142857143\n",
      "\n",
      " Recall of event Happening: \n",
      " 94.94949494949495\n",
      "\n",
      " AUC: \n",
      " 0.6285936285936286\n",
      "\n",
      " F-Score:\n",
      " 0.8909952606635071\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 16  36]\n",
      " [ 10 188]]\n",
      "RM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57        52\n",
      "           1       0.89      0.89      0.89       198\n",
      "\n",
      "    accuracy                           0.82       250\n",
      "   macro avg       0.73      0.73      0.73       250\n",
      "weighted avg       0.82      0.82      0.82       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1\n",
      " 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0\n",
      " 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 82.39999999999999\n",
      "\n",
      " Precision of event Happening: \n",
      " 88.5\n",
      "\n",
      " Recall of event Happening: \n",
      " 89.39393939393939\n",
      "\n",
      " AUC: \n",
      " 0.7258158508158509\n",
      "\n",
      " F-Score:\n",
      " 0.8894472361809046\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 29  23]\n",
      " [ 21 177]]\n",
      "Xgboost From Random Forest Selection\n",
      "[12:10:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.54      0.60        52\n",
      "           1       0.89      0.93      0.91       198\n",
      "\n",
      "    accuracy                           0.85       250\n",
      "   macro avg       0.78      0.74      0.76       250\n",
      "weighted avg       0.84      0.85      0.85       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 85.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 88.51674641148325\n",
      "\n",
      " Recall of event Happening: \n",
      " 93.43434343434343\n",
      "\n",
      " AUC: \n",
      " 0.7364024864024863\n",
      "\n",
      " F-Score:\n",
      " 0.9090909090909092\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 28  24]\n",
      " [ 13 185]]\n",
      "Index(['minIntensity', 'mean_MFCC_2nd_coef', 'std_Log_energy',\n",
      "       'std_delta_log_energy', 'std_delta_delta_log_energy',\n",
      "       'std_6th_delta_delta', 'std_7th_delta_delta', 'tqwt_energy_dec_26',\n",
      "       'tqwt_energy_dec_27', 'tqwt_entropy_log_dec_12',\n",
      "       'tqwt_entropy_log_dec_35', 'tqwt_TKEO_std_dec_12',\n",
      "       'tqwt_stdValue_dec_11', 'tqwt_minValue_dec_12', 'tqwt_maxValue_dec_12'],\n",
      "      dtype='object')\n",
      "Logistic Regression From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.27      0.37        52\n",
      "           1       0.83      0.95      0.89       198\n",
      "\n",
      "    accuracy                           0.81       250\n",
      "   macro avg       0.72      0.61      0.63       250\n",
      "weighted avg       0.79      0.81      0.78       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 81.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 83.25991189427313\n",
      "\n",
      " Recall of event Happening: \n",
      " 95.45454545454545\n",
      "\n",
      " AUC: \n",
      " 0.6118881118881119\n",
      "\n",
      " F-Score:\n",
      " 0.8894117647058823\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 14  38]\n",
      " [  9 189]]\n",
      "SVM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.79      0.99      0.88       198\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.40      0.49      0.44       250\n",
      "weighted avg       0.63      0.78      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.03225806451613\n",
      "\n",
      " Recall of event Happening: \n",
      " 98.98989898989899\n",
      "\n",
      " AUC: \n",
      " 0.494949494949495\n",
      "\n",
      " F-Score:\n",
      " 0.8789237668161436\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  0  52]\n",
      " [  2 196]]\n",
      "RM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64        52\n",
      "           1       0.90      0.91      0.91       198\n",
      "\n",
      "    accuracy                           0.85       250\n",
      "   macro avg       0.78      0.77      0.77       250\n",
      "weighted avg       0.85      0.85      0.85       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0\n",
      " 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 85.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 90.45226130653266\n",
      "\n",
      " Recall of event Happening: \n",
      " 90.9090909090909\n",
      "\n",
      " AUC: \n",
      " 0.7718531468531468\n",
      "\n",
      " F-Score:\n",
      " 0.906801007556675\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 33  19]\n",
      " [ 18 180]]\n",
      "Xgboost From Random Forest Selection\n",
      "[12:10:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.54      0.57        52\n",
      "           1       0.88      0.90      0.89       198\n",
      "\n",
      "    accuracy                           0.83       250\n",
      "   macro avg       0.74      0.72      0.73       250\n",
      "weighted avg       0.82      0.83      0.82       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 82.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 88.17733990147784\n",
      "\n",
      " Recall of event Happening: \n",
      " 90.40404040404042\n",
      "\n",
      " AUC: \n",
      " 0.7212509712509712\n",
      "\n",
      " F-Score:\n",
      " 0.8927680798004988\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 28  24]\n",
      " [ 19 179]]\n",
      "Index(['apq11Shimmer', 'minIntensity', 'GQ_std_cycle_open',\n",
      "       'mean_MFCC_2nd_coef', 'std_Log_energy', 'std_delta_log_energy',\n",
      "       'std_delta_delta_log_energy', 'std_7th_delta_delta',\n",
      "       'std_9th_delta_delta', 'app_TKEO_std_8_coef', 'tqwt_energy_dec_12',\n",
      "       'tqwt_entropy_shannon_dec_12', 'tqwt_entropy_shannon_dec_17',\n",
      "       'tqwt_entropy_log_dec_12', 'tqwt_entropy_log_dec_35',\n",
      "       'tqwt_TKEO_mean_dec_12', 'tqwt_TKEO_std_dec_11', 'tqwt_TKEO_std_dec_12',\n",
      "       'tqwt_stdValue_dec_12', 'tqwt_stdValue_dec_36'],\n",
      "      dtype='object')\n",
      "Logistic Regression From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.33      0.39        52\n",
      "           1       0.84      0.90      0.87       198\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.65      0.62      0.63       250\n",
      "weighted avg       0.76      0.78      0.77       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0\n",
      " 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 83.64485981308411\n",
      "\n",
      " Recall of event Happening: \n",
      " 90.40404040404042\n",
      "\n",
      " AUC: \n",
      " 0.6154817404817405\n",
      "\n",
      " F-Score:\n",
      " 0.8689320388349515\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 17  35]\n",
      " [ 19 179]]\n",
      "SVM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.12      0.18        52\n",
      "           1       0.80      0.95      0.87       198\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.60      0.53      0.53       250\n",
      "weighted avg       0.72      0.78      0.73       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.0\n",
      "\n",
      " Precision of event Happening: \n",
      " 80.42553191489363\n",
      "\n",
      " Recall of event Happening: \n",
      " 95.45454545454545\n",
      "\n",
      " AUC: \n",
      " 0.534965034965035\n",
      "\n",
      " F-Score:\n",
      " 0.8729792147806006\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  6  46]\n",
      " [  9 189]]\n",
      "RM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.60      0.63        52\n",
      "           1       0.90      0.92      0.91       198\n",
      "\n",
      "    accuracy                           0.85       250\n",
      "   macro avg       0.78      0.76      0.77       250\n",
      "weighted avg       0.85      0.85      0.85       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 85.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 89.65517241379311\n",
      "\n",
      " Recall of event Happening: \n",
      " 91.91919191919192\n",
      "\n",
      " AUC: \n",
      " 0.7576728826728827\n",
      "\n",
      " F-Score:\n",
      " 0.9077306733167083\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 31  21]\n",
      " [ 16 182]]\n",
      "Xgboost From Random Forest Selection\n",
      "[12:10:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.58      0.62        52\n",
      "           1       0.89      0.93      0.91       198\n",
      "\n",
      "    accuracy                           0.86       250\n",
      "   macro avg       0.79      0.75      0.77       250\n",
      "weighted avg       0.85      0.86      0.85       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1\n",
      " 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1\n",
      " 0 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0\n",
      " 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 85.6\n",
      "\n",
      " Precision of event Happening: \n",
      " 89.32038834951457\n",
      "\n",
      " Recall of event Happening: \n",
      " 92.92929292929293\n",
      "\n",
      " AUC: \n",
      " 0.7531080031080031\n",
      "\n",
      " F-Score:\n",
      " 0.9108910891089108\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 30  22]\n",
      " [ 14 184]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_features(X_train, y_train, X_test,n):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectFromModel(RandomForestClassifier(n_estimators=100),threshold=-np.inf, max_features=n)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    selected_feat= X_train.columns[(fs.get_support())]\n",
    "    print(selected_feat)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    " \n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(5,25,5):\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test,n)\n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From Random Forest Selection\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From Random Forest Selection\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From Random Forest Selection\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From Random Forest Selection\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ae0cd4",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "- Logistic Regression with Random Forest selection performs well on 10 features. the accuracy is 82.8, Precision 87 and recall 91.\n",
    "- SVM with with Random Forest selection performs well on 10 features as accuracy is 81, precision is 83, recall is 94.\n",
    "- RF with random forest selection performs very well on 15 features as accuracy is 85.2, precision is 90 and recall is 90.9.\n",
    "- Xgboost with random forest selection performs well on 10 features as accuracy is 85.2, precision is 88 and recall is 93.\n",
    "\n",
    "\n",
    "We concluded that LR, SVM, Xgboost with 10 features works really better with Random Forest selection as it is useful in minimizing the features. \n",
    "So if we want to select one model from random forest selection we will choose Xgboost (with 10 features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b9e5e2",
   "metadata": {},
   "source": [
    "# 2- XGBOOST SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be55f258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:13:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tqwt_entropy_shannon_dec_13    0.045603\n",
       "tqwt_TKEO_std_dec_12           0.035513\n",
       "std_delta_delta_log_energy     0.028034\n",
       "app_entropy_shannon_1_coef     0.020530\n",
       "tqwt_medianValue_dec_31        0.019773\n",
       "                                 ...   \n",
       "det_TKEO_std_6_coef            0.000000\n",
       "tqwt_entropy_log_dec_10        0.000000\n",
       "tqwt_entropy_log_dec_9         0.000000\n",
       "tqwt_entropy_log_dec_8         0.000000\n",
       "gender                         0.000000\n",
       "Length: 753, dtype: float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= XGBClassifier(n_estimators=100,random_state=0)\n",
    "model.fit(X,Y)\n",
    "pd.Series(model.feature_importances_,index=X.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b27e896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:15:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Index(['std_delta_delta_log_energy', 'std_10th_delta_delta',\n",
      "       'det_TKEO_mean_8_coef', 'app_LT_TKEO_mean_1_coef',\n",
      "       'tqwt_TKEO_std_dec_12'],\n",
      "      dtype='object')\n",
      "Logistic Regression From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      1.00      0.34        52\n",
      "           1       0.00      0.00      0.00       198\n",
      "\n",
      "    accuracy                           0.21       250\n",
      "   macro avg       0.10      0.50      0.17       250\n",
      "weighted avg       0.04      0.21      0.07       250\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 20.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 52   0]\n",
      " [198   0]]\n",
      "SVM From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.02      0.04        52\n",
      "           1       0.79      0.98      0.88       198\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.52      0.50      0.46       250\n",
      "weighted avg       0.68      0.78      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.26829268292683\n",
      "\n",
      " Recall of event Happening: \n",
      " 98.48484848484848\n",
      "\n",
      " AUC: \n",
      " 0.502039627039627\n",
      "\n",
      " F-Score:\n",
      " 0.8783783783783784\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  1  51]\n",
      " [  3 195]]\n",
      "RM From XGboost Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.58      0.61        52\n",
      "           1       0.89      0.92      0.91       198\n",
      "\n",
      "    accuracy                           0.85       250\n",
      "   macro avg       0.77      0.75      0.76       250\n",
      "weighted avg       0.84      0.85      0.84       250\n",
      "\n",
      "Prediction Vector: \n",
      " [0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 84.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 89.2156862745098\n",
      "\n",
      " Recall of event Happening: \n",
      " 91.91919191919192\n",
      "\n",
      " AUC: \n",
      " 0.748057498057498\n",
      "\n",
      " F-Score:\n",
      " 0.9054726368159205\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 30  22]\n",
      " [ 16 182]]\n",
      "Xgboost From XGboost Selection\n",
      "[12:15:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56        52\n",
      "           1       0.88      0.90      0.89       198\n",
      "\n",
      "    accuracy                           0.82       250\n",
      "   macro avg       0.73      0.72      0.72       250\n",
      "weighted avg       0.82      0.82      0.82       250\n",
      "\n",
      "Prediction Vector: \n",
      " [0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1\n",
      " 0 1 1 1 0 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1\n",
      " 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 82.39999999999999\n",
      "\n",
      " Precision of event Happening: \n",
      " 88.11881188118812\n",
      "\n",
      " Recall of event Happening: \n",
      " 89.8989898989899\n",
      "\n",
      " AUC: \n",
      " 0.7187257187257188\n",
      "\n",
      " F-Score:\n",
      " 0.89\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 28  24]\n",
      " [ 20 178]]\n",
      "[12:15:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['VFER_std', 'std_delta_delta_log_energy', 'std_10th_delta_delta',\n",
      "       'det_TKEO_mean_8_coef', 'app_LT_TKEO_mean_1_coef',\n",
      "       'tqwt_TKEO_mean_dec_21', 'tqwt_TKEO_std_dec_12',\n",
      "       'tqwt_meanValue_dec_36', 'tqwt_minValue_dec_7', 'tqwt_maxValue_dec_11'],\n",
      "      dtype='object')\n",
      "Logistic Regression From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      1.00      0.34        52\n",
      "           1       0.00      0.00      0.00       198\n",
      "\n",
      "    accuracy                           0.21       250\n",
      "   macro avg       0.10      0.50      0.17       250\n",
      "weighted avg       0.04      0.21      0.07       250\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 20.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 52   0]\n",
      " [198   0]]\n",
      "SVM From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.02      0.04        52\n",
      "           1       0.79      0.98      0.88       198\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.52      0.50      0.46       250\n",
      "weighted avg       0.68      0.78      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.26829268292683\n",
      "\n",
      " Recall of event Happening: \n",
      " 98.48484848484848\n",
      "\n",
      " AUC: \n",
      " 0.502039627039627\n",
      "\n",
      " F-Score:\n",
      " 0.8783783783783784\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  1  51]\n",
      " [  3 195]]\n",
      "RM From XGboost Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.56      0.64        52\n",
      "           1       0.89      0.95      0.92       198\n",
      "\n",
      "    accuracy                           0.87       250\n",
      "   macro avg       0.82      0.75      0.78       250\n",
      "weighted avg       0.86      0.87      0.86       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 86.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 89.0995260663507\n",
      "\n",
      " Recall of event Happening: \n",
      " 94.94949494949495\n",
      "\n",
      " AUC: \n",
      " 0.7535936285936287\n",
      "\n",
      " F-Score:\n",
      " 0.9193154034229829\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 29  23]\n",
      " [ 10 188]]\n",
      "Xgboost From XGboost Selection\n",
      "[12:15:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.58      0.61        52\n",
      "           1       0.89      0.91      0.90       198\n",
      "\n",
      "    accuracy                           0.84       250\n",
      "   macro avg       0.76      0.75      0.75       250\n",
      "weighted avg       0.84      0.84      0.84       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0\n",
      " 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 84.39999999999999\n",
      "\n",
      " Precision of event Happening: \n",
      " 89.16256157635468\n",
      "\n",
      " Recall of event Happening: \n",
      " 91.41414141414141\n",
      "\n",
      " AUC: \n",
      " 0.7455322455322455\n",
      "\n",
      " F-Score:\n",
      " 0.9027431421446384\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 30  22]\n",
      " [ 17 181]]\n",
      "[12:15:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['VFER_std', 'std_MFCC_1st_coef', 'std_MFCC_11th_coef',\n",
      "       'std_delta_delta_log_energy', 'std_10th_delta_delta',\n",
      "       'det_TKEO_mean_8_coef', 'Ed2_1_coef', 'app_LT_TKEO_mean_1_coef',\n",
      "       'tqwt_entropy_shannon_dec_19', 'tqwt_TKEO_mean_dec_21',\n",
      "       'tqwt_TKEO_std_dec_12', 'tqwt_meanValue_dec_36', 'tqwt_stdValue_dec_17',\n",
      "       'tqwt_minValue_dec_7', 'tqwt_maxValue_dec_11'],\n",
      "      dtype='object')\n",
      "Logistic Regression From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.79      0.97      0.87       198\n",
      "\n",
      "    accuracy                           0.77       250\n",
      "   macro avg       0.39      0.48      0.43       250\n",
      "weighted avg       0.62      0.77      0.69       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 76.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 78.68852459016394\n",
      "\n",
      " Recall of event Happening: \n",
      " 96.96969696969697\n",
      "\n",
      " AUC: \n",
      " 0.48484848484848486\n",
      "\n",
      " F-Score:\n",
      " 0.8687782805429864\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  0  52]\n",
      " [  6 192]]\n",
      "SVM From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.02      0.04        52\n",
      "           1       0.79      0.98      0.88       198\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.52      0.50      0.46       250\n",
      "weighted avg       0.68      0.78      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.26829268292683\n",
      "\n",
      " Recall of event Happening: \n",
      " 98.48484848484848\n",
      "\n",
      " AUC: \n",
      " 0.502039627039627\n",
      "\n",
      " F-Score:\n",
      " 0.8783783783783784\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  1  51]\n",
      " [  3 195]]\n",
      "RM From XGboost Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.58      0.65        52\n",
      "           1       0.90      0.95      0.92       198\n",
      "\n",
      "    accuracy                           0.87       250\n",
      "   macro avg       0.82      0.76      0.79       250\n",
      "weighted avg       0.87      0.87      0.87       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1\n",
      " 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 87.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 89.52380952380953\n",
      "\n",
      " Recall of event Happening: \n",
      " 94.94949494949495\n",
      "\n",
      " AUC: \n",
      " 0.7632090132090132\n",
      "\n",
      " F-Score:\n",
      " 0.9215686274509803\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 30  22]\n",
      " [ 10 188]]\n",
      "Xgboost From XGboost Selection\n",
      "[12:15:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.56      0.58        52\n",
      "           1       0.89      0.90      0.90       198\n",
      "\n",
      "    accuracy                           0.83       250\n",
      "   macro avg       0.75      0.73      0.74       250\n",
      "weighted avg       0.83      0.83      0.83       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 0\n",
      " 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 83.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 88.61386138613861\n",
      "\n",
      " Recall of event Happening: \n",
      " 90.40404040404042\n",
      "\n",
      " AUC: \n",
      " 0.7308663558663558\n",
      "\n",
      " F-Score:\n",
      " 0.895\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 29  23]\n",
      " [ 19 179]]\n",
      "[12:15:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['b2', 'VFER_std', 'std_MFCC_1st_coef', 'std_MFCC_11th_coef',\n",
      "       'std_delta_delta_log_energy', 'std_10th_delta_delta',\n",
      "       'det_TKEO_mean_8_coef', 'Ed2_1_coef', 'app_LT_TKEO_mean_1_coef',\n",
      "       'tqwt_energy_dec_14', 'tqwt_energy_dec_33',\n",
      "       'tqwt_entropy_shannon_dec_19', 'tqwt_TKEO_mean_dec_21',\n",
      "       'tqwt_TKEO_std_dec_12', 'tqwt_meanValue_dec_36', 'tqwt_stdValue_dec_17',\n",
      "       'tqwt_minValue_dec_7', 'tqwt_maxValue_dec_11', 'tqwt_maxValue_dec_25',\n",
      "       'tqwt_kurtosisValue_dec_22'],\n",
      "      dtype='object')\n",
      "Logistic Regression From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.79      0.99      0.88       198\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.40      0.49      0.44       250\n",
      "weighted avg       0.63      0.78      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.03225806451613\n",
      "\n",
      " Recall of event Happening: \n",
      " 98.98989898989899\n",
      "\n",
      " AUC: \n",
      " 0.494949494949495\n",
      "\n",
      " F-Score:\n",
      " 0.8789237668161436\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  0  52]\n",
      " [  2 196]]\n",
      "SVM From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.02      0.04        52\n",
      "           1       0.79      0.98      0.88       198\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.52      0.50      0.46       250\n",
      "weighted avg       0.68      0.78      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.26829268292683\n",
      "\n",
      " Recall of event Happening: \n",
      " 98.48484848484848\n",
      "\n",
      " AUC: \n",
      " 0.502039627039627\n",
      "\n",
      " F-Score:\n",
      " 0.8783783783783784\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  1  51]\n",
      " [  3 195]]\n",
      "RM From XGboost Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.60      0.68        52\n",
      "           1       0.90      0.96      0.93       198\n",
      "\n",
      "    accuracy                           0.88       250\n",
      "   macro avg       0.85      0.78      0.81       250\n",
      "weighted avg       0.88      0.88      0.88       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1\n",
      " 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 88.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 90.04739336492891\n",
      "\n",
      " Recall of event Happening: \n",
      " 95.95959595959596\n",
      "\n",
      " AUC: \n",
      " 0.7778749028749028\n",
      "\n",
      " F-Score:\n",
      " 0.9290953545232273\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 31  21]\n",
      " [  8 190]]\n",
      "Xgboost From XGboost Selection\n",
      "[12:15:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.54      0.57        52\n",
      "           1       0.88      0.91      0.90       198\n",
      "\n",
      "    accuracy                           0.83       250\n",
      "   macro avg       0.75      0.72      0.73       250\n",
      "weighted avg       0.83      0.83      0.83       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1\n",
      " 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0\n",
      " 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 83.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 88.23529411764706\n",
      "\n",
      " Recall of event Happening: \n",
      " 90.9090909090909\n",
      "\n",
      " AUC: \n",
      " 0.7237762237762237\n",
      "\n",
      " F-Score:\n",
      " 0.8955223880597014\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 28  24]\n",
      " [ 18 180]]\n"
     ]
    }
   ],
   "source": [
    "def select_features(X_train, y_train, X_test,n):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectFromModel(XGBClassifier(n_estimators=100),threshold=-np.inf, max_features=n)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    selected_feat= X_train.columns[(fs.get_support())]\n",
    "    print(selected_feat)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(5,25,5):\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test,n)\n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From XGboost Selection\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From XGboost Selection\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From XGboost Selection\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From XGboost Selection\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325e8d8a",
   "metadata": {},
   "source": [
    "# Interpretation \n",
    "- Logistic Regression with xgboost feature selection doesnot perform well on the less number of features it perform well on 20 features with the accuracy 78.4, precision 79 and recall 98.\n",
    "- SVM with xgboost feature selection perform almost same with more or less features so its better to select with less features. (accuracy 78.4, precision 79, recall 98.48)\n",
    "- RF with xgboost selection performs well on 20 features with accuracy 86.6, precision 90.04 and recall 95.95.\n",
    "- Xgboost with xgboost selection performs well on 10 features with accuracy 84.39, precision 89.16, recall 91.41.\n",
    "\n",
    "We concluded that from xgboost selection RF model (with 10 features) performs well from all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9ce774",
   "metadata": {},
   "source": [
    "# 3- RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3069f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3908353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['std_delta_delta_log_energy', 'det_TKEO_mean_8_coef',\n",
      "       'tqwt_entropy_shannon_dec_36', 'tqwt_TKEO_std_dec_12',\n",
      "       'tqwt_meanValue_dec_36'],\n",
      "      dtype='object')\n",
      "Logistic Regression From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      1.00      0.34        52\n",
      "           1       0.00      0.00      0.00       198\n",
      "\n",
      "    accuracy                           0.21       250\n",
      "   macro avg       0.10      0.50      0.17       250\n",
      "weighted avg       0.04      0.21      0.07       250\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 20.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 52   0]\n",
      " [198   0]]\n",
      "SVM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.02      0.04        52\n",
      "           1       0.79      0.98      0.88       198\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.52      0.50      0.46       250\n",
      "weighted avg       0.68      0.78      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.26829268292683\n",
      "\n",
      " Recall of event Happening: \n",
      " 98.48484848484848\n",
      "\n",
      " AUC: \n",
      " 0.502039627039627\n",
      "\n",
      " F-Score:\n",
      " 0.8783783783783784\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  1  51]\n",
      " [  3 195]]\n",
      "RM From RFE Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55        52\n",
      "           1       0.87      0.91      0.89       198\n",
      "\n",
      "    accuracy                           0.83       250\n",
      "   macro avg       0.74      0.71      0.72       250\n",
      "weighted avg       0.82      0.83      0.82       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1\n",
      " 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 82.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 87.43961352657004\n",
      "\n",
      " Recall of event Happening: \n",
      " 91.41414141414141\n",
      "\n",
      " AUC: \n",
      " 0.7070707070707071\n",
      "\n",
      " F-Score:\n",
      " 0.8938271604938272\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 26  26]\n",
      " [ 17 181]]\n",
      "Xgboost From RFE Selection\n",
      "[12:21:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.50      0.52        52\n",
      "           1       0.87      0.89      0.88       198\n",
      "\n",
      "    accuracy                           0.81       250\n",
      "   macro avg       0.71      0.69      0.70       250\n",
      "weighted avg       0.80      0.81      0.81       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1\n",
      " 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0\n",
      " 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 80.80000000000001\n",
      "\n",
      " Precision of event Happening: \n",
      " 87.12871287128714\n",
      "\n",
      " Recall of event Happening: \n",
      " 88.88888888888889\n",
      "\n",
      " AUC: \n",
      " 0.6944444444444444\n",
      "\n",
      " F-Score:\n",
      " 0.88\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 26  26]\n",
      " [ 22 176]]\n",
      "Index(['std_7th_delta', 'std_delta_delta_log_energy', 'std_10th_delta_delta',\n",
      "       'det_TKEO_mean_8_coef', 'tqwt_entropy_shannon_dec_36',\n",
      "       'tqwt_TKEO_std_dec_12', 'tqwt_meanValue_dec_36', 'tqwt_stdValue_dec_33',\n",
      "       'tqwt_skewnessValue_dec_25', 'tqwt_kurtosisValue_dec_22'],\n",
      "      dtype='object')\n",
      "Logistic Regression From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.04      0.07        52\n",
      "           1       0.80      0.99      0.88       198\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.65      0.51      0.48       250\n",
      "weighted avg       0.74      0.79      0.71       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 79.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.67479674796748\n",
      "\n",
      " Recall of event Happening: \n",
      " 98.98989898989899\n",
      "\n",
      " AUC: \n",
      " 0.5141802641802642\n",
      "\n",
      " F-Score:\n",
      " 0.882882882882883\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  2  50]\n",
      " [  2 196]]\n",
      "SVM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.02      0.04        52\n",
      "           1       0.79      0.98      0.88       198\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.52      0.50      0.46       250\n",
      "weighted avg       0.68      0.78      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.26829268292683\n",
      "\n",
      " Recall of event Happening: \n",
      " 98.48484848484848\n",
      "\n",
      " AUC: \n",
      " 0.502039627039627\n",
      "\n",
      " F-Score:\n",
      " 0.8783783783783784\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  1  51]\n",
      " [  3 195]]\n",
      "RM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68        52\n",
      "           1       0.91      0.92      0.92       198\n",
      "\n",
      "    accuracy                           0.87       250\n",
      "   macro avg       0.80      0.80      0.80       250\n",
      "weighted avg       0.87      0.87      0.87       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0\n",
      " 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 86.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 91.4572864321608\n",
      "\n",
      " Recall of event Happening: \n",
      " 91.91919191919192\n",
      "\n",
      " AUC: \n",
      " 0.7961344211344212\n",
      "\n",
      " F-Score:\n",
      " 0.9168765743073047\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 35  17]\n",
      " [ 16 182]]\n",
      "Xgboost From RFE Selection\n",
      "[12:22:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.56      0.55        52\n",
      "           1       0.88      0.88      0.88       198\n",
      "\n",
      "    accuracy                           0.81       250\n",
      "   macro avg       0.72      0.72      0.72       250\n",
      "weighted avg       0.81      0.81      0.81       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 1 0\n",
      " 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 81.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 88.3248730964467\n",
      "\n",
      " Recall of event Happening: \n",
      " 87.87878787878788\n",
      "\n",
      " AUC: \n",
      " 0.7182400932400932\n",
      "\n",
      " F-Score:\n",
      " 0.8810126582278481\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 29  23]\n",
      " [ 24 174]]\n",
      "Index(['std_delta_log_energy', 'std_7th_delta', 'std_delta_delta_log_energy',\n",
      "       'std_10th_delta_delta', 'det_TKEO_mean_8_coef',\n",
      "       'tqwt_entropy_shannon_dec_27', 'tqwt_entropy_shannon_dec_36',\n",
      "       'tqwt_TKEO_std_dec_12', 'tqwt_meanValue_dec_36', 'tqwt_stdValue_dec_33',\n",
      "       'tqwt_minValue_dec_24', 'tqwt_minValue_dec_35',\n",
      "       'tqwt_skewnessValue_dec_25', 'tqwt_skewnessValue_dec_28',\n",
      "       'tqwt_kurtosisValue_dec_22'],\n",
      "      dtype='object')\n",
      "Logistic Regression From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.08      0.13        52\n",
      "           1       0.80      0.98      0.88       198\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.65      0.53      0.51       250\n",
      "weighted avg       0.74      0.79      0.73       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 79.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 80.16528925619835\n",
      "\n",
      " Recall of event Happening: \n",
      " 97.97979797979798\n",
      "\n",
      " AUC: \n",
      " 0.5283605283605283\n",
      "\n",
      " F-Score:\n",
      " 0.8818181818181817\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  4  48]\n",
      " [  4 194]]\n",
      "SVM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.02      0.04        52\n",
      "           1       0.79      0.98      0.88       198\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.52      0.50      0.46       250\n",
      "weighted avg       0.68      0.78      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.26829268292683\n",
      "\n",
      " Recall of event Happening: \n",
      " 98.48484848484848\n",
      "\n",
      " AUC: \n",
      " 0.502039627039627\n",
      "\n",
      " F-Score:\n",
      " 0.8783783783783784\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  1  51]\n",
      " [  3 195]]\n",
      "RM From RFE Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.62        52\n",
      "           1       0.90      0.91      0.90       198\n",
      "\n",
      "    accuracy                           0.85       250\n",
      "   macro avg       0.77      0.76      0.76       250\n",
      "weighted avg       0.84      0.85      0.85       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 0 0 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 84.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 89.60396039603961\n",
      "\n",
      " Recall of event Happening: \n",
      " 91.41414141414141\n",
      "\n",
      " AUC: \n",
      " 0.7551476301476301\n",
      "\n",
      " F-Score:\n",
      " 0.9049999999999999\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 31  21]\n",
      " [ 17 181]]\n",
      "Xgboost From RFE Selection\n",
      "[12:24:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.50      0.53        52\n",
      "           1       0.87      0.90      0.89       198\n",
      "\n",
      "    accuracy                           0.82       250\n",
      "   macro avg       0.72      0.70      0.71       250\n",
      "weighted avg       0.81      0.82      0.81       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0\n",
      " 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 81.6\n",
      "\n",
      " Precision of event Happening: \n",
      " 87.25490196078431\n",
      "\n",
      " Recall of event Happening: \n",
      " 89.8989898989899\n",
      "\n",
      " AUC: \n",
      " 0.6994949494949495\n",
      "\n",
      " F-Score:\n",
      " 0.8855721393034826\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 26  26]\n",
      " [ 20 178]]\n",
      "Index(['std_MFCC_5th_coef', 'std_delta_log_energy', 'std_4th_delta',\n",
      "       'std_6th_delta', 'std_7th_delta', 'std_delta_delta_log_energy',\n",
      "       'std_6th_delta_delta', 'std_10th_delta_delta', 'det_TKEO_mean_8_coef',\n",
      "       'tqwt_entropy_shannon_dec_27', 'tqwt_entropy_shannon_dec_36',\n",
      "       'tqwt_TKEO_std_dec_12', 'tqwt_meanValue_dec_36', 'tqwt_stdValue_dec_33',\n",
      "       'tqwt_minValue_dec_24', 'tqwt_minValue_dec_35',\n",
      "       'tqwt_skewnessValue_dec_3', 'tqwt_skewnessValue_dec_25',\n",
      "       'tqwt_skewnessValue_dec_28', 'tqwt_kurtosisValue_dec_22'],\n",
      "      dtype='object')\n",
      "Logistic Regression From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.08      0.13        52\n",
      "           1       0.80      0.98      0.88       198\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.65      0.53      0.51       250\n",
      "weighted avg       0.74      0.79      0.73       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 79.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 80.16528925619835\n",
      "\n",
      " Recall of event Happening: \n",
      " 97.97979797979798\n",
      "\n",
      " AUC: \n",
      " 0.5283605283605283\n",
      "\n",
      " F-Score:\n",
      " 0.8818181818181817\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  4  48]\n",
      " [  4 194]]\n",
      "SVM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.02      0.04        52\n",
      "           1       0.79      0.98      0.88       198\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.52      0.50      0.46       250\n",
      "weighted avg       0.68      0.78      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.26829268292683\n",
      "\n",
      " Recall of event Happening: \n",
      " 98.48484848484848\n",
      "\n",
      " AUC: \n",
      " 0.502039627039627\n",
      "\n",
      " F-Score:\n",
      " 0.8783783783783784\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  1  51]\n",
      " [  3 195]]\n",
      "RM From RFE Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.56      0.60        52\n",
      "           1       0.89      0.92      0.91       198\n",
      "\n",
      "    accuracy                           0.85       250\n",
      "   macro avg       0.77      0.74      0.76       250\n",
      "weighted avg       0.84      0.85      0.84       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 84.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 88.83495145631069\n",
      "\n",
      " Recall of event Happening: \n",
      " 92.42424242424242\n",
      "\n",
      " AUC: \n",
      " 0.740967365967366\n",
      "\n",
      " F-Score:\n",
      " 0.905940594059406\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 29  23]\n",
      " [ 15 183]]\n",
      "Xgboost From RFE Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:26:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57        52\n",
      "           1       0.89      0.89      0.89       198\n",
      "\n",
      "    accuracy                           0.82       250\n",
      "   macro avg       0.73      0.73      0.73       250\n",
      "weighted avg       0.82      0.82      0.82       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0\n",
      " 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 82.39999999999999\n",
      "\n",
      " Precision of event Happening: \n",
      " 88.5\n",
      "\n",
      " Recall of event Happening: \n",
      " 89.39393939393939\n",
      "\n",
      " AUC: \n",
      " 0.7258158508158509\n",
      "\n",
      " F-Score:\n",
      " 0.8894472361809046\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 29  23]\n",
      " [ 21 177]]\n"
     ]
    }
   ],
   "source": [
    "def select_features(X_train, y_train, X_test,n):\n",
    "    # configure to select a subset of features\n",
    "    fs = RFE(estimator = DecisionTreeClassifier(), n_features_to_select = n)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    selected_feat= X_train.columns[(fs.get_support())]\n",
    "    print(selected_feat)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(5,25,5):\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test,n)\n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From RFE Selection\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From RFE Selection\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From RFE Selection\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From RFE Selection\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea32444",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "- Logistic Regression with RFE selection perform well with 10 features with an accuracy of 79, precision 79.67, recall 98.9.\n",
    "- SVM with RFE selection perform well with 5 features with an accuracy 78, precision 79, recall 98.\n",
    "- RF with RFE selection perform well with 10 features with an accuracy of 86.6, precision 91.45, recall 91.9.\n",
    "- Xgboost with RFE selection performs well with 20 features with an accuracy of 82.39, precision 88.5, recall 89.39\n",
    "\n",
    "We concluded that from RFE selection RF performs (with 10 features) model performs well from all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a565992d",
   "metadata": {},
   "source": [
    "# 4- LASSO FOR FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df9cdb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8e8c727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.979e-03, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.050e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.244e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.528e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.583e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.977e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.938e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.305e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.626e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.732e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.282e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.885e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.783e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.752e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.892e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.394e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.463e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.654e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.365e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.275e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.910e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.701e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.972e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.491e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.904e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.579e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.162e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.745e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.339e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.392e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.111e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.311e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.287e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.741e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.212e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.578e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.668e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.083e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.434e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.281e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.150e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.237e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.212e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.176e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.151e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.806e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.686e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.054e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.273e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.124e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.795e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.547e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.511e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.062e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.964e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.310e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.813e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.262e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.593e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.505e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.929e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.371e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.072e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.825e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.804e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.543e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.087e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.252e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.875e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.236e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.826e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.214e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.859e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.617e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.557e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.832e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.406e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.996e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.382e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.830e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.832e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.796e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.070e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.987e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.409e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.616e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.613e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.617e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.020e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.421e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.291e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.179e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.108e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.308e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.998e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.362e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.332e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.695e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.394e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.439e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.888e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.575e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.425e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.833e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.001e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.440e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.195e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.584e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.582e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.090e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.955e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.450e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.403e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.855e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.450e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.464e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.448e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.207e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.864e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.869e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.412e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.618e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tqwt_meanValue_dec_2', 'tqwt_meanValue_dec_5', 'tqwt_meanValue_dec_7',\n",
      "       'tqwt_meanValue_dec_17', 'tqwt_meanValue_dec_20'],\n",
      "      dtype='object')\n",
      "Logistic Regression From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.79      1.00      0.88       198\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.40      0.50      0.44       250\n",
      "weighted avg       0.63      0.79      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 79.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.2\n",
      "\n",
      " Recall of event Happening: \n",
      " 100.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.8839285714285714\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  0  52]\n",
      " [  0 198]]\n",
      "SVM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.08      0.11        52\n",
      "           1       0.79      0.92      0.85       198\n",
      "\n",
      "    accuracy                           0.75       250\n",
      "   macro avg       0.50      0.50      0.48       250\n",
      "weighted avg       0.67      0.75      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 74.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.22077922077922\n",
      "\n",
      " Recall of event Happening: \n",
      " 92.42424242424242\n",
      "\n",
      " AUC: \n",
      " 0.5005827505827505\n",
      "\n",
      " F-Score:\n",
      " 0.8531468531468532\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  4  48]\n",
      " [ 15 183]]\n",
      "RM From L1 Based Feature Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.79      1.00      0.88       198\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.40      0.50      0.44       250\n",
      "weighted avg       0.63      0.79      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 79.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.2\n",
      "\n",
      " Recall of event Happening: \n",
      " 100.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.8839285714285714\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  0  52]\n",
      " [  0 198]]\n",
      "Xgboost From L1 Based Feature Selection\n",
      "[12:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.23      0.25        52\n",
      "           1       0.80      0.83      0.82       198\n",
      "\n",
      "    accuracy                           0.71       250\n",
      "   macro avg       0.54      0.53      0.53       250\n",
      "weighted avg       0.69      0.71      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1\n",
      " 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0\n",
      " 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 70.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 80.48780487804879\n",
      "\n",
      " Recall of event Happening: \n",
      " 83.33333333333334\n",
      "\n",
      " AUC: \n",
      " 0.532051282051282\n",
      "\n",
      " F-Score:\n",
      " 0.8188585607940447\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 12  40]\n",
      " [ 33 165]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.979e-03, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.050e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.244e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.528e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.583e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.977e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.938e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.305e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.626e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.732e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.282e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.885e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.783e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.752e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.892e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.394e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.463e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.654e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.365e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.275e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.910e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.701e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.972e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.491e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.904e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.579e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.162e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.745e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.339e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.392e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.111e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.311e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.287e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.741e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.212e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.578e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.668e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.083e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.434e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.281e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.150e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.237e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.212e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.176e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.151e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.806e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.686e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.054e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.273e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.124e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.795e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.547e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.511e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.062e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.964e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.310e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.813e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.262e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.593e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.505e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.929e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.371e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.072e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.825e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.804e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.543e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.087e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.252e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.875e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.236e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.826e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.214e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.859e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.617e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.557e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.832e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.406e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.996e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.382e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.830e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.832e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.796e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.070e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.987e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.409e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.616e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.613e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.617e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.020e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.421e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.291e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.179e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.108e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.308e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.998e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.362e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.332e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.695e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.394e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.439e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.888e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.575e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.425e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.833e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.001e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.440e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.195e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.584e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.582e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.090e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.955e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.450e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.403e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.855e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.450e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.464e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.448e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.207e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.864e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.869e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.412e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.618e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tqwt_medianValue_dec_5', 'tqwt_medianValue_dec_8',\n",
      "       'tqwt_meanValue_dec_2', 'tqwt_meanValue_dec_5', 'tqwt_meanValue_dec_7',\n",
      "       'tqwt_meanValue_dec_16', 'tqwt_meanValue_dec_17',\n",
      "       'tqwt_meanValue_dec_20', 'tqwt_meanValue_dec_22',\n",
      "       'tqwt_meanValue_dec_25'],\n",
      "      dtype='object')\n",
      "Logistic Regression From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.79      1.00      0.88       198\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.40      0.50      0.44       250\n",
      "weighted avg       0.63      0.79      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 79.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.2\n",
      "\n",
      " Recall of event Happening: \n",
      " 100.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.8839285714285714\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  0  52]\n",
      " [  0 198]]\n",
      "SVM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.08      0.13        52\n",
      "           1       0.80      0.96      0.87       198\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.58      0.52      0.50       250\n",
      "weighted avg       0.71      0.78      0.72       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.0\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.9163179916318\n",
      "\n",
      " Recall of event Happening: \n",
      " 96.46464646464646\n",
      "\n",
      " AUC: \n",
      " 0.5207847707847708\n",
      "\n",
      " F-Score:\n",
      " 0.8741418764302059\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  4  48]\n",
      " [  7 191]]\n",
      "RM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.37      0.35        52\n",
      "           1       0.83      0.81      0.82       198\n",
      "\n",
      "    accuracy                           0.72       250\n",
      "   macro avg       0.58      0.59      0.59       250\n",
      "weighted avg       0.73      0.72      0.72       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0\n",
      " 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0\n",
      " 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 72.0\n",
      "\n",
      " Precision of event Happening: \n",
      " 82.9896907216495\n",
      "\n",
      " Recall of event Happening: \n",
      " 81.31313131313132\n",
      "\n",
      " AUC: \n",
      " 0.5892579642579643\n",
      "\n",
      " F-Score:\n",
      " 0.8214285714285714\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 19  33]\n",
      " [ 37 161]]\n",
      "Xgboost From L1 Based Feature Selection\n",
      "[12:30:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.31      0.36        52\n",
      "           1       0.83      0.89      0.86       198\n",
      "\n",
      "    accuracy                           0.77       250\n",
      "   macro avg       0.63      0.60      0.61       250\n",
      "weighted avg       0.75      0.77      0.76       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1\n",
      " 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 77.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 83.09859154929578\n",
      "\n",
      " Recall of event Happening: \n",
      " 89.39393939393939\n",
      "\n",
      " AUC: \n",
      " 0.6008158508158508\n",
      "\n",
      " F-Score:\n",
      " 0.8613138686131386\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 16  36]\n",
      " [ 21 177]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.979e-03, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.050e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.244e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.528e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.583e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.977e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.938e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.305e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.626e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.732e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.282e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.885e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.783e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.752e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.892e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.394e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.463e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.654e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.365e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.275e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.910e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.701e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.972e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.491e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.904e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.579e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.162e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.745e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.339e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.392e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.111e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.311e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.287e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.741e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.212e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.578e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.668e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.083e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.434e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.281e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.150e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.237e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.212e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.176e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.151e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.806e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.686e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.054e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.273e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.124e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.795e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.547e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.511e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.062e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.964e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.310e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.813e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.262e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.593e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.505e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.929e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.371e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.072e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.825e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.804e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.543e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.087e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.252e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.875e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.236e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.826e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.214e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.859e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.617e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.557e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.832e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.406e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.996e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.382e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.830e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.832e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.796e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.070e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.987e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.409e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.616e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.613e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.617e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.020e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.421e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.291e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.179e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.108e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.308e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.998e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.362e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.332e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.695e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.394e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.439e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.888e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.575e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.425e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.833e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.001e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.440e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.195e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.584e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.582e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.090e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.955e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.450e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.403e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.855e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.450e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.464e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.448e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.207e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.864e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.869e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.412e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.618e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mean_7th_delta_delta', 'tqwt_TKEO_std_dec_6', 'tqwt_medianValue_dec_5',\n",
      "       'tqwt_medianValue_dec_8', 'tqwt_medianValue_dec_10',\n",
      "       'tqwt_medianValue_dec_14', 'tqwt_medianValue_dec_22',\n",
      "       'tqwt_meanValue_dec_2', 'tqwt_meanValue_dec_5', 'tqwt_meanValue_dec_7',\n",
      "       'tqwt_meanValue_dec_16', 'tqwt_meanValue_dec_17',\n",
      "       'tqwt_meanValue_dec_20', 'tqwt_meanValue_dec_22',\n",
      "       'tqwt_meanValue_dec_25'],\n",
      "      dtype='object')\n",
      "Logistic Regression From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.79      1.00      0.88       198\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.40      0.50      0.44       250\n",
      "weighted avg       0.63      0.79      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 79.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.2\n",
      "\n",
      " Recall of event Happening: \n",
      " 100.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.8839285714285714\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  0  52]\n",
      " [  0 198]]\n",
      "SVM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.13      0.19        52\n",
      "           1       0.80      0.92      0.86       198\n",
      "\n",
      "    accuracy                           0.76       250\n",
      "   macro avg       0.56      0.53      0.52       250\n",
      "weighted avg       0.70      0.76      0.72       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 76.0\n",
      "\n",
      " Precision of event Happening: \n",
      " 80.26315789473685\n",
      "\n",
      " Recall of event Happening: \n",
      " 92.42424242424242\n",
      "\n",
      " AUC: \n",
      " 0.5294289044289044\n",
      "\n",
      " F-Score:\n",
      " 0.8591549295774648\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  7  45]\n",
      " [ 15 183]]\n",
      "RM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.33      0.34        52\n",
      "           1       0.83      0.85      0.84       198\n",
      "\n",
      "    accuracy                           0.74       250\n",
      "   macro avg       0.59      0.59      0.59       250\n",
      "weighted avg       0.73      0.74      0.74       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1\n",
      " 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1]\n",
      "\n",
      " Accuracy: \n",
      " 74.0\n",
      "\n",
      " Precision of event Happening: \n",
      " 82.75862068965517\n",
      "\n",
      " Recall of event Happening: \n",
      " 84.84848484848484\n",
      "\n",
      " AUC: \n",
      " 0.5877039627039627\n",
      "\n",
      " F-Score:\n",
      " 0.8379052369077307\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 17  35]\n",
      " [ 30 168]]\n",
      "Xgboost From L1 Based Feature Selection\n",
      "[12:31:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.35      0.36        52\n",
      "           1       0.83      0.85      0.84       198\n",
      "\n",
      "    accuracy                           0.75       250\n",
      "   macro avg       0.61      0.60      0.60       250\n",
      "weighted avg       0.74      0.75      0.74       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0\n",
      " 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1\n",
      " 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1\n",
      " 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 74.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 83.2512315270936\n",
      "\n",
      " Recall of event Happening: \n",
      " 85.35353535353535\n",
      "\n",
      " AUC: \n",
      " 0.5998445998445998\n",
      "\n",
      " F-Score:\n",
      " 0.8428927680798005\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 18  34]\n",
      " [ 29 169]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.979e-03, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.050e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.244e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.528e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.583e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.977e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.938e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.305e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.626e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.732e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.282e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.885e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.783e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.752e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.892e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.394e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.463e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.654e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.365e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.275e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.910e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.701e-02, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e-01, tolerance: 8.353e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.972e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.491e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.904e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.579e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.162e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.745e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.339e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.392e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.111e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.311e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.287e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.741e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.212e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.578e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.668e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.083e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.434e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.281e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.150e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.237e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.212e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.176e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.151e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.806e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.686e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.054e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.273e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.124e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.795e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.547e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.511e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.062e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.964e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.310e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.813e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.262e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.593e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.505e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.929e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.371e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.072e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.825e-02, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.804e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.543e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.087e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.252e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e-01, tolerance: 8.058e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.875e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.236e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.826e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.214e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.859e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.617e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.557e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.832e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.406e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.996e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.382e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.830e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.832e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.796e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.070e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.987e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.409e-02, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.616e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.613e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.617e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.020e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.421e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.291e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.179e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.108e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.308e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.998e-01, tolerance: 8.235e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.362e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.332e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.695e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.394e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.439e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.888e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.575e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.425e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.833e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.001e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.440e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.195e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.584e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.582e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.090e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.955e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.450e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.403e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.855e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.450e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.464e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.448e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.207e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.864e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.869e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.412e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.618e-02, tolerance: 7.778e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mean_delta_log_energy', 'mean_7th_delta_delta',\n",
      "       'std_delta_delta_log_energy', 'std_7th_delta_delta',\n",
      "       'tqwt_TKEO_std_dec_6', 'tqwt_TKEO_std_dec_11', 'tqwt_medianValue_dec_5',\n",
      "       'tqwt_medianValue_dec_8', 'tqwt_medianValue_dec_10',\n",
      "       'tqwt_medianValue_dec_14', 'tqwt_medianValue_dec_22',\n",
      "       'tqwt_medianValue_dec_25', 'tqwt_meanValue_dec_2',\n",
      "       'tqwt_meanValue_dec_5', 'tqwt_meanValue_dec_7', 'tqwt_meanValue_dec_16',\n",
      "       'tqwt_meanValue_dec_17', 'tqwt_meanValue_dec_20',\n",
      "       'tqwt_meanValue_dec_22', 'tqwt_meanValue_dec_25'],\n",
      "      dtype='object')\n",
      "Logistic Regression From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.79      1.00      0.88       198\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.40      0.50      0.44       250\n",
      "weighted avg       0.63      0.79      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 79.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.2\n",
      "\n",
      " Recall of event Happening: \n",
      " 100.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.8839285714285714\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  0  52]\n",
      " [  0 198]]\n",
      "SVM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.42      0.48        52\n",
      "           1       0.86      0.91      0.88       198\n",
      "\n",
      "    accuracy                           0.81       250\n",
      "   macro avg       0.70      0.67      0.68       250\n",
      "weighted avg       0.79      0.81      0.80       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 80.80000000000001\n",
      "\n",
      " Precision of event Happening: \n",
      " 85.71428571428571\n",
      "\n",
      " Recall of event Happening: \n",
      " 90.9090909090909\n",
      "\n",
      " AUC: \n",
      " 0.666083916083916\n",
      "\n",
      " F-Score:\n",
      " 0.8823529411764706\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 22  30]\n",
      " [ 18 180]]\n",
      "RM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61        52\n",
      "           1       0.90      0.90      0.90       198\n",
      "\n",
      "    accuracy                           0.84       250\n",
      "   macro avg       0.76      0.75      0.75       250\n",
      "weighted avg       0.84      0.84      0.84       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0\n",
      " 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 84.0\n",
      "\n",
      " Precision of event Happening: \n",
      " 89.5\n",
      "\n",
      " Recall of event Happening: \n",
      " 90.40404040404042\n",
      "\n",
      " AUC: \n",
      " 0.750097125097125\n",
      "\n",
      " F-Score:\n",
      " 0.8994974874371859\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 31  21]\n",
      " [ 19 179]]\n",
      "Xgboost From L1 Based Feature Selection\n",
      "[12:32:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.52      0.56        52\n",
      "           1       0.88      0.91      0.89       198\n",
      "\n",
      "    accuracy                           0.83       250\n",
      "   macro avg       0.74      0.71      0.73       250\n",
      "weighted avg       0.82      0.83      0.82       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 82.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 87.8048780487805\n",
      "\n",
      " Recall of event Happening: \n",
      " 90.9090909090909\n",
      "\n",
      " AUC: \n",
      " 0.7141608391608392\n",
      "\n",
      " F-Score:\n",
      " 0.8933002481389578\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 27  25]\n",
      " [ 18 180]]\n"
     ]
    }
   ],
   "source": [
    "def select_features(X_train, y_train, X_test,n):\n",
    "    # configure to select a subset of features\n",
    "    # Use L1 penalty\n",
    "    estimator = LassoCV(cv=5, normalize = True)\n",
    "    fs = SelectFromModel(estimator,threshold=-np.inf, max_features=n)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    selected_feat= X_train.columns[(fs.get_support())]\n",
    "    print(selected_feat)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(5,25,5):\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test,n)\n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From L1 Based Feature Selection\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From L1 Based Feature Selection\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From L1 Based Feature Selection\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From L1 Based Feature Selection\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5739ce08",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "- Logistic Regression with lasso selection performs well with 5 features with an accuracy of 79, precision 79, recall 100.\n",
    "- SVM with lasso selection performs well with 20 features with an accuracy of 80, precision 85, recall 90.\n",
    "-  RF with lasso selection performs well with 20 features with an accuracy of 84, precision 89, recall 90.\n",
    "- Xgboost with lasso selection performs well with 20 features with an accuracy of 80, precision 85, recall 90.\n",
    "\n",
    "We concluded that lasso selection of less features doesnot perform with classifiers. RF from lasso selection (20 features) performs well from all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ac2013",
   "metadata": {},
   "source": [
    "# 5- PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52b2405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.37504643e-01 9.51837889e-02 8.94482982e-02 4.09762065e-02\n",
      " 3.40610210e-02 3.15507542e-02 2.31409205e-02 2.21798366e-02\n",
      " 2.05611606e-02 1.83448879e-02 1.76660464e-02 1.59261127e-02\n",
      " 1.35777612e-02 1.28940147e-02 1.18516348e-02 1.12204248e-02\n",
      " 1.10173401e-02 1.08214091e-02 1.02830814e-02 9.43278628e-03\n",
      " 9.03553162e-03 8.18433259e-03 7.69075958e-03 7.45569245e-03\n",
      " 7.21196404e-03 6.94448485e-03 6.57986039e-03 6.32834163e-03\n",
      " 6.17792709e-03 5.87730543e-03 5.61544020e-03 5.39412686e-03\n",
      " 5.12026444e-03 4.79552192e-03 4.61794727e-03 4.49698524e-03\n",
      " 4.40862742e-03 4.16287794e-03 3.93179379e-03 3.90541086e-03\n",
      " 3.81865387e-03 3.71859594e-03 3.64610278e-03 3.58404178e-03\n",
      " 3.48797555e-03 3.35835237e-03 3.32127681e-03 3.24785941e-03\n",
      " 3.17295471e-03 3.07712380e-03 2.97452348e-03 2.96501909e-03\n",
      " 2.90058445e-03 2.86215345e-03 2.79546579e-03 2.76088805e-03\n",
      " 2.71646944e-03 2.67357603e-03 2.59260594e-03 2.52473972e-03\n",
      " 2.49755019e-03 2.47787127e-03 2.41925262e-03 2.39886993e-03\n",
      " 2.33914755e-03 2.29678060e-03 2.29068589e-03 2.24041499e-03\n",
      " 2.22998759e-03 2.18374363e-03 2.15312373e-03 2.12550999e-03\n",
      " 2.11242872e-03 2.07149142e-03 2.03407697e-03 2.01906763e-03\n",
      " 2.00650704e-03 1.96367661e-03 1.94394096e-03 1.91040025e-03\n",
      " 1.87318015e-03 1.84551014e-03 1.78878398e-03 1.77416718e-03\n",
      " 1.74945599e-03 1.74063117e-03 1.73428300e-03 1.72495503e-03\n",
      " 1.71103071e-03 1.67345364e-03 1.65811814e-03 1.64120742e-03\n",
      " 1.60371183e-03 1.59017541e-03 1.58110403e-03 1.55453783e-03\n",
      " 1.52447892e-03 1.50714161e-03 1.49718639e-03 1.47495717e-03\n",
      " 1.45403088e-03 1.44938879e-03 1.43610855e-03 1.40514275e-03\n",
      " 1.39406918e-03 1.38927679e-03 1.37392474e-03 1.35212236e-03\n",
      " 1.33625847e-03 1.33111372e-03 1.29199509e-03 1.27082554e-03\n",
      " 1.26448578e-03 1.25557564e-03 1.24375066e-03 1.21315154e-03\n",
      " 1.19737703e-03 1.19160818e-03 1.17842588e-03 1.16021881e-03\n",
      " 1.12968371e-03 1.10841670e-03 1.09743448e-03 1.08946894e-03\n",
      " 1.07522245e-03 1.06447416e-03 1.05784719e-03 1.04630151e-03\n",
      " 1.03581721e-03 1.02765626e-03 1.01177975e-03 9.90250078e-04\n",
      " 9.76397183e-04 9.68345854e-04 9.55884151e-04 9.46305598e-04\n",
      " 9.35810137e-04 9.26923724e-04 9.01787548e-04 8.99504321e-04\n",
      " 8.83069656e-04 8.70240636e-04 8.51788540e-04 8.39963505e-04\n",
      " 8.34698013e-04 8.23435991e-04 8.15037870e-04 8.07627019e-04\n",
      " 7.96245434e-04 7.92290479e-04 7.78599752e-04 7.66371324e-04\n",
      " 7.47725797e-04 7.36885764e-04 7.32431995e-04 7.28584968e-04\n",
      " 7.16514893e-04 7.10615749e-04 7.02617797e-04 6.97346804e-04\n",
      " 6.86826748e-04 6.73426971e-04 6.66768254e-04 6.55011051e-04\n",
      " 6.43151629e-04 6.30574380e-04 6.24542565e-04 6.19788514e-04\n",
      " 6.14331099e-04 6.02326457e-04 5.92874680e-04 5.87060732e-04\n",
      " 5.79956411e-04 5.66854671e-04 5.58692737e-04 5.46660785e-04\n",
      " 5.41688450e-04 5.34160446e-04 5.22409689e-04 5.19905945e-04\n",
      " 5.06580685e-04 5.06057448e-04 4.96621018e-04 4.92051976e-04\n",
      " 4.84620085e-04 4.78583972e-04 4.69748499e-04 4.66661718e-04\n",
      " 4.56920684e-04 4.51358886e-04 4.45250165e-04 4.40630834e-04\n",
      " 4.29337140e-04 4.22737138e-04 4.22049925e-04 4.15376644e-04\n",
      " 4.14435501e-04 4.01243361e-04 3.94891309e-04 3.87447586e-04\n",
      " 3.82496395e-04 3.79328864e-04 3.72763394e-04 3.60168115e-04\n",
      " 3.55993374e-04 3.52004541e-04 3.44007714e-04 3.40870214e-04\n",
      " 3.38755860e-04 3.37078604e-04 3.32535088e-04 3.21211580e-04\n",
      " 3.19878435e-04 3.14683004e-04 3.12046821e-04 2.97267820e-04\n",
      " 2.94281126e-04 2.89633801e-04 2.88245627e-04 2.85358802e-04\n",
      " 2.82797636e-04 2.78928187e-04 2.72918454e-04 2.65855866e-04\n",
      " 2.64447656e-04 2.58723247e-04 2.55279310e-04 2.49375640e-04\n",
      " 2.47321484e-04 2.42874617e-04 2.41705576e-04 2.34453153e-04\n",
      " 2.32294894e-04 2.27710246e-04 2.20562507e-04 2.15517437e-04\n",
      " 2.12145933e-04 2.10331879e-04 2.07867741e-04 2.05080925e-04\n",
      " 2.01017426e-04 1.99254330e-04 1.96826457e-04 1.90147125e-04\n",
      " 1.87065062e-04 1.85650065e-04 1.83754260e-04 1.79558512e-04\n",
      " 1.77783778e-04 1.72315669e-04 1.70170937e-04 1.69837355e-04\n",
      " 1.64240903e-04 1.61974554e-04 1.59938941e-04 1.56982874e-04\n",
      " 1.54113095e-04 1.51518700e-04 1.47927944e-04 1.44571000e-04\n",
      " 1.41796656e-04 1.38602125e-04 1.36065013e-04 1.33969374e-04\n",
      " 1.30177911e-04 1.29380183e-04 1.25123310e-04 1.21590269e-04\n",
      " 1.18917889e-04 1.18399207e-04 1.16883563e-04 1.14322886e-04\n",
      " 1.13169697e-04 1.10331658e-04 1.08463342e-04 1.06419431e-04\n",
      " 1.03541327e-04 1.01502919e-04 9.96727956e-05 9.73577151e-05\n",
      " 9.66596985e-05 9.53555747e-05 9.49490381e-05 9.19283783e-05\n",
      " 9.06426968e-05 8.93372516e-05 8.67222409e-05 8.60592617e-05\n",
      " 8.49057828e-05 8.34354383e-05 8.12104624e-05 8.05276713e-05\n",
      " 7.90128558e-05 7.71531008e-05 7.54981809e-05 7.50505476e-05\n",
      " 7.18523808e-05 7.11384690e-05 7.01018514e-05 6.83675786e-05\n",
      " 6.74841118e-05 6.63253400e-05 6.58964826e-05 6.51202186e-05\n",
      " 6.37292507e-05 6.26036766e-05 6.04466336e-05 5.96455524e-05\n",
      " 5.87886790e-05 5.79384098e-05 5.77552518e-05 5.58404735e-05\n",
      " 5.46490757e-05 5.39573569e-05 5.26884390e-05 5.11741344e-05\n",
      " 5.06879996e-05 4.83823357e-05 4.77042204e-05 4.73293044e-05\n",
      " 4.59947911e-05 4.55076822e-05 4.50393834e-05 4.40492116e-05\n",
      " 4.37253427e-05 4.29893411e-05 4.19233952e-05 4.03742109e-05\n",
      " 3.96077946e-05 3.89328221e-05 3.82247172e-05 3.80273135e-05\n",
      " 3.70290649e-05 3.59411048e-05 3.49474576e-05 3.48521743e-05\n",
      " 3.34677892e-05 3.30155459e-05 3.27704905e-05 3.21308042e-05\n",
      " 3.12007851e-05 3.04975266e-05 2.96669539e-05 2.90684142e-05\n",
      " 2.86360848e-05 2.77249142e-05 2.75930775e-05 2.72445605e-05\n",
      " 2.65724278e-05 2.62829724e-05 2.58787681e-05 2.55042989e-05\n",
      " 2.47133612e-05 2.43574956e-05 2.36264562e-05 2.33546315e-05\n",
      " 2.30059517e-05 2.24868973e-05 2.19330190e-05 2.15316222e-05\n",
      " 2.09895962e-05 2.05339354e-05 2.00659106e-05 1.95942766e-05\n",
      " 1.91673328e-05 1.89517942e-05 1.83571096e-05 1.81131572e-05\n",
      " 1.79945264e-05 1.73645974e-05 1.73204914e-05 1.71442289e-05\n",
      " 1.68949173e-05 1.60487146e-05 1.58008055e-05 1.55929598e-05\n",
      " 1.49920286e-05 1.47331725e-05 1.44527903e-05 1.40786402e-05\n",
      " 1.37195423e-05 1.35689523e-05 1.32488881e-05 1.27799064e-05\n",
      " 1.22350349e-05 1.19810033e-05 1.18881490e-05 1.15239542e-05\n",
      " 1.13614045e-05 1.11758807e-05 1.08446041e-05 1.07319552e-05\n",
      " 1.04136634e-05 1.01337447e-05 1.00506898e-05 9.92599798e-06\n",
      " 9.55981405e-06 9.35866177e-06 9.12924547e-06 8.98039134e-06\n",
      " 8.78766195e-06 8.70088106e-06 8.64068019e-06 8.43592481e-06\n",
      " 8.19512362e-06 8.05321195e-06 7.88199328e-06 7.74144012e-06\n",
      " 7.33069625e-06 7.28535302e-06 7.11263898e-06 6.92616162e-06\n",
      " 6.86910480e-06 6.68159554e-06 6.34679496e-06 6.25349911e-06\n",
      " 6.13584845e-06 5.88227448e-06 5.76888811e-06 5.54958215e-06\n",
      " 5.43655221e-06 5.33118900e-06 5.29954819e-06 5.19968286e-06\n",
      " 5.01357365e-06 4.73338526e-06 4.58641523e-06 4.52037862e-06\n",
      " 4.30418483e-06 4.10658713e-06 4.06463849e-06 4.00996524e-06\n",
      " 3.91238036e-06 3.84170356e-06 3.68763161e-06 3.61819439e-06\n",
      " 3.49521042e-06 3.46756402e-06 3.36982224e-06 3.22470053e-06\n",
      " 3.07242085e-06 3.02237813e-06 2.99077318e-06 2.90668109e-06\n",
      " 2.67613791e-06 2.59303873e-06 2.49266173e-06 2.43599900e-06\n",
      " 2.37650710e-06 2.33551205e-06 2.27890191e-06 2.23221569e-06\n",
      " 2.11752927e-06 2.07337571e-06 2.00075685e-06 1.97195027e-06\n",
      " 1.88758432e-06 1.84242243e-06 1.79771585e-06 1.69276180e-06\n",
      " 1.63836424e-06 1.57345154e-06 1.51396337e-06 1.50131269e-06\n",
      " 1.42598127e-06 1.36057498e-06 1.33245619e-06 1.25715387e-06\n",
      " 1.22519176e-06 1.20788330e-06 1.15713576e-06 1.08998964e-06\n",
      " 1.04658487e-06 1.02516163e-06 9.62992770e-07 9.58653154e-07\n",
      " 9.09079815e-07 8.78945445e-07 8.28435228e-07 7.99581966e-07\n",
      " 7.74218950e-07 7.59494992e-07 7.34958420e-07 6.90136566e-07\n",
      " 6.83931548e-07 6.35800362e-07 5.88002082e-07 5.68777198e-07\n",
      " 5.49781044e-07 5.34702267e-07 4.96339434e-07 4.66068978e-07\n",
      " 4.55171643e-07 4.36372911e-07 4.17385429e-07 3.68400450e-07\n",
      " 3.42306629e-07 3.18703899e-07 3.13289581e-07 2.84371818e-07\n",
      " 2.61415700e-07 2.50559807e-07 2.15929271e-07 1.99057725e-07\n",
      " 1.80994779e-07 2.71180093e-32]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)\n",
    "with plt.style.context('dark_background'):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(range(len(X_train)), explained_variance, alpha=0.5, align='center',label='individual explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "884d897d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio of  5  Components:\n",
      "[0.13750464 0.09518379 0.0894483  0.04097621 0.03406102]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.52      0.59        52\n",
      "           1       0.88      0.93      0.91       198\n",
      "\n",
      "    accuracy                           0.85       250\n",
      "   macro avg       0.78      0.73      0.75       250\n",
      "weighted avg       0.84      0.85      0.84       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1\n",
      " 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 84.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 88.09523809523809\n",
      "\n",
      " Recall of event Happening: \n",
      " 93.43434343434343\n",
      "\n",
      " AUC: \n",
      " 0.7267871017871017\n",
      "\n",
      " F-Score:\n",
      " 0.9068627450980393\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 27  25]\n",
      " [ 13 185]]\n",
      "SVM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.38      0.49        52\n",
      "           1       0.86      0.95      0.90       198\n",
      "\n",
      "    accuracy                           0.84       250\n",
      "   macro avg       0.77      0.67      0.70       250\n",
      "weighted avg       0.82      0.84      0.82       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 83.6\n",
      "\n",
      " Precision of event Happening: \n",
      " 85.52036199095022\n",
      "\n",
      " Recall of event Happening: \n",
      " 95.45454545454545\n",
      "\n",
      " AUC: \n",
      " 0.6695804195804196\n",
      "\n",
      " F-Score:\n",
      " 0.9021479713603817\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 20  32]\n",
      " [  9 189]]\n",
      "RM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.48      0.53        52\n",
      "           1       0.87      0.91      0.89       198\n",
      "\n",
      "    accuracy                           0.82       250\n",
      "   macro avg       0.73      0.69      0.71       250\n",
      "weighted avg       0.81      0.82      0.81       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 0 1\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 82.0\n",
      "\n",
      " Precision of event Happening: \n",
      " 86.95652173913044\n",
      "\n",
      " Recall of event Happening: \n",
      " 90.9090909090909\n",
      "\n",
      " AUC: \n",
      " 0.6949300699300699\n",
      "\n",
      " F-Score:\n",
      " 0.888888888888889\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 25  27]\n",
      " [ 18 180]]\n",
      "Xgboost From PCA\n",
      "[12:39:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.48      0.51        52\n",
      "           1       0.87      0.89      0.88       198\n",
      "\n",
      "    accuracy                           0.80       250\n",
      "   macro avg       0.70      0.68      0.69       250\n",
      "weighted avg       0.80      0.80      0.80       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Vector: \n",
      " [1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 80.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 86.69950738916256\n",
      "\n",
      " Recall of event Happening: \n",
      " 88.88888888888889\n",
      "\n",
      " AUC: \n",
      " 0.6848290598290598\n",
      "\n",
      " F-Score:\n",
      " 0.8778054862842892\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 25  27]\n",
      " [ 22 176]]\n",
      "Explained Variance Ratio of  10  Components:\n",
      "[0.13750464 0.09518379 0.0894483  0.04097621 0.03406102 0.03155075\n",
      " 0.0231409  0.02217981 0.02056051 0.01834452]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.58        52\n",
      "           1       0.89      0.88      0.89       198\n",
      "\n",
      "    accuracy                           0.82       250\n",
      "   macro avg       0.73      0.74      0.74       250\n",
      "weighted avg       0.83      0.82      0.83       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 82.39999999999999\n",
      "\n",
      " Precision of event Happening: \n",
      " 89.28571428571429\n",
      "\n",
      " Recall of event Happening: \n",
      " 88.38383838383838\n",
      "\n",
      " AUC: \n",
      " 0.7399961149961151\n",
      "\n",
      " F-Score:\n",
      " 0.8883248730964467\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 31  21]\n",
      " [ 23 175]]\n",
      "SVM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.42      0.53        52\n",
      "           1       0.86      0.95      0.91       198\n",
      "\n",
      "    accuracy                           0.84       250\n",
      "   macro avg       0.79      0.69      0.72       250\n",
      "weighted avg       0.83      0.84      0.83       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 84.39999999999999\n",
      "\n",
      " Precision of event Happening: \n",
      " 86.3013698630137\n",
      "\n",
      " Recall of event Happening: \n",
      " 95.45454545454545\n",
      "\n",
      " AUC: \n",
      " 0.6888111888111889\n",
      "\n",
      " F-Score:\n",
      " 0.906474820143885\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 22  30]\n",
      " [  9 189]]\n",
      "RM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.60      0.65        52\n",
      "           1       0.90      0.93      0.92       198\n",
      "\n",
      "    accuracy                           0.86       250\n",
      "   macro avg       0.80      0.77      0.78       250\n",
      "weighted avg       0.86      0.86      0.86       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 86.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 89.80582524271846\n",
      "\n",
      " Recall of event Happening: \n",
      " 93.43434343434343\n",
      "\n",
      " AUC: \n",
      " 0.7652486402486403\n",
      "\n",
      " F-Score:\n",
      " 0.9158415841584159\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 31  21]\n",
      " [ 13 185]]\n",
      "Xgboost From PCA\n",
      "[12:39:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.46      0.49        52\n",
      "           1       0.86      0.89      0.88       198\n",
      "\n",
      "    accuracy                           0.80       250\n",
      "   macro avg       0.69      0.68      0.68       250\n",
      "weighted avg       0.79      0.80      0.80       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Vector: \n",
      " [1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1\n",
      " 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0\n",
      " 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 80.0\n",
      "\n",
      " Precision of event Happening: \n",
      " 86.27450980392157\n",
      "\n",
      " Recall of event Happening: \n",
      " 88.88888888888889\n",
      "\n",
      " AUC: \n",
      " 0.6752136752136753\n",
      "\n",
      " F-Score:\n",
      " 0.8756218905472637\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 24  28]\n",
      " [ 22 176]]\n",
      "Explained Variance Ratio of  15  Components:\n",
      "[0.13750464 0.09518379 0.0894483  0.04097621 0.03406102 0.03155075\n",
      " 0.02314092 0.02217984 0.02056116 0.01834488 0.01766604 0.01592611\n",
      " 0.01357762 0.01289251 0.01184907]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60        52\n",
      "           1       0.89      0.89      0.89       198\n",
      "\n",
      "    accuracy                           0.83       250\n",
      "   macro avg       0.75      0.75      0.75       250\n",
      "weighted avg       0.83      0.83      0.83       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1\n",
      " 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 83.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 89.39393939393939\n",
      "\n",
      " Recall of event Happening: \n",
      " 89.39393939393939\n",
      "\n",
      " AUC: \n",
      " 0.74504662004662\n",
      "\n",
      " F-Score:\n",
      " 0.8939393939393939\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 31  21]\n",
      " [ 21 177]]\n",
      "SVM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.44      0.55        52\n",
      "           1       0.87      0.95      0.91       198\n",
      "\n",
      "    accuracy                           0.85       250\n",
      "   macro avg       0.79      0.70      0.73       250\n",
      "weighted avg       0.84      0.85      0.83       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 84.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 86.69724770642202\n",
      "\n",
      " Recall of event Happening: \n",
      " 95.45454545454545\n",
      "\n",
      " AUC: \n",
      " 0.6984265734265734\n",
      "\n",
      " F-Score:\n",
      " 0.9086538461538463\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 23  29]\n",
      " [  9 189]]\n",
      "RM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.54      0.60        52\n",
      "           1       0.88      0.93      0.91       198\n",
      "\n",
      "    accuracy                           0.85       250\n",
      "   macro avg       0.78      0.73      0.75       250\n",
      "weighted avg       0.84      0.85      0.84       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 84.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 88.46153846153845\n",
      "\n",
      " Recall of event Happening: \n",
      " 92.92929292929293\n",
      "\n",
      " AUC: \n",
      " 0.7338772338772339\n",
      "\n",
      " F-Score:\n",
      " 0.9064039408866995\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 28  24]\n",
      " [ 14 184]]\n",
      "Xgboost From PCA\n",
      "[12:39:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.46      0.48        52\n",
      "           1       0.86      0.88      0.87       198\n",
      "\n",
      "    accuracy                           0.80       250\n",
      "   macro avg       0.69      0.67      0.68       250\n",
      "weighted avg       0.79      0.80      0.79       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1\n",
      " 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0\n",
      " 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 79.60000000000001\n",
      "\n",
      " Precision of event Happening: \n",
      " 86.20689655172413\n",
      "\n",
      " Recall of event Happening: \n",
      " 88.38383838383838\n",
      "\n",
      " AUC: \n",
      " 0.6726884226884228\n",
      "\n",
      " F-Score:\n",
      " 0.8728179551122195\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 24  28]\n",
      " [ 23 175]]\n",
      "Explained Variance Ratio of  20  Components:\n",
      "[0.13750464 0.09518379 0.0894483  0.04097621 0.03406102 0.03155075\n",
      " 0.02314092 0.02217984 0.02056116 0.01834489 0.01766605 0.01592611\n",
      " 0.01357776 0.01289392 0.01185156 0.01122039 0.01101717 0.01082133\n",
      " 0.01028134 0.0094322 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.64        52\n",
      "           1       0.90      0.92      0.91       198\n",
      "\n",
      "    accuracy                           0.86       250\n",
      "   macro avg       0.78      0.77      0.78       250\n",
      "weighted avg       0.85      0.86      0.85       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 85.6\n",
      "\n",
      " Precision of event Happening: \n",
      " 90.0990099009901\n",
      "\n",
      " Recall of event Happening: \n",
      " 91.91919191919192\n",
      "\n",
      " AUC: \n",
      " 0.7672882672882674\n",
      "\n",
      " F-Score:\n",
      " 0.91\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 32  20]\n",
      " [ 16 182]]\n",
      "SVM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.50      0.60        52\n",
      "           1       0.88      0.96      0.92       198\n",
      "\n",
      "    accuracy                           0.86       250\n",
      "   macro avg       0.82      0.73      0.76       250\n",
      "weighted avg       0.86      0.86      0.85       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 86.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 87.96296296296296\n",
      "\n",
      " Recall of event Happening: \n",
      " 95.95959595959596\n",
      "\n",
      " AUC: \n",
      " 0.7297979797979798\n",
      "\n",
      " F-Score:\n",
      " 0.9178743961352657\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 26  26]\n",
      " [  8 190]]\n",
      "RM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.60      0.65        52\n",
      "           1       0.90      0.93      0.92       198\n",
      "\n",
      "    accuracy                           0.86       250\n",
      "   macro avg       0.80      0.77      0.78       250\n",
      "weighted avg       0.86      0.86      0.86       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 86.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 89.80582524271846\n",
      "\n",
      " Recall of event Happening: \n",
      " 93.43434343434343\n",
      "\n",
      " AUC: \n",
      " 0.7652486402486403\n",
      "\n",
      " F-Score:\n",
      " 0.9158415841584159\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 31  21]\n",
      " [ 13 185]]\n",
      "Xgboost From PCA\n",
      "[12:39:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.54      0.57        52\n",
      "           1       0.88      0.91      0.90       198\n",
      "\n",
      "    accuracy                           0.83       250\n",
      "   macro avg       0.75      0.72      0.73       250\n",
      "weighted avg       0.83      0.83      0.83       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 83.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 88.23529411764706\n",
      "\n",
      " Recall of event Happening: \n",
      " 90.9090909090909\n",
      "\n",
      " AUC: \n",
      " 0.7237762237762237\n",
      "\n",
      " F-Score:\n",
      " 0.8955223880597014\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 28  24]\n",
      " [ 18 180]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def select_features(X_train, X_test,n):\n",
    "    global pca\n",
    "    # configure to select a subset of features\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    pca = PCA(n_components = n)\n",
    "    X_train_fs = pca.fit_transform(X_train)\n",
    "    X_test_fs = pca.transform(X_test)\n",
    "    return X_train_fs, X_test_fs\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(5,25,5):\n",
    "    X_train_fs, X_test_fs = select_features(X_train, X_test,n)\n",
    "    \n",
    "    print (\"Explained Variance Ratio of \",n,\" Components:\")\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    print(explained_variance)\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(range(n), explained_variance, alpha=0.5, align='center',label='individual explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From PCA\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From PCA\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From PCA\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From PCA\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b191acff",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "- Logistic Regression with PCA performs well with 5 components with an accuracy of 84, precision 88, recall 93.\n",
    "- SVM with PCA performs well with 10 components with an accuracy of 84, precision 86, recall 95.\n",
    "- RF with PCA performs well with 10 components with an accuracy of 86, precision 89, recall 93.\n",
    "- Xgboost with PCA performs well with 20 components with an accuracy of 83, precision 88, recall 90.\n",
    "\n",
    "We concluded that PCA is useful in dimensionality reduction of the dataset as Logistic Regression with 5 componenets perform well from all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea42bb47",
   "metadata": {},
   "source": [
    "# 6- LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cbaf818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAraElEQVR4nO3deVxU9f7H8dcMLrgvYNcEFRcy8ZaRCKYW7qhds67mbl7topma1s2ofpmV1c0Ws8UUcUlLUytUMHfBzA0HBNQQBUUFl1xSMLcEzu8Pr6MEOFgOjM77+Xich3POfM+Zz/mivP2ec+YcE2AgIiLiYMwlXYCIiEhBFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQSpV0ATfr+PHjHDx4sKTLEBGRW6Ru3brcdddd+ZbfdgF18OBBmjdvXtJliIjILWKxWApcrkN8IiLikBRQIiLikBRQIiLikG67c1Aid7pq1aoxZswYvLy8MJlMJV2OyC1hGAYHDhxg8uTJnD59ukjrKKBEHMyYMWOIjY3lrbfeIicnp6TLEbklXFxcePTRRxkzZgzjx48v0jo6xCfiYLy8vFi+fLnCSe4oOTk5/PDDD3h5eRV5HbsF1MyZM/nll1/YuXNnoW0++eQTUlJSSExMxNfX116liNxWTCaTwknuSDk5OTd12NpuAfXll1/SuXPnQt/v0qUL3t7eeHt7M3ToUKZOnWqvUkRE5DZkt3NQP/30E3Xr1i30/e7duzN37lwAYmJiqFq1KjVr1uTYsWP2KknkttRp+NO3dHurp8602WbTpk20atWqyNsMDAzkxRdfpFu3bnTr1g0fHx8mTpxYaPs333yTDRs2sG7dukK382ekpaXh5+fHqVOn/tT6tkRHR/Piiy8SFxdXaJuwsDAmTZrE7t27//Ln2Wt/bmWN9lRiF0l4eHiQnp5unc/IyMDDw0MBJeIAbiac/igyMpLIyMgbtinqSfLbUXBwcEmXcENms9nha7yqxAKqoOOQhlHww32Dg4MZOnQoAO7u7n/5szsNf5rVU2fekj9L0q3aB+2LY+0DQOUa1/6el61Q/pbWef22C3N4fxoe9evh69OECe+8wy9Hj3J/06ZYtm3j2efHkHXiJE/06sW7b77J6cxMLDExlCpTBoBnRo6kSaNGTPx4Ej+ti+KBAH8Mw6BcuXLEbt5C0+Z+fDrpY1atXs3SZZG0b9uO995+m1O//krijh2UKlOGyjXceXnsWM6dO8dnX3wBwJYfN9B7QH8Opaczb84cPGt5ULZsWaaFTefLr74CwGQ2U8ndjctmE1knTlK5hjtZJ07y+JM9een5FyhfoQJ79+xh9EtjKZ1rEBUdTYC/P9kuZiK/+55Jn31K/DYLq9esYcvmzTRr7kdy0m5G/ucFLly4gEvp0lSsVpXKNdyZ9P77PPiAL66urixdFsl/338fgGWLlzDujfHEJyZyOO0A06ZPJ6hTRy5euEjfQU9x4sQJ3NzcmPzBh3h6eADw8rjXiNm2jWrVqjErNBR3N3fi4rdjdnGhkrsbp06dsu7L82NfpKZ7Dd758AOyTpzkmZEj8bnnHl6b8BZzpofhVa8epUuVYvqsmXw66WMq13Dn8P40poROo03rh3n97Qm89vIr1hoL248dsXF8s2ghXToFUapUKQb9+2lSUlOpUKEC77/7X3ybNsXAYPy41wkPD6djx468+eablC1bln379jF48GDOnTv3l/6ulthVfBkZGdSuXds67+npyZEjRwpsGxYWRvPmzWnevDknT54srhJFBLj/vvsYM2YM/q1bUb9+fVoEBFC2bFk+nTSJbt260bnbP6hZs2a+9bLOniUxMZHWLVsC0KVTEFHR0WRnZ1vbXN1O7wED6NztH/ytgBuGFmTk6NEEduxAm04dGfbvYKpVq1ZoWzc3N158/gU6dOjAIx3aExsby4hnnuHQoUNM/uwzpk2bxqhnnyUpKYmo9esBuMfbm+nTp9OqTRuysrL49+DB+bY74d13adOpIy3bBNLqoZY08fHJ16ZihQpY4mJp3bYtm7duYdCAgQBMfPsdpoROo21QJwYOGcxnkz4G4OUXx7IlJoaH27dj+cpV1Lnud+RVSyIj+ec//2md/+fjj7Nw4UIAhgwZQmDHDvj5+THs38FUr179Sh0VK7J7dzItWrRga0xMkffj1KlfeaRDe2bN+ZLnnh0BwEsvvEBWVtaV9m3aEBUVhZubG6+99hodOnSgWbNmxMbG8sILLxT6MymqEguoiIgInnrqKQACAgLIzMzU4T0RB7Q9fjuHDx/GMAwSEhKoU7s29957LwcPHSI1NRWAr7/+usB1Fy5cyD8ffxyAfz7xOOFLl+R5/x5vbw4eOsT+tP1X2n/3bZFqGhYczMboaNauWIGHhwcN6tcvtG2LFi2495572LRpEz9FRTNo0CDqeF75xT933tdUqlSJIYMG8eKLL1rXSc/IYPPmzdZ9axEQkG+7T3Tvzoa16/gpKorGjRpx7z335Gtz6dIlVq5eDUBC4g7q/i9w2jzyCB/89z1+iormm6+u1FCxQgVaPvQQi777DoDVa9cU+IXWU6dOsX//fvyaNaN69ep4N2zApk2bAHjuuefYGB3N1q1b8fDwwNvbG4Ds7GyWLiv4sOuN9iPyh2UAxCcmUqfO1doDCZs1y9rmzJkztGjRAh8fHzZt2kR8fDyDBg264TUIRWW3Q3zz58+nTZs2uLu7k56ezvjx4yldujQAoaGhLF++nK5du5Kamsr58+cZXMD/UESk5F269Lv1dU5ODqVcrvzaKOyQ/PUiIiJ4b+JEqlWtygP3N+XHn37K16aw7WRn52A2X/s/tKurKwCtW7akzSOBdOzalQsXLrBs8RJcy5YttAaTyUT0jz/yZI8e1sNkVw9zlitXDk9PT+DKKON8TnaBNf1xvm6dOox6dgRtO3XkTGYmX3z6GWXLuub77MvXjRZzcnJwKXWl78xmMx27duHixYtF7o/rLVy4kCe6d6dB7TpELl9u7ZcOHTrQsWtXfjmUzoaNG619dvHiRXJzc/Ntx9Z+XPr9ys8+NycHl//93K+cnslbo8lkYs2aNfTr189m7TfDbiOofv36UatWLcqUKUPt2rWZNWsWoaGhhIaGWtuMHDmShg0bcv/999/wqhgRcSzJycnUrVOH+v8bufTt27fAdufOnWN7fDzvvfMOq9aszvdLcm9KCnXr1KHe/7682fOJa4euDqUfoul99wPQ9L77qVunDgCVK1fmzJkzXLhwAe+GDWnerNkNa926dSsB/v40aNAAuBJKV0dcb457nXnz5vHOxImEhYVZ16lTuzYtWrSw7tsfD4tVqlSJc+fPkZmVRY0aNejYvt0Na/ijqPXrGfr0tXOl9/397wBs3rKFJ3v0BKBDu/aFHroMDw/nH1260LdvX8KXLAGu9Mvp06e5cOECjRo1stkvf3Y/otavJ3jItdqrVq3K1q1badWqVZ4+vjp6+yt0qyMRB/fjnG9KuoR8Ll26xOj//IcffviB05mZ/BgdTTU3twLbhi9ZwtxZs+javXuh21k0bz6nfv2VrTExNL73XgAili2jb69e/BQVTXx8PKn79gGwNiqKIYP+xab160lN3YfFxn9uT548ybPPjeKbb76hXIXy5Gbn8O4H71OprCsPPvAAzw4bRkW36nTt2In+ffqyPCKC5D17GDRoEK0feZg9u5MZ9/aEPNvc9fPP7Ni5i5ifNnLg4EFitm27qf576f9e5aP3JrJp/XpKuZRi89YtPD92LO99+AGzQkN57NF1bNy8mUPXXel8vTNnzpC8Zy/3NGzI9vh4a7881bcfm9avZ/fPSTb75c/uxwcfT+LD9yay5ccN5OTmMH7c6yxevJh//etffPPNN5T932j2tddeIyUl5SZ6JT8FlIjkU6lSJSrXcOfHH38kPuln6/JRo0ZZD4+ti46i8aJF+Q6bzV+4IM/80mWRVLmrRp7tP/vcKOvrddFRNG/VMl8NFy9e5IlevQqsr2ffPgUuv9+v4FHDho0b8ff3z1Nr1omTdOjaxTqq6/G/Q4DVylcgNzeX4cOH59u3fzzxeIH7cL3r23jU87K+Xros0noe6Ndff2Xw0PyXep8+fTrPPr/6+rgCPwOg94D+eWr7/fff6dq1a759rFzD3frzLKjGwvbj+r6MT0y0rnPu3DmGjxppfS/rxJUL16Kjo/H39y+03j9D9+ITERGHpIASEbnOwYMHeSjwkZIuQ1BAiTgcwzBwcXEp6TJEbjkXF5ciXaV4lQJKxMEcOHCATh06KKTkjnL1eVAHDhwo8jq6SELEwUyePJl3Pv6IHv/8Z4k9UffC2d8oV6niLftT+3Dn7suFs78Vqd31T9QtKgWUiIM5ffo0S2I2lWgNujeiY+zD7bAvRbk7/p+lQ3wiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQ7BpQQUFBJCcnk5KSQkhISL73K1euTEREBAkJCezatYt//etf9ixHRERuI3YLKLPZzJQpU+jSpQs+Pj707duXxo0b52kzYsQIkpKSeOCBB2jTpg0fffQRpUuXtldJIiJyG7FbQPn7+5OamkpaWhqXL19mwYIFdO/ePU8bwzCoVKkSABUrVuTXX38lOzvbXiWJiMhtxG4B5eHhQXp6unU+IyMDDw+PPG0+//xzGjduzJEjR9i5cyejR4/GMIx82woODsZisWCxWHB3d7dXySIi4kDsFlAmkynfsj+GT1BQEAkJCdSqVYsHHniAzz//3Dqiul5YWBjNmzenefPmnDx50l4li4iIA7FbQGVkZFC7dm3rvKenJ0eOHMnTZvDgwYSHhwOwb98+0tLSuPfee+1VkoiI3EbsFlAWiwVvb2+8vLwoXbo0ffr0ISIiIk+bQ4cO0b59ewDuuusuGjVqxP79++1VkoiI3EZsBpSHhwfh4eEcP36cY8eO8d133+U7l1SQnJwcRo4cyapVq9i9ezeLFi0iKSmJYcOGMWzYMAAmTJhAy5Yt2bFjB+vWrSMkJIRTp0799b0SEZHbXilbDWbPns38+fN58sknARgwYACzZ8+mU6dONje+YsUKVqxYkWdZaGio9fXRo0cJCgq62ZpFRMQJ2BxB1ahRgy+//JKcnBxycnKYM2cONWrUKI7aRETEidkMqJMnT9K/f3/MZjNms5n+/fvrMJyIiNidzYAaMmQIvXr14tixYxw9epSePXsyZMiQ4qhNREScmM1zUOnp6fnuACEiImJvhQbU2LFj+eCDD/j0008LvLvD6NGj7VqYiIg4t0IDavfu3QDExsYWWzEiIiJXFRpQy5YtA+D8+fN89913ed7r2bOnfasSERGnZ/MiiVdeeaVIy0RERG6lQkdQnTt3pmvXrnh4ePDJJ59Yl1euXFmPxBAREbsrNKCOHDlCbGwsjz32GHFxcdblZ8+e5fnnny+W4kRExHkVGlA7duxgx44dzJ8/XyMmEREpdja/B+Xl5cV///tffHx8cHV1tS5v0KCBXQsTERHnZvMiidmzZzN16lSys7Np27Ytc+fO5auvviqO2kRExInZDKhy5coRFRWFyWTi0KFDvPnmm7Rr1644ahMRESdm8xDfxYsXMZlMpKSkMGLECA4fPsxdd91VHLWJiIgTszmCGjNmDOXLl+e5556jWbNmDBgwgEGDBhVHbSIi4sRuOIIym8306tWLl156iXPnzuku5iIiUmxuOILKzc2lWbNmxVWLiIiIlc1zUPHx8SxdupRvv/2Wc+fOWZcvXrzYroWJiIhzsxlQ1atX59SpU3mu3DMMQwElIiJ2ZTOgdN5JRERKgs2r+EREREqCAkpERBySAkpERBySzYC66667mDFjBsuXLwegcePGOi8lIiJ2ZzOgvvzyS1atWkWtWrUA2Lt3L2PGjLF3XSIi4uRsBpS7uzvffvstubm5AOTk5JCTk2P3wkRExLnZDKhz585RvXp1DMMAICAggMzMTLsXJiIizs3m96BeeOEFIiIiaNCgARs3bqRGjRr07NmzOGoTEREnVqRbHQUGBtKoUSNMJhN79uzRI+BFRMTubB7ie/bZZ6lYsSJJSUn8/PPPVKxYkeHDhxdHbSIi4sRsBlRwcHCec05nzpwhODjYrkWJiIjYDCiz2ZxvvkyZMnYrSEREBIpwDmrVqlUsWrSIadOmYRgGzzzzDCtXriyO2kRExInZDKiQkBCGDRvG8OHDMZlMrF69mhkzZhRHbSIi4sRsBpRhGEybNo1p06YVRz0iIiJAEc5BtWzZktWrV7Nnzx727dvH/v372bdvX5E2HhQURHJyMikpKYSEhBTYJjAwkPj4eHbt2sX69etvqngREblz2RxBzZw5k+eff564uLibusWR2WxmypQpdOzYkYyMDCwWCxEREezevdvapkqVKnzxxRd07tyZ9PR0atSo8ef2QkRE7jg2AyozM/NPXRTh7+9PamoqaWlpACxYsIDu3bvnCah+/foRHh5Oeno6ACdOnLjpzxERkTuTzUN80dHRvP/++7Ro0QJfX1/rZIuHh4c1eAAyMjLw8PDI0+aee+6hWrVqREdHExsby8CBAwvcVnBwMBaLBYvFgru7u83PFhGR25/NEVRAQAAAfn5+1mWGYdC+ffsbrmcymfItu3rDWeuHlypFs2bNaN++PeXKlWPLli1s3bqVlJSUPO3CwsIICwsDwGKx2CpZRETuADYDql27dn9qwxkZGdSuXds67+npyZEjR/K1OXnyJOfPn+f8+fNs2LCBpk2b5gsoERFxPjYDCqBr1640adIEV1dX67IJEybccB2LxYK3tzdeXl4cPnyYPn360K9fvzxtli5dyueff46LiwtlypQhICCAjz/++E/shoiI3GlsBtTUqVMpX748bdu2ZcaMGfTs2ZNt27bZ3HBOTg4jR45k1apVuLi4MGvWLJKSkhg2bBgAoaGhJCcns3LlSnbs2EFubi4zZszg559//ut7JSIitz2bAdWyZUuaNm1KYmIib731Fh999BHh4eFF2viKFStYsWJFnmWhoaF55j/88EM+/PDDmyhZREScgc2r+C5cuADA+fPnufvuu7l8+TL16tWze2EiIuLcbI6gli1bRpUqVfjggw/Yvn07hmHoXnwiImJ3NgPq7bffBiA8PJxly5bh6upKVlaW3QsTERHnVmhAtW3blujoaJ544okC31+8eLHdihIRESk0oAIDA4mOjqZbt2753jMMQwElIiJ2VWhAvfHGG5hMJlasWMG3335bnDWJiIjc+Co+wzAYOXJkcdUiIiJiZfMy8zVr1vCf//wHT09PqlWrZp1ERETsyeZVfEOGDAFgxIgR1mWGYdCgQQP7VSUiIk7PZkDVr1+/OOoQERHJo0g3i23SpAk+Pj55bhb71Vdf2a0oERERmwH1+uuv06ZNG3x8fFi+fDldunRh48aNCigREbErmxdJ9OzZk/bt23Ps2DGGDBlC06ZNKVu2bHHUJiIiTqxIN4s1DIPs7GwqVarE8ePHdV5KRETszuYhvtjYWKpUqUJYWBhxcXH89ttvRXoelIiIyF9hM6CuXl4eGhrKypUrqVy5Mjt37rR7YSIi4txsHuJbsmQJffv2pXz58hw8eFDhJCIixcJmQE2aNInWrVuTlJTEokWL6NGjhy6SEBERu7MZUBs2bGDEiBHUr1+f6dOn06tXL44fP14ctYmIiBMr0hd1XV1d6datG7179+bBBx9kzpw59q5LREScnM2AWrBgAQEBAaxcuZIpU6awfv16DMMojtpERMSJ2Qyo2bNn069fP3Jzc4ujHhEREaAIAbVq1ariqENERCQPmxdJiIiIlAQFlIiIOKRCD/H5+vrecMX4+PhbXoyIiMhVhQbURx99BFy5xNzPz4/ExERMJhP3338/MTExPPzww8VWpIiIOJ9CD/G1a9eOdu3acfDgQR588EGaN2+On58fvr6+pKamFmeNIiLihGyeg7r33nvZtWuXdf7nn3/mgQcesGdNIiIiti8z3717N2FhYXz99dcYhsGAAQPYvXt3cdQmIiJOzGZADR48mOHDhzN69Gjgyr35pk6davfCRETEudkMqEuXLjFt2jSWL1/O3r17i6MmERER2+egunXrRkJCAitXrgSgadOmLF261O6FiYiIc7MZUOPHj8ff358zZ84AkJiYiJeXl53LEhERZ2czoLKzs8nKyiqOWkRERKxsBtSuXbvo27cvLi4uNGzYkE8//ZTNmzcXR20iIuLEbAbUqFGjaNKkCZcuXeKbb74hKyuLMWPGFGnjQUFBJCcnk5KSQkhISKHt/Pz8yM7OpkePHkUuXERE7mw2r+K7cOECr732Gq+99tpNbdhsNjNlyhQ6duxIRkYGFouFiIiIfN+hMpvNTJw4UY/1EBGRPGwGlLe3Ny+++CJeXl6UKnWtefv27W+4nr+/P6mpqaSlpQFXnszbvXv3fAE1atQovv/+e5o3b/5n6hcRkTuUzYD69ttvmTZtGjNmzCAnJ6fIG/bw8CA9Pd06n5GRQUBAQJ42tWrV4oknnqBdu3Y3DKjg4GCGDh0KgLu7e5FrEBGR25fNgMrOzmbatGk3vWGTyZRvmWEYeeYnT55MSEiIzcfJh4WFERYWBoDFYrnpWkRE5PZjM6AiIyMZPnw4ixcv5tKlS9blp0+fvuF6GRkZ1K5d2zrv6enJkSNH8rTx8/NjwYIFwJWRUdeuXcnOztYXgUVExHZADRo0CICxY8dalxmGQYMGDW64nsViwdvbGy8vLw4fPkyfPn3o169fnjb169e3vp49ezbLli1TOImICFCEgLo+RG5GTk4OI0eOZNWqVbi4uDBr1iySkpIYNmwYAKGhoX9quyIi4hwKDai2bdsSHR3NE088UeD7ixcvtrnxFStWsGLFijzLCgumwYMH29yeiIg4j0IDKjAwkOjoaLp165bvPcMwihRQIiIif1ahAfXGG28AMGTIkOKqRURExMrmOSiArl270qRJE1xdXa3LJkyYYLeiREREbN6Lb+rUqfTu3ZtRo0ZhMpl48sknqVu3bnHUJiIiTsxmQLVs2ZJBgwZx+vRp3nrrLR566KE8328SERGxB5sBdeHCBQDOnz/P3XffzeXLl6lXr57dCxMREedm8xzUsmXLqFKlCh988AHbt2/HMAxmzJhRHLWJiIgTsxlQb7/9NgDh4eEsW7YMV1dXPWFXRETsrtCAKuwLulfpe1AiImJPhQZUQV/QvUpf1BUREXsrNKD0BV0RESlJNq/iq169Op988glxcXHExsYyefJkqlevXhy1iYiIE7MZUAsWLODEiRP06NGDnj17cuLECRYuXFgctYmIiBMr0gjq7bff5sCBAxw4cIB33nmHqlWrFkNpIiLizGwGVHR0NL1798ZkMllvdfTDDz8UR20iIuLEbAbUsGHDmD9/PpcuXeLSpUssWLCAF154gaysLDIzM4ujRhERcUI2v6hbuXLl4qhDREQkD5sjqD9ebm42m3n99dftVpCIiAgUIaDat2/PDz/8QM2aNfn73//O1q1bqVSpUnHUJiIiTszmIb7+/fvTq1cvdu7cyfnz5+nbty+bN28ujtpERMSJ2RxBNWzYkNGjR/P9999z4MABBg4cSLly5YqjNhERcWI2AyoyMpJx48bxzDPPEBgYSEpKChaLpThqExERJ2bzEJ+/vz9nz561zk+aNImIiAi7FiUiIlLoCGrs2LEAnD17lp49e+Z5b/DgwfatSkREnF6hAdWnTx/r61deeSXPe507d7ZfRSIiItwgoEwmU4GvC5oXERG51QoNKMMwCnxd0LyIiMitVuhFEk2bNiUzMxOTyUS5cuWs990zmUy4uroWW4EiIuKcCg2oUqVsXuAnIiJiNza/ByUiIlISFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQFFAiIuKQ7BpQQUFBJCcnk5KSQkhISL73+/XrR2JiIomJiWzatIn777/fnuWIiMhtxG7fxjWbzUyZMoWOHTuSkZGBxWIhIiKC3bt3W9ukpaURGBjImTNn6Ny5M9OnT6dFixb2KklERG4jdhtB+fv7k5qaSlpaGpcvX2bBggV07949T5stW7Zw5swZALZu3Yqnp6e9yhERkduM3QLKw8OD9PR063xGRgYeHh6Ftn/66adZsWJFge8FBwdjsViwWCy4u7vf8lpFRMTx2O0QX0GP5CjsLuht2rTh6aefpnXr1gW+HxYWRlhYGIAeNy8i4iTsFlAZGRnUrl3bOu/p6cmRI0fytbvvvvuYMWMGXbp04ddff7VXOSIicpux2yE+i8WCt7c3Xl5elC5dmj59+hAREZGnTe3atQkPD2fgwIGkpKTYqxQREbkN2W0ElZOTw8iRI1m1ahUuLi7MmjWLpKQkhg0bBkBoaCivv/46bm5ufPHFFwBkZ2fTvHlze5UkIiK3Ebs+9GnFihX5LnwIDQ21vg4ODiY4ONieJYiIyG1Kd5IQERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHpIASERGHZNeACgoKIjk5mZSUFEJCQgps88knn5CSkkJiYiK+vr72LEdERG4jdgsos9nMlClT6NKlCz4+PvTt25fGjRvnadOlSxe8vb3x9vZm6NChTJ061V7liIjIbcZuAeXv709qaippaWlcvnyZBQsW0L179zxtunfvzty5cwGIiYmhatWq1KxZ014liYjIbcQEGPbYcI8ePejcuTPBwcEADBgwgICAAEaNGmVtExkZyXvvvcemTZsAWLt2LSEhIcTFxeXZVnBwMEOHDgWgUaNG7Nmz5y/V5u7uzsmTJ//SNu4k6o9r1BfXqC+uUV9cY4++qFu3LnfddVe+5aVu6adcx2Qy5VtmGMZNtwEICwsjLCzsltVmsVho3rz5Ldve7U79cY364hr1xTXqi2uKsy/sdogvIyOD2rVrW+c9PT05cuTITbcRERHnZLeAslgseHt74+XlRenSpenTpw8RERF52kRERPDUU08BEBAQQGZmJseOHbNXSSIichux2yG+nJwcRo4cyapVq3BxcWHWrFkkJSUxbNgwAEJDQ1m+fDldu3YlNTWV8+fPM3jwYHuVk8f06dOL5XNuF+qPa9QX16gvrlFfXFOcfWG3iyRERET+Ct1JQkREHJICSkREHJLTBVRRbr90J5k5cya//PILO3futC6rVq0aq1evZu/evaxevZqqVata33v55ZdJSUkhOTmZTp06lUDF9uPp6UlUVBRJSUns2rWL5557DnDO/ihbtiwxMTEkJCSwa9cu3njjDcA5++Iqs9nM9u3biYyMBJy3L9LS0tixYwfx8fFYLBagZPvCcJbJbDYbqampRr169YzSpUsbCQkJRuPGjUu8LntODz/8sOHr62vs3LnTumzixIlGSEiIARghISHGe++9ZwBG48aNjYSEBKNMmTKGl5eXkZqaapjN5hLfh1s11axZ0/D19TUAo2LFisaePXuMxo0bO21/VKhQwQCMUqVKGVu3bjUCAgKcti8A4/nnnzfmzZtnREZGGuC8/07S0tIMNze3PMtKsC9KvkOKa2rRooWxcuVK6/zLL79svPzyyyVel72nunXr5gmo5ORko2bNmgZc+aWdnJxcYH+sXLnSaNGiRYnXb69pyZIlRocOHZy+P8qVK2fExcUZ/v7+TtsXHh4extq1a422bdtaA8pZ+6KggCqpvnCqQ3weHh6kp6db5zMyMvDw8CjBikrG3/72N+v3zY4dO2a9xYgz9U/dunXx9fUlJibGafvDbDYTHx/P8ePHWbNmDdu2bXPavpg8eTIvvfQSubm51mXO2heGYbB69WpiY2Ott6orqb6w2/egHFFRb63krJylfypUqMD333/PmDFjOHv2bKHt7vT+yM3NxdfXlypVqrB48WKaNGlSaNs7uS8effRRjh8/zvbt2wkMDLTZ/k7uC4BWrVpx9OhRatSowZo1a0hOTi60rb37wqlGULq10hW//PKL9a7xNWvW5Pjx44Bz9E+pUqX4/vvvmTdvHosXLwacuz8AMjMzWb9+PZ07d3bKvmjVqhWPPfYYaWlpLFiwgHbt2vHVV185ZV8AHD16FIATJ06wePFi/P39S7QvSvyYZ3FNLi4uxr59+wwvLy/rRRI+Pj4lXpe9pz+eg3r//ffznPCcOHGiARg+Pj55Tnju27fvjjr5Cxhz5swxPv744zzLnLE/3N3djSpVqhiA4erqamzYsMF49NFHnbIvrp8CAwOt56CcsS/Kly9vVKxY0fp606ZNRlBQUEn2Rcl3SnFOXbp0Mfbs2WOkpqYar776aonXY+9p/vz5xpEjR4zff//dSE9PN4YMGWJUr17dWLt2rbF3715j7dq1RrVq1aztX331VSM1NdVITk42OnfuXOL138qpVatWhmEYRmJiohEfH2/Ex8cbXbp0ccr+uO+++4zt27cbiYmJxs6dO41x48YZgFP2xfXT9QHljH1Rr149IyEhwUhISDB27dpl/R1ZUn2hWx2JiIhDcqpzUCIicvtQQImIiENSQImIiENSQImIiENSQImIiENSQMkdITs7m/j4eHbu3MmiRYsoV65cge02bdr0p7bfrFkzPvnkkz9d343uWHEnGT16dKF9L3KzdJm53BHOnj1LpUqVAPj666+Ji4vj448/tr5vNpvz3GetuF1f350sLS0NPz8/Tp06VdKlyB1AIyi54/z00080bNiQwMBAoqKimDdvnvV5WFdHMoGBgURHR/Ptt9+ye/duvv76a+v6fn5+bNq0iYSEBGJiYqhYsSKBgYHW5wSNHz+euXPnsm7dOvbu3cu///1v4Mo9/tauXUtcXBw7duzgscces1nrwIEDSUxMJCEhgblz5wJQp04d1q5dS2JiImvXrrXeSmb27Nl88cUXREVFsW/fPh555BFmzpxJUlISs2fPtm7z7NmzfPjhh8TFxbF27Vrc3d0BaNq0KVu2bCExMZHw8HDrM32io6N57733iImJYc+ePbRu3Rq4Eurvv/8+27ZtIzExkaFDh96w70aNGkWtWrWIjo4mKioKs9nM7Nmz2blzJzt27GDMmDE3/8MUp1fi317WpOmvTmfPnjXgyu2slixZYjzzzDNGYGCg8dtvvxleXl752gUGBhpnzpwxPDw8DJPJZGzevNlo1aqVUbp0aWPfvn2Gn5+fARiVKlUyXFxc8txhYPz48UZCQoLh6upquLm5GYcOHTLuvvtuw8XFxahUqZIBGG5ubkZKSkq+z71+8vHxMZKTk62PNrj67fyIiAjjqaeeMgBj8ODBxuLFiw3AmD17tvHNN98YgPHYY48ZmZmZxt///nfDZDIZsbGxRtOmTQ3AMAzD6NevnwEY48aNMz777DMDMBITE41HHnnEAIw333zTesun6Oho48MPPzTgyp1W1qxZYwBGcHCw8X//938GYJQpU8awWCyGl5dXoX0HeR/V8OCDDxqrV6+27u/VWytp0lTUSSMouSOUK1eO+Ph4YmNjOXToEDNnzgRg27ZtHDhwoMB1tm3bxuHDhzEMg4SEBLy8vGjUqBFHjx4lNjYWuDIaycnJybfu0qVLuXjxIqdOnSI6Ohp/f39MJhPvvvuudeTj4eHB3/72t0JrbteuHd999531cNjp06cBeOihh5g/fz4AX331lXVEA1hHcTt37uSXX35h165dGIbBzz//jJeXFwA5OTksXLgQuHK4s3Xr1lSuXJmqVauyYcMGAObMmcMjjzxi3W54eDgAcXFx1u106tSJp556ivj4eGJiYnBzc8Pb27vQvvuj/fv3U79+fT799FOCgoLIysoqtC9ECuJUj9uQO9eFCxfw9fXNt/zcuXOFrnPp0iXr65ycHEqVKoXJZCrS4wL+2MYwDPr370+NGjVo1qwZ2dnZpKWl4erqWug2/sxnXa05Nzc3T/25ubmUKlXwP+eifMbVbV3th6v1jRo1itWrV+dpGxgYWGDf/dGZM2do2rQpQUFBjBgxgl69evH000/brEXkKo2gRK6TnJxMrVq18PPzA6BixYq4uLjka9e9e3fKli1L9erVadOmDRaLhSpVqnD8+HGys7Np06ZNgaOK661bt45evXpRvXp1AKpVqwbA5s2b6dOnDwD9+/dn48aNN7UPLi4u9OzZE4B+/fqxceNGsrKyOH36tHU0NnDgQH788ccbbmfVqlUMHz7cGj7e3t6UL1/+hutcfzGIm5sbZrOZ8PBwxo0bx4MPPnhT+yGiEZTIdS5fvkzv3r357LPPKFeuHBcuXKBDhw752m3bto0ffviBOnXqMGHCBI4ePcq8efOIjIzEYrGQkJDA7t27b/hZSUlJvPPOO/z444/k5OQQHx/P4MGDee6555g1axZjx47lxIkTDB48+Kb24bfffqNJkybExsaSmZlJ7969ARg0aBDTpk2jfPny7N+/3+Z2Z8yYgZeXF9u3b8dkMnHixAkef/zxG64zffp0VqxYwdGjRxkzZgyzZ8/GbL7y/+BXXnnlpvZDRJeZi9yk8ePH89tvv/HRRx+VdCkFcpZL2uXOp0N8IiLikDSCEhERh6QRlIiIOCQFlIiIOCQFlIiIOCQFlIiIOCQFlIiIOKT/Bzt6Vwh5tsFoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "sc = StandardScaler()\n",
    "y_train = y_train.to_numpy(dtype='int')\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "X_train = lda.fit_transform(X_train,y_train)\n",
    "X_test = lda.transform(X_test)\n",
    "explained_variance = lda.explained_variance_ratio_\n",
    "print(explained_variance)\n",
    "with plt.style.context('dark_background'):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(range(len(X_train)), explained_variance, alpha=0.5, align='center',label='individual explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f54b8863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio\n",
      "[0.13750464 0.09518379 0.0894483  0.04097621 0.03406102 0.03155075\n",
      " 0.02314092 0.02217984 0.02056116 0.01834489 0.01766605 0.01592611\n",
      " 0.01357776 0.01289392 0.01185156 0.01122039 0.01101717 0.01082133\n",
      " 0.01028134 0.0094322 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From LDA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.77      0.57        52\n",
      "           1       0.93      0.76      0.83       198\n",
      "\n",
      "    accuracy                           0.76       250\n",
      "   macro avg       0.69      0.76      0.70       250\n",
      "weighted avg       0.83      0.76      0.78       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1\n",
      " 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0\n",
      " 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1\n",
      " 0 1 1 0 1 0 0 1 1 0 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1\n",
      " 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 76.0\n",
      "\n",
      " Precision of event Happening: \n",
      " 92.5925925925926\n",
      "\n",
      " Recall of event Happening: \n",
      " 75.75757575757575\n",
      "\n",
      " AUC: \n",
      " 0.7634032634032634\n",
      "\n",
      " F-Score:\n",
      " 0.8333333333333334\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 40  12]\n",
      " [ 48 150]]\n",
      "SVM From LDA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.62      0.51        52\n",
      "           1       0.89      0.79      0.84       198\n",
      "\n",
      "    accuracy                           0.76       250\n",
      "   macro avg       0.66      0.70      0.67       250\n",
      "weighted avg       0.79      0.76      0.77       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1\n",
      " 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1\n",
      " 1 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0\n",
      " 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1\n",
      " 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1\n",
      " 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 75.6\n",
      "\n",
      " Precision of event Happening: \n",
      " 88.70056497175142\n",
      "\n",
      " Recall of event Happening: \n",
      " 79.29292929292929\n",
      "\n",
      " AUC: \n",
      " 0.7041569541569541\n",
      "\n",
      " F-Score:\n",
      " 0.8373333333333334\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 32  20]\n",
      " [ 41 157]]\n",
      "RM From LDA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.77      0.57        52\n",
      "           1       0.93      0.76      0.83       198\n",
      "\n",
      "    accuracy                           0.76       250\n",
      "   macro avg       0.69      0.76      0.70       250\n",
      "weighted avg       0.83      0.76      0.78       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1\n",
      " 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0\n",
      " 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1\n",
      " 0 1 1 0 1 0 0 1 1 0 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1\n",
      " 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 76.0\n",
      "\n",
      " Precision of event Happening: \n",
      " 92.5925925925926\n",
      "\n",
      " Recall of event Happening: \n",
      " 75.75757575757575\n",
      "\n",
      " AUC: \n",
      " 0.7634032634032634\n",
      "\n",
      " F-Score:\n",
      " 0.8333333333333334\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 40  12]\n",
      " [ 48 150]]\n",
      "Xgboost From LDA\n",
      "[13:18:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.77      0.57        52\n",
      "           1       0.93      0.76      0.83       198\n",
      "\n",
      "    accuracy                           0.76       250\n",
      "   macro avg       0.69      0.76      0.70       250\n",
      "weighted avg       0.83      0.76      0.78       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1\n",
      " 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0\n",
      " 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1\n",
      " 0 1 1 0 1 0 0 1 1 0 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1\n",
      " 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 76.0\n",
      "\n",
      " Precision of event Happening: \n",
      " 92.5925925925926\n",
      "\n",
      " Recall of event Happening: \n",
      " 75.75757575757575\n",
      "\n",
      " AUC: \n",
      " 0.7634032634032634\n",
      "\n",
      " F-Score:\n",
      " 0.8333333333333334\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 40  12]\n",
      " [ 48 150]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.0,\n",
       " 'precision': 92.5925925925926,\n",
       " 'recall': 75.75757575757575,\n",
       " 'auc_val': 0.7634032634032634,\n",
       " 'f_score': 0.8333333333333334,\n",
       " 'model_obj': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "               gamma=0, gpu_id=-1, importance_type=None,\n",
       "               interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
       "               max_depth=6, min_child_weight=1, missing=nan,\n",
       "               monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "               num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "               reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "               tree_method='exact', validate_parameters=1, verbosity=None)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_features(X_train, X_test,y_train):\n",
    "    global lda\n",
    "    # configure to select a subset of features\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    y_train = y_train.to_numpy(dtype='int')\n",
    "    lda = LinearDiscriminantAnalysis(solver='svd')\n",
    "    X_train_fs = lda.fit_transform(X_train,y_train)\n",
    "    X_test_fs = lda.transform(X_test)\n",
    "    return X_train_fs, X_test_fs\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "\n",
    "X_train_fs, X_test_fs  = select_features(X_train, X_test,y_train)\n",
    "    \n",
    "print (\"Explained Variance Ratio\")\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(range(len(explained_variance)), explained_variance, alpha=0.5, align='center',label='individual explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "    # fit the model\n",
    "print (\"Logistic Regression From LDA\")\n",
    "LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "print (\"SVM From LDA\")\n",
    "SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "print (\"RM From LDA\")\n",
    "RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "print (\"Xgboost From LDA\")\n",
    "XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e60597c",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "TSNE doesnot perform on less number of components. It doesnot reduce the dimensionality of dataset.\n",
    "Logistic Regression, Xgboost, RF all perform well with 20 components except SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ebd3d",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "266ed3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.79      1.00      0.88       198\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.40      0.50      0.44       250\n",
      "weighted avg       0.63      0.79      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 79.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.2\n",
      "\n",
      " Recall of event Happening: \n",
      " 100.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.8839285714285714\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  0  52]\n",
      " [  0 198]]\n",
      "SVM From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.79      1.00      0.88       198\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.40      0.50      0.44       250\n",
      "weighted avg       0.63      0.79      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 79.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.2\n",
      "\n",
      " Recall of event Happening: \n",
      " 100.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.8839285714285714\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  0  52]\n",
      " [  0 198]]\n",
      "RM From TSNE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.15      0.15        52\n",
      "           1       0.77      0.76      0.77       198\n",
      "\n",
      "    accuracy                           0.63       250\n",
      "   macro avg       0.46      0.46      0.46       250\n",
      "weighted avg       0.64      0.63      0.64       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1\n",
      " 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1\n",
      " 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 63.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 77.31958762886599\n",
      "\n",
      " Recall of event Happening: \n",
      " 75.75757575757575\n",
      "\n",
      " AUC: \n",
      " 0.45571095571095566\n",
      "\n",
      " F-Score:\n",
      " 0.7653061224489796\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  8  44]\n",
      " [ 48 150]]\n",
      "Xgboost From TSNE\n",
      "[12:54:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.06      0.07        52\n",
      "           1       0.78      0.86      0.82       198\n",
      "\n",
      "    accuracy                           0.69       250\n",
      "   macro avg       0.44      0.46      0.44       250\n",
      "weighted avg       0.63      0.69      0.66       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 69.19999999999999\n",
      "\n",
      " Precision of event Happening: \n",
      " 77.6255707762557\n",
      "\n",
      " Recall of event Happening: \n",
      " 85.85858585858585\n",
      "\n",
      " AUC: \n",
      " 0.45813908313908314\n",
      "\n",
      " F-Score:\n",
      " 0.8153477218225419\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  3  49]\n",
      " [ 28 170]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.79      1.00      0.88       198\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.40      0.50      0.44       250\n",
      "weighted avg       0.63      0.79      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 79.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.2\n",
      "\n",
      " Recall of event Happening: \n",
      " 100.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.8839285714285714\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  0  52]\n",
      " [  0 198]]\n",
      "SVM From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.79      0.96      0.86       198\n",
      "\n",
      "    accuracy                           0.76       250\n",
      "   macro avg       0.39      0.48      0.43       250\n",
      "weighted avg       0.62      0.76      0.68       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 76.0\n",
      "\n",
      " Precision of event Happening: \n",
      " 78.51239669421489\n",
      "\n",
      " Recall of event Happening: \n",
      " 95.95959595959596\n",
      "\n",
      " AUC: \n",
      " 0.4797979797979798\n",
      "\n",
      " F-Score:\n",
      " 0.8636363636363636\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  0  52]\n",
      " [  8 190]]\n",
      "RM From TSNE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.76      0.84      0.80       198\n",
      "\n",
      "    accuracy                           0.66       250\n",
      "   macro avg       0.38      0.42      0.40       250\n",
      "weighted avg       0.60      0.66      0.63       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0\n",
      " 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 66.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 76.14678899082568\n",
      "\n",
      " Recall of event Happening: \n",
      " 83.83838383838383\n",
      "\n",
      " AUC: \n",
      " 0.41919191919191917\n",
      "\n",
      " F-Score:\n",
      " 0.798076923076923\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  0  52]\n",
      " [ 32 166]]\n",
      "Xgboost From TSNE\n",
      "[12:54:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.02      0.02        52\n",
      "           1       0.77      0.86      0.81       198\n",
      "\n",
      "    accuracy                           0.68       250\n",
      "   macro avg       0.40      0.44      0.42       250\n",
      "weighted avg       0.62      0.68      0.65       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Vector: \n",
      " [1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 68.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 76.92307692307693\n",
      "\n",
      " Recall of event Happening: \n",
      " 85.85858585858585\n",
      "\n",
      " AUC: \n",
      " 0.4389083139083139\n",
      "\n",
      " F-Score:\n",
      " 0.81145584725537\n",
      "\n",
      " Confusion Matrix: \n",
      " [[  1  51]\n",
      " [ 28 170]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.40      0.40        52\n",
      "           1       0.84      0.83      0.84       198\n",
      "\n",
      "    accuracy                           0.74       250\n",
      "   macro avg       0.62      0.62      0.62       250\n",
      "weighted avg       0.75      0.74      0.75       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1\n",
      " 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1]\n",
      "\n",
      " Accuracy: \n",
      " 74.4\n",
      "\n",
      " Precision of event Happening: \n",
      " 84.18367346938776\n",
      "\n",
      " Recall of event Happening: \n",
      " 83.33333333333334\n",
      "\n",
      " AUC: \n",
      " 0.6185897435897436\n",
      "\n",
      " F-Score:\n",
      " 0.8375634517766497\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 21  31]\n",
      " [ 33 165]]\n",
      "SVM From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.25      0.31        52\n",
      "           1       0.82      0.90      0.86       198\n",
      "\n",
      "    accuracy                           0.77       250\n",
      "   macro avg       0.61      0.58      0.59       250\n",
      "weighted avg       0.73      0.77      0.75       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 76.8\n",
      "\n",
      " Precision of event Happening: \n",
      " 82.11009174311926\n",
      "\n",
      " Recall of event Happening: \n",
      " 90.40404040404042\n",
      "\n",
      " AUC: \n",
      " 0.577020202020202\n",
      "\n",
      " F-Score:\n",
      " 0.8605769230769231\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 13  39]\n",
      " [ 19 179]]\n",
      "RM From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.23      0.24        52\n",
      "           1       0.80      0.83      0.82       198\n",
      "\n",
      "    accuracy                           0.70       250\n",
      "   macro avg       0.53      0.53      0.53       250\n",
      "weighted avg       0.69      0.70      0.70       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1\n",
      " 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1\n",
      " 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 70.39999999999999\n",
      "\n",
      " Precision of event Happening: \n",
      " 80.3921568627451\n",
      "\n",
      " Recall of event Happening: \n",
      " 82.82828282828282\n",
      "\n",
      " AUC: \n",
      " 0.5295260295260296\n",
      "\n",
      " F-Score:\n",
      " 0.8159203980099502\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 12  40]\n",
      " [ 34 164]]\n",
      "Xgboost From TSNE\n",
      "[12:54:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.33      0.32        52\n",
      "           1       0.82      0.81      0.82       198\n",
      "\n",
      "    accuracy                           0.71       250\n",
      "   macro avg       0.57      0.57      0.57       250\n",
      "weighted avg       0.72      0.71      0.71       250\n",
      "\n",
      "Prediction Vector: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1\n",
      " 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 71.2\n",
      "\n",
      " Precision of event Happening: \n",
      " 82.14285714285714\n",
      "\n",
      " Recall of event Happening: \n",
      " 81.31313131313132\n",
      "\n",
      " AUC: \n",
      " 0.570027195027195\n",
      "\n",
      " F-Score:\n",
      " 0.817258883248731\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 17  35]\n",
      " [ 37 161]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "def select_features(X_train, X_test,n):\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    tsne = TSNE(n_components = n)\n",
    "    X_train_fs = tsne.fit_transform(X_train)\n",
    "    X_test_fs = tsne.fit_transform(X_test)\n",
    "    return X_train_fs, X_test_fs\n",
    " \n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(1,4):\n",
    "    X_train_fs, X_test_fs  = select_features(X_train, X_test,n)\n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From TSNE\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From TSNE\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From TSNE\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From TSNE\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f96bf",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "- Logistic Regression with TSNE performs well with 1 component with an accuracy of 79, precision 79, recall 100.\n",
    "- SVM with TSNE performs well with 1 component with an accuracy of 79, precision 79, recall 100.\n",
    "- RF with TSNE performs well with 3 components with an accuracy of 70, precision 80.3, recall 82.8.\n",
    "- Xgboost with TSNE performs well with 3 components with an accuracy of 71, precision 82, recall 81.\n",
    "\n",
    "We concluded that TSNE is useful in dimensionality reduction of the dataset as Logistic Regression with 1 componenet perform well from all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a09651d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
