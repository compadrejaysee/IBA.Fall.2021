{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b127ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b1e169e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MouseID</th>\n",
       "      <th>DYRK1A_N</th>\n",
       "      <th>ITSN1_N</th>\n",
       "      <th>BDNF_N</th>\n",
       "      <th>NR1_N</th>\n",
       "      <th>NR2A_N</th>\n",
       "      <th>pAKT_N</th>\n",
       "      <th>pBRAF_N</th>\n",
       "      <th>pCAMKII_N</th>\n",
       "      <th>pCREB_N</th>\n",
       "      <th>...</th>\n",
       "      <th>pCFOS_N</th>\n",
       "      <th>SYP_N</th>\n",
       "      <th>H3AcK18_N</th>\n",
       "      <th>EGR1_N</th>\n",
       "      <th>H3MeK4_N</th>\n",
       "      <th>CaNA_N</th>\n",
       "      <th>Genotype</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>309_1</td>\n",
       "      <td>0.503644</td>\n",
       "      <td>0.747193</td>\n",
       "      <td>0.430175</td>\n",
       "      <td>2.816329</td>\n",
       "      <td>5.990152</td>\n",
       "      <td>0.218830</td>\n",
       "      <td>0.177565</td>\n",
       "      <td>2.373744</td>\n",
       "      <td>0.232224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108336</td>\n",
       "      <td>0.427099</td>\n",
       "      <td>0.114783</td>\n",
       "      <td>0.131790</td>\n",
       "      <td>0.128186</td>\n",
       "      <td>1.675652</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>309_2</td>\n",
       "      <td>0.514617</td>\n",
       "      <td>0.689064</td>\n",
       "      <td>0.411770</td>\n",
       "      <td>2.789514</td>\n",
       "      <td>5.685038</td>\n",
       "      <td>0.211636</td>\n",
       "      <td>0.172817</td>\n",
       "      <td>2.292150</td>\n",
       "      <td>0.226972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104315</td>\n",
       "      <td>0.441581</td>\n",
       "      <td>0.111974</td>\n",
       "      <td>0.135103</td>\n",
       "      <td>0.131119</td>\n",
       "      <td>1.743610</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>309_3</td>\n",
       "      <td>0.509183</td>\n",
       "      <td>0.730247</td>\n",
       "      <td>0.418309</td>\n",
       "      <td>2.687201</td>\n",
       "      <td>5.622059</td>\n",
       "      <td>0.209011</td>\n",
       "      <td>0.175722</td>\n",
       "      <td>2.283337</td>\n",
       "      <td>0.230247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106219</td>\n",
       "      <td>0.435777</td>\n",
       "      <td>0.111883</td>\n",
       "      <td>0.133362</td>\n",
       "      <td>0.127431</td>\n",
       "      <td>1.926427</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MouseID  DYRK1A_N   ITSN1_N    BDNF_N     NR1_N    NR2A_N    pAKT_N  \\\n",
       "0   309_1  0.503644  0.747193  0.430175  2.816329  5.990152  0.218830   \n",
       "1   309_2  0.514617  0.689064  0.411770  2.789514  5.685038  0.211636   \n",
       "2   309_3  0.509183  0.730247  0.418309  2.687201  5.622059  0.209011   \n",
       "\n",
       "    pBRAF_N  pCAMKII_N   pCREB_N  ...   pCFOS_N     SYP_N  H3AcK18_N  \\\n",
       "0  0.177565   2.373744  0.232224  ...  0.108336  0.427099   0.114783   \n",
       "1  0.172817   2.292150  0.226972  ...  0.104315  0.441581   0.111974   \n",
       "2  0.175722   2.283337  0.230247  ...  0.106219  0.435777   0.111883   \n",
       "\n",
       "     EGR1_N  H3MeK4_N    CaNA_N  Genotype  Treatment  Behavior   class  \n",
       "0  0.131790  0.128186  1.675652   Control  Memantine       C/S  c-CS-m  \n",
       "1  0.135103  0.131119  1.743610   Control  Memantine       C/S  c-CS-m  \n",
       "2  0.133362  0.127431  1.926427   Control  Memantine       C/S  c-CS-m  \n",
       "\n",
       "[3 rows x 82 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"D:\\\\Ayesha\\\\IBA Data Science\\\\Semester 3\\\\ML II\\\\Data_Cortex_Nuclear.xls\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402563e5",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING AND ENCODING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14a1b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions for data processing\n",
    "\n",
    "def encoding(df):\n",
    "    \n",
    "    code = {'Control':1,\n",
    "            'Ts65Dn':0,\n",
    "            'Memantine':1,\n",
    "            'Saline':0,\n",
    "            'C/S':0,\n",
    "            'S/C':1,\n",
    "            'c-CS-m':0,\n",
    "            'c-SC-m':1,\n",
    "            'c-CS-s':2,\n",
    "            'c-SC-s':3,\n",
    "            't-CS-m':4,\n",
    "            't-SC-m':5,\n",
    "            't-CS-s':6,\n",
    "            't-SC-s':7,\n",
    "           }\n",
    "    for col in df.select_dtypes('object'):\n",
    "        df.loc[:,col]=df[col].map(code)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def imputation(df):\n",
    "    \n",
    "    #df = df.dropna(axis=0)\n",
    "    df = df.fillna(df.mean())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def feature_engineering(df):\n",
    "    useless_columns = ['MouseID']\n",
    "    for feature in useless_columns:\n",
    "        if feature in df:\n",
    "            df = df.drop(feature,axis=1)\n",
    "    return df\n",
    "\n",
    "def standard_scale(data):\n",
    "    \n",
    "    \"\"\" This function is used to standardize the data frame \"\"\"\n",
    "    \n",
    "    df_scaled=pd.DataFrame(StandardScaler().fit_transform(data.iloc[:,:-1]),columns=list(data.columns[:-1]))# Standardize the feature\n",
    "    data=pd.concat((df_scaled,data[\"class\"]),axis=1) #Concat with label\n",
    "    return data\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b5f310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    df = encoding(df)\n",
    "    df = feature_engineering(df)\n",
    "    df = imputation(df)\n",
    "    df= standard_scale(df)\n",
    "    \n",
    "    X = df.drop('class',axis=1)\n",
    "    y = df['class'].astype(int)\n",
    "      \n",
    "    return df,X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f059544c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DYRK1A_N</th>\n",
       "      <th>ITSN1_N</th>\n",
       "      <th>BDNF_N</th>\n",
       "      <th>NR1_N</th>\n",
       "      <th>NR2A_N</th>\n",
       "      <th>pAKT_N</th>\n",
       "      <th>pBRAF_N</th>\n",
       "      <th>pCAMKII_N</th>\n",
       "      <th>pCREB_N</th>\n",
       "      <th>pELK_N</th>\n",
       "      <th>...</th>\n",
       "      <th>pCFOS_N</th>\n",
       "      <th>SYP_N</th>\n",
       "      <th>H3AcK18_N</th>\n",
       "      <th>EGR1_N</th>\n",
       "      <th>H3MeK4_N</th>\n",
       "      <th>CaNA_N</th>\n",
       "      <th>Genotype</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.312711</td>\n",
       "      <td>0.517934</td>\n",
       "      <td>2.253669</td>\n",
       "      <td>1.497362</td>\n",
       "      <td>2.304365</td>\n",
       "      <td>-0.345019</td>\n",
       "      <td>-0.158601</td>\n",
       "      <td>-0.899902</td>\n",
       "      <td>0.604115</td>\n",
       "      <td>0.691475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987371</td>\n",
       "      <td>-0.285744</td>\n",
       "      <td>-1.011615</td>\n",
       "      <td>-1.416624</td>\n",
       "      <td>-1.607891</td>\n",
       "      <td>1.065901</td>\n",
       "      <td>0.945905</td>\n",
       "      <td>0.945905</td>\n",
       "      <td>-1.028175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.356798</td>\n",
       "      <td>0.286501</td>\n",
       "      <td>1.880279</td>\n",
       "      <td>1.420009</td>\n",
       "      <td>1.976769</td>\n",
       "      <td>-0.518126</td>\n",
       "      <td>-0.334523</td>\n",
       "      <td>-0.963018</td>\n",
       "      <td>0.442658</td>\n",
       "      <td>0.359831</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.162114</td>\n",
       "      <td>-0.067645</td>\n",
       "      <td>-1.063458</td>\n",
       "      <td>-1.325218</td>\n",
       "      <td>-1.546844</td>\n",
       "      <td>1.280291</td>\n",
       "      <td>0.945905</td>\n",
       "      <td>0.945905</td>\n",
       "      <td>-1.028175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.334966</td>\n",
       "      <td>0.450465</td>\n",
       "      <td>2.012928</td>\n",
       "      <td>1.124860</td>\n",
       "      <td>1.909149</td>\n",
       "      <td>-0.581298</td>\n",
       "      <td>-0.226891</td>\n",
       "      <td>-0.969835</td>\n",
       "      <td>0.543335</td>\n",
       "      <td>0.284600</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.079366</td>\n",
       "      <td>-0.155059</td>\n",
       "      <td>-1.065130</td>\n",
       "      <td>-1.373257</td>\n",
       "      <td>-1.623595</td>\n",
       "      <td>1.857038</td>\n",
       "      <td>0.945905</td>\n",
       "      <td>0.945905</td>\n",
       "      <td>-1.028175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.065474</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>0.802123</td>\n",
       "      <td>0.489481</td>\n",
       "      <td>1.219245</td>\n",
       "      <td>-0.247424</td>\n",
       "      <td>-0.199461</td>\n",
       "      <td>-1.071196</td>\n",
       "      <td>-0.171236</td>\n",
       "      <td>0.357061</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.860192</td>\n",
       "      <td>-0.818989</td>\n",
       "      <td>-0.723367</td>\n",
       "      <td>-0.984718</td>\n",
       "      <td>-1.218364</td>\n",
       "      <td>1.144490</td>\n",
       "      <td>0.945905</td>\n",
       "      <td>0.945905</td>\n",
       "      <td>-1.028175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036682</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.805692</td>\n",
       "      <td>0.197652</td>\n",
       "      <td>0.939202</td>\n",
       "      <td>-0.482759</td>\n",
       "      <td>-0.304516</td>\n",
       "      <td>-1.085341</td>\n",
       "      <td>-0.627671</td>\n",
       "      <td>0.162107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.884881</td>\n",
       "      <td>-0.179502</td>\n",
       "      <td>-0.943378</td>\n",
       "      <td>-1.181435</td>\n",
       "      <td>-1.187585</td>\n",
       "      <td>1.583530</td>\n",
       "      <td>0.945905</td>\n",
       "      <td>0.945905</td>\n",
       "      <td>-1.028175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DYRK1A_N   ITSN1_N    BDNF_N     NR1_N    NR2A_N    pAKT_N   pBRAF_N  \\\n",
       "0  0.312711  0.517934  2.253669  1.497362  2.304365 -0.345019 -0.158601   \n",
       "1  0.356798  0.286501  1.880279  1.420009  1.976769 -0.518126 -0.334523   \n",
       "2  0.334966  0.450465  2.012928  1.124860  1.909149 -0.581298 -0.226891   \n",
       "3  0.065474 -0.000103  0.802123  0.489481  1.219245 -0.247424 -0.199461   \n",
       "4  0.036682  0.001305  0.805692  0.197652  0.939202 -0.482759 -0.304516   \n",
       "\n",
       "   pCAMKII_N   pCREB_N    pELK_N  ...   pCFOS_N     SYP_N  H3AcK18_N  \\\n",
       "0  -0.899902  0.604115  0.691475  ... -0.987371 -0.285744  -1.011615   \n",
       "1  -0.963018  0.442658  0.359831  ... -1.162114 -0.067645  -1.063458   \n",
       "2  -0.969835  0.543335  0.284600  ... -1.079366 -0.155059  -1.065130   \n",
       "3  -1.071196 -0.171236  0.357061  ... -0.860192 -0.818989  -0.723367   \n",
       "4  -1.085341 -0.627671  0.162107  ... -0.884881 -0.179502  -0.943378   \n",
       "\n",
       "     EGR1_N  H3MeK4_N    CaNA_N  Genotype  Treatment  Behavior  class  \n",
       "0 -1.416624 -1.607891  1.065901  0.945905   0.945905 -1.028175      0  \n",
       "1 -1.325218 -1.546844  1.280291  0.945905   0.945905 -1.028175      0  \n",
       "2 -1.373257 -1.623595  1.857038  0.945905   0.945905 -1.028175      0  \n",
       "3 -0.984718 -1.218364  1.144490  0.945905   0.945905 -1.028175      0  \n",
       "4 -1.181435 -1.187585  1.583530  0.945905   0.945905 -1.028175      0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data.copy() #making copy of oringnal data and apply data preprocessing functions on it \n",
    "df,X,y = preprocessing(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e822b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('class',axis=1)\n",
    "Y=df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b06a459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validationmetrics(model, testX, testY, verbose=True):  \n",
    "    global predictions\n",
    "    \n",
    "    predictions = model.predict(testX)\n",
    "    \n",
    "    if model.__class__.__module__.startswith('lightgbm'):\n",
    "        for i in range(0, predictions.shape[0]):\n",
    "            predictions[i]= 1 if predictions[i] >= 0.5 else 0\n",
    "    \n",
    "    #Accuracy\n",
    "    accuracy = accuracy_score(testY, predictions)*100\n",
    "    \n",
    "    result1 = classification_report(testY, predictions)\n",
    "    print(\"Classification Report:\",)\n",
    "    print (result1)\n",
    "    \n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Prediction Vector: \\n\", predictions)\n",
    "        print(\"\\n Accuracy: \\n\", accuracy)\n",
    "    \n",
    "        #confusion Matrix\n",
    "        print(\"\\n Confusion Matrix: \\n\", confusion_matrix(testY, predictions,labels=[0,1,2,3,4,5,6,7]))\n",
    "    \n",
    "    res_map = {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"model_obj\": model\n",
    "              }\n",
    "    \n",
    "    return res_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f38a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogReg(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf  = LogisticRegression()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def SVM(trainX, testX, trainY, testY, svmtype=\"SVC\", verbose=True, clf=None):\n",
    "    # for one vs all\n",
    "    if not clf:\n",
    "        if svmtype == \"Linear\":\n",
    "            clf = svm.LinearSVC()\n",
    "        else:\n",
    "            clf = svm.SVC()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def RandomForest(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf  = RandomForestClassifier()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def XgBoost(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf = XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "    clf.fit(trainX,trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a09fc5",
   "metadata": {},
   "source": [
    "# Random Forest Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f23601a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Treatment     0.117243\n",
       "Genotype      0.113524\n",
       "SOD1_N        0.050694\n",
       "Behavior      0.045989\n",
       "pERK_N        0.030286\n",
       "                ...   \n",
       "Bcatenin_N    0.003066\n",
       "pCFOS_N       0.002771\n",
       "CREB_N        0.002436\n",
       "EGR1_N        0.002360\n",
       "MEK_N         0.001967\n",
       "Length: 80, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "model.fit(X,Y)\n",
    "pd.Series(model.feature_importances_,index=X.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77b873b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SOD1_N', 'pPKCG_N', 'Genotype', 'Treatment', 'Behavior'], dtype='object')\n",
      "Logistic Regression From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "RM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From Random Forest Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:43:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       0.97      1.00      0.98        28\n",
      "           7       1.00      0.98      0.99        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 6 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 99.71988795518207\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  1 45]]\n",
      "Index(['DYRK1A_N', 'pCAMKII_N', 'pERK_N', 'SOD1_N', 'pPKCG_N', 'Ubiquitin_N',\n",
      "       'CaNA_N', 'Genotype', 'Treatment', 'Behavior'],\n",
      "      dtype='object')\n",
      "Logistic Regression From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "RM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From Random Forest Selection\n",
      "[17:43:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      0.96      0.98        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       0.93      1.00      0.97        42\n",
      "           4       1.00      0.91      0.96        47\n",
      "           5       0.98      1.00      0.99        47\n",
      "           6       0.90      1.00      0.95        28\n",
      "           7       0.98      0.96      0.97        46\n",
      "\n",
      "    accuracy                           0.98       357\n",
      "   macro avg       0.97      0.98      0.98       357\n",
      "weighted avg       0.98      0.98      0.98       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 6 0 5\n",
      " 0 2 3 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 5 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 3 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 7 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 6\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 6 4 7 4 6 7 7 0 6 1 4 0 3 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 97.75910364145658\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 48  0  1  0  1  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 43  0  3  1]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  2  0  0  0 44]]\n",
      "Index(['DYRK1A_N', 'pCAMKII_N', 'pERK_N', 'pPKCAB_N', 'APP_N', 'SOD1_N',\n",
      "       'pPKCG_N', 'ARC_N', 'Tau_N', 'Ubiquitin_N', 'pS6_N', 'CaNA_N',\n",
      "       'Genotype', 'Treatment', 'Behavior'],\n",
      "      dtype='object')\n",
      "Logistic Regression From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "RM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From Random Forest Selection\n",
      "[17:43:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        53\n",
      "           1       1.00      0.98      0.99        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       0.91      1.00      0.95        42\n",
      "           4       1.00      0.96      0.98        47\n",
      "           5       0.98      1.00      0.99        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       0.98      0.91      0.94        46\n",
      "\n",
      "    accuracy                           0.98       357\n",
      "   macro avg       0.98      0.98      0.98       357\n",
      "weighted avg       0.98      0.98      0.98       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 3 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 5 2 3 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 7 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 0\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 3 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 3 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 98.0392156862745\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 49  0  1  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 1  0  0  0 45  0  0  1]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  3  0  1  0 42]]\n",
      "Index(['DYRK1A_N', 'ITSN1_N', 'pCAMKII_N', 'pERK_N', 'pPKCAB_N', 'BRAF_N',\n",
      "       'APP_N', 'SOD1_N', 'pP70S6_N', 'pGSK3B_N', 'pPKCG_N', 'S6_N', 'ARC_N',\n",
      "       'Tau_N', 'Ubiquitin_N', 'pS6_N', 'CaNA_N', 'Genotype', 'Treatment',\n",
      "       'Behavior'],\n",
      "      dtype='object')\n",
      "Logistic Regression From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "RM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From Random Forest Selection\n",
      "[17:43:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      0.98      0.99        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       0.93      1.00      0.97        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      0.96      0.98        46\n",
      "\n",
      "    accuracy                           0.99       357\n",
      "   macro avg       0.99      0.99      0.99       357\n",
      "weighted avg       0.99      0.99      0.99       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 3 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 3 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 3 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 99.15966386554622\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 49  0  1  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  2  0  0  0 44]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_features(X_train, y_train, X_test,n):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectFromModel(RandomForestClassifier(n_estimators=100),threshold=-np.inf, max_features=n)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    selected_feat= X_train.columns[(fs.get_support())]\n",
    "    print(selected_feat)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    " \n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(5,25,5):\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test,n)\n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From Random Forest Selection\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From Random Forest Selection\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From Random Forest Selection\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From Random Forest Selection\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11914295",
   "metadata": {},
   "source": [
    "# Xgboost Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89ba3205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:43:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pMTOR_N       0.060030\n",
       "H3AcK18_N     0.058091\n",
       "BRAF_N        0.056664\n",
       "Genotype      0.053601\n",
       "Treatment     0.048841\n",
       "                ...   \n",
       "ELK_N         0.000000\n",
       "ERK_N         0.000000\n",
       "GSK3B_N       0.000000\n",
       "JNK_N         0.000000\n",
       "Bcatenin_N    0.000000\n",
       "Length: 80, dtype: float32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= XGBClassifier(n_estimators=100,random_state=0)\n",
    "model.fit(X,Y)\n",
    "pd.Series(model.feature_importances_,index=X.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf6934bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:43:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Index(['TRKA_N', 'pNUMB_N', 'TIAM1_N', 'pPKCG_N', 'Genotype'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.51      0.58        53\n",
      "           1       0.57      0.82      0.67        50\n",
      "           2       0.47      0.41      0.44        44\n",
      "           3       0.85      0.79      0.81        42\n",
      "           4       0.51      0.51      0.51        47\n",
      "           5       0.83      0.85      0.84        47\n",
      "           6       0.30      0.21      0.25        28\n",
      "           7       0.77      0.89      0.83        46\n",
      "\n",
      "    accuracy                           0.64       357\n",
      "   macro avg       0.62      0.62      0.62       357\n",
      "weighted avg       0.64      0.64      0.63       357\n",
      "\n",
      "Prediction Vector: \n",
      " [0 5 3 2 4 2 0 1 0 3 7 1 3 5 5 3 4 5 1 0 7 1 5 3 1 2 4 2 4 2 1 5 7 2 4 0 5\n",
      " 2 1 7 1 6 5 0 1 1 4 1 2 5 3 7 1 2 1 4 7 3 2 4 3 2 0 3 2 7 1 1 4 0 1 2 4 0\n",
      " 2 0 1 5 0 5 1 4 2 7 6 0 1 7 1 1 1 1 5 5 0 3 4 6 1 0 1 3 6 3 7 4 2 1 5 7 5\n",
      " 3 7 7 1 3 0 3 7 5 1 7 7 1 1 5 3 1 4 7 3 5 6 4 1 5 5 4 2 7 1 5 7 5 1 2 5 6\n",
      " 1 4 2 4 6 0 0 4 0 3 7 7 5 7 7 2 6 5 4 1 3 1 1 1 7 2 1 1 0 0 1 3 5 1 0 3 3\n",
      " 2 1 1 3 7 5 6 5 7 1 1 1 7 4 2 5 0 1 6 3 5 5 6 1 5 7 0 4 2 1 4 0 5 1 3 7 2\n",
      " 3 3 0 5 0 0 4 3 7 7 0 1 7 7 6 1 2 1 1 5 1 2 3 7 5 2 1 3 0 4 1 3 4 0 6 4 1\n",
      " 4 7 2 2 1 3 4 3 2 6 4 1 7 5 5 2 1 7 4 3 2 5 7 2 5 0 6 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 4 7 7 6 5 5 4 4 6 4 5 0 7 1 3 4 7 0 7 7 0 7 3 0 1 1 1 1 1 5 0 6 5 7 3\n",
      " 4 4 4 7 4 4 7 7 2 6 1 4 0 7 1 6 2 3 0 2 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 64.42577030812325\n",
      "\n",
      " Confusion Matrix: \n",
      " [[27 13 13  0  0  0  0  0]\n",
      " [ 2 41  1  6  0  0  0  0]\n",
      " [11 15 18  0  0  0  0  0]\n",
      " [ 0  3  6 33  0  0  0  0]\n",
      " [ 0  0  0  0 24  7 12  4]\n",
      " [ 0  0  0  0  5 40  2  0]\n",
      " [ 0  0  0  0 14  0  6  8]\n",
      " [ 0  0  0  0  4  1  0 41]]\n",
      "SVM From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.69        53\n",
      "           1       0.61      0.86      0.72        50\n",
      "           2       0.77      0.55      0.64        44\n",
      "           3       0.82      0.79      0.80        42\n",
      "           4       0.69      0.81      0.75        47\n",
      "           5       0.91      0.91      0.91        47\n",
      "           6       0.77      0.36      0.49        28\n",
      "           7       0.85      0.98      0.91        46\n",
      "\n",
      "    accuracy                           0.76       357\n",
      "   macro avg       0.77      0.74      0.74       357\n",
      "weighted avg       0.77      0.76      0.75       357\n",
      "\n",
      "Prediction Vector: \n",
      " [0 5 3 0 6 2 0 1 0 3 7 1 3 5 5 3 6 4 1 0 4 1 5 3 3 2 4 2 4 2 1 5 7 1 4 0 5\n",
      " 2 1 7 1 4 5 0 3 1 4 1 0 5 1 7 3 2 1 4 7 3 2 4 3 0 0 1 2 7 1 1 4 0 1 0 6 0\n",
      " 0 0 1 5 2 5 1 4 0 7 4 2 3 7 1 3 1 1 5 4 0 3 4 6 1 0 1 3 4 3 7 4 2 1 5 7 5\n",
      " 3 7 7 1 3 0 3 7 5 1 7 7 2 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 3 5 7 5 1 2 4 6\n",
      " 1 4 0 5 4 0 0 7 1 3 7 7 5 7 4 2 4 5 4 1 1 1 1 1 7 2 1 1 1 0 1 1 5 1 0 3 3\n",
      " 0 1 2 3 7 5 4 5 7 2 1 1 7 4 2 4 0 1 7 3 5 4 4 1 5 7 0 4 2 0 7 0 5 1 3 7 2\n",
      " 3 3 0 5 0 0 7 3 7 7 0 1 7 7 4 1 0 1 3 5 1 2 1 7 7 2 1 3 0 6 2 3 4 0 6 4 1\n",
      " 7 7 0 2 1 3 7 1 2 4 4 1 4 5 5 1 1 7 4 1 2 5 7 2 5 0 4 7 6 5 4 1 2 4 4 7 4\n",
      " 5 4 4 7 7 4 5 5 5 4 5 5 5 2 5 1 3 4 6 2 7 7 0 6 3 1 1 1 1 1 1 5 0 5 5 7 3\n",
      " 4 4 4 7 4 4 7 7 0 6 3 4 0 7 0 4 0 3 0 0 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 75.91036414565826\n",
      "\n",
      " Confusion Matrix: \n",
      " [[35 13  5  0  0  0  0  0]\n",
      " [ 0 43  0  7  0  0  0  0]\n",
      " [ 9 11 24  0  0  0  0  0]\n",
      " [ 4  3  2 33  0  0  0  0]\n",
      " [ 0  0  0  0 38  3  3  3]\n",
      " [ 0  0  0  0  4 43  0  0]\n",
      " [ 0  0  0  0 13  0 10  5]\n",
      " [ 0  0  0  0  0  1  0 45]]\n",
      "RM From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82        53\n",
      "           1       0.65      0.70      0.67        50\n",
      "           2       0.84      0.73      0.78        44\n",
      "           3       0.79      0.88      0.83        42\n",
      "           4       0.83      0.83      0.83        47\n",
      "           5       0.94      0.94      0.94        47\n",
      "           6       0.68      0.75      0.71        28\n",
      "           7       0.93      0.87      0.90        46\n",
      "\n",
      "    accuracy                           0.81       357\n",
      "   macro avg       0.81      0.81      0.81       357\n",
      "weighted avg       0.82      0.81      0.81       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 0 3 5 5 3 6 4 0 0 4 1 5 3 1 2 6 2 5 2 2 5 7 0 4 0 5\n",
      " 0 1 7 1 6 5 0 3 1 5 1 0 5 1 7 3 3 1 4 6 3 2 4 3 0 0 1 2 6 1 1 6 0 2 0 6 0\n",
      " 0 0 1 4 2 5 1 4 0 7 4 0 1 6 0 3 1 3 5 5 2 3 4 6 0 0 0 3 4 3 7 4 2 1 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 7 3 1 6 4 3 5 6 4 1 5 5 4 2 6 3 4 7 5 1 2 4 6\n",
      " 1 4 3 5 4 0 0 6 1 3 7 4 5 7 4 2 6 5 4 1 3 1 1 1 7 2 1 1 2 0 1 1 5 1 0 3 3\n",
      " 3 1 2 3 7 5 6 5 7 2 1 1 7 4 2 5 0 1 7 3 5 4 4 2 5 7 0 4 2 2 7 0 5 2 3 7 2\n",
      " 3 3 0 5 0 2 7 3 4 7 0 0 7 6 4 0 3 1 3 5 1 2 1 6 7 3 1 3 0 6 2 3 6 0 4 6 0\n",
      " 6 7 0 2 1 3 7 1 2 4 4 1 6 5 5 0 1 7 4 1 2 5 7 2 4 0 4 7 4 5 4 1 2 6 4 7 4\n",
      " 5 4 4 7 7 4 5 5 5 5 5 5 5 2 5 1 3 6 6 2 7 6 0 6 3 2 1 1 1 1 1 5 2 7 5 7 3\n",
      " 6 4 4 7 4 4 7 7 0 6 3 4 0 7 2 4 3 3 0 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.23249299719888\n",
      "\n",
      " Confusion Matrix: \n",
      " [[42  7  3  1  0  0  0  0]\n",
      " [ 5 35  2  8  0  0  0  0]\n",
      " [ 3  8 32  1  0  0  0  0]\n",
      " [ 0  4  1 37  0  0  0  0]\n",
      " [ 0  0  0  0 39  2  5  1]\n",
      " [ 0  0  0  0  1 44  0  2]\n",
      " [ 0  0  0  0  7  0 21  0]\n",
      " [ 0  0  0  0  0  1  5 40]]\n",
      "Xgboost From XGboost Selection\n",
      "[17:43:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79        53\n",
      "           1       0.64      0.86      0.74        50\n",
      "           2       0.82      0.70      0.76        44\n",
      "           3       0.79      0.74      0.77        42\n",
      "           4       0.73      0.79      0.76        47\n",
      "           5       0.86      0.89      0.88        47\n",
      "           6       0.56      0.50      0.53        28\n",
      "           7       0.93      0.85      0.89        46\n",
      "\n",
      "    accuracy                           0.77       357\n",
      "   macro avg       0.77      0.76      0.76       357\n",
      "weighted avg       0.78      0.77      0.77       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 4 1 3 5 5 3 6 4 1 0 4 1 5 3 1 0 6 2 4 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 6 5 0 3 1 5 1 0 5 1 7 1 2 1 4 6 3 0 4 3 2 0 1 2 6 1 1 7 0 1 0 4 0\n",
      " 0 0 1 6 2 5 1 4 0 7 4 2 1 4 1 3 1 3 5 5 0 1 4 5 0 0 1 3 4 1 7 4 2 1 5 7 5\n",
      " 3 3 7 1 3 2 3 7 5 1 7 7 0 1 4 3 1 6 4 3 5 6 4 1 5 5 4 2 6 3 5 7 5 1 2 4 6\n",
      " 2 4 3 5 4 0 0 6 1 3 7 4 5 7 4 2 6 5 4 1 1 1 1 1 7 2 1 1 2 0 1 1 5 1 0 3 3\n",
      " 0 1 2 3 7 5 6 5 7 2 1 1 7 4 2 5 0 1 4 3 5 4 4 2 5 7 0 4 2 2 7 0 5 2 3 7 2\n",
      " 3 3 0 5 0 2 7 3 7 7 0 1 6 6 4 1 0 1 3 5 1 2 1 7 7 2 1 1 0 6 2 3 6 0 4 6 2\n",
      " 6 7 0 2 1 3 7 1 2 4 4 1 4 5 5 1 1 7 4 1 2 5 7 2 5 0 4 7 4 5 4 1 2 6 4 7 4\n",
      " 5 4 4 7 7 4 5 5 5 5 5 5 6 0 5 1 3 6 4 2 7 6 0 4 3 1 1 1 1 1 1 5 2 7 5 7 3\n",
      " 6 4 4 7 4 4 7 7 0 6 3 5 0 7 2 4 3 3 0 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.31092436974791\n",
      "\n",
      " Confusion Matrix: \n",
      " [[39  9  5  0  0  0  0  0]\n",
      " [ 0 43  0  7  0  0  0  0]\n",
      " [ 6  7 31  0  0  0  0  0]\n",
      " [ 1  8  2 31  0  0  0  0]\n",
      " [ 0  0  0  0 37  5  5  0]\n",
      " [ 0  0  0  0  3 42  1  1]\n",
      " [ 0  0  0  0 11  1 14  2]\n",
      " [ 0  0  0  1  0  1  5 39]]\n",
      "[17:43:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pRSK_N', 'TRKA_N', 'P38_N', 'AMPKA_N', 'pNUMB_N', 'TIAM1_N', 'pPKCG_N',\n",
      "       'Genotype', 'Treatment', 'Behavior'],\n",
      "      dtype='object')\n",
      "Logistic Regression From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "RM From XGboost Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From XGboost Selection\n",
      "[17:43:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      0.93      0.96        28\n",
      "           7       0.96      1.00      0.98        46\n",
      "\n",
      "    accuracy                           0.99       357\n",
      "   macro avg       0.99      0.99      0.99       357\n",
      "weighted avg       0.99      0.99      0.99       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 7 2 7 6 0 7 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 99.43977591036415\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 26  2]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "[17:43:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pPKCAB_N', 'pRSK_N', 'BRAF_N', 'TRKA_N', 'P38_N', 'pMTOR_N', 'DSCR1_N',\n",
      "       'AMPKA_N', 'pNUMB_N', 'TIAM1_N', 'pPKCG_N', 'IL1B_N', 'Genotype',\n",
      "       'Treatment', 'Behavior'],\n",
      "      dtype='object')\n",
      "Logistic Regression From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "RM From XGboost Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From XGboost Selection\n",
      "[17:43:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       0.98      1.00      0.99        44\n",
      "           3       1.00      0.98      0.99        42\n",
      "           4       0.98      0.98      0.98        47\n",
      "           5       0.96      0.98      0.97        47\n",
      "           6       0.96      0.89      0.93        28\n",
      "           7       0.96      0.98      0.97        46\n",
      "\n",
      "    accuracy                           0.98       357\n",
      "   macro avg       0.98      0.98      0.98       357\n",
      "weighted avg       0.98      0.98      0.98       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 5 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 5 0 0 1 1 4 3 7 4 2 0 5 6 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 4 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 2 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 7 2 7 6 0 7 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 98.0392156862745\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  1 41  0  0  0  0]\n",
      " [ 0  0  0  0 46  1  0  0]\n",
      " [ 0  0  0  0  1 46  0  0]\n",
      " [ 0  0  0  0  0  1 25  2]\n",
      " [ 0  0  0  0  0  0  1 45]]\n",
      "[17:43:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pPKCAB_N', 'pRSK_N', 'BRAF_N', 'TRKA_N', 'SOD1_N', 'P38_N', 'pMTOR_N',\n",
      "       'DSCR1_N', 'AMPKA_N', 'pNUMB_N', 'TIAM1_N', 'pP70S6_N', 'pPKCG_N',\n",
      "       'ARC_N', 'IL1B_N', 'H3AcK18_N', 'CaNA_N', 'Genotype', 'Treatment',\n",
      "       'Behavior'],\n",
      "      dtype='object')\n",
      "Logistic Regression From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "RM From XGboost Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From XGboost Selection\n",
      "[17:43:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       0.98      1.00      0.99        50\n",
      "           2       0.98      1.00      0.99        44\n",
      "           3       0.95      0.98      0.96        42\n",
      "           4       0.96      1.00      0.98        47\n",
      "           5       0.96      0.96      0.96        47\n",
      "           6       1.00      0.89      0.94        28\n",
      "           7       0.95      0.91      0.93        46\n",
      "\n",
      "    accuracy                           0.97       357\n",
      "   macro avg       0.97      0.97      0.97       357\n",
      "weighted avg       0.97      0.97      0.97       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 3 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 1 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 5 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 4\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 4 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 5 7 4 0 3 2 1 5 0 2 3 7 7 2 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 7 2 7 6 0 7 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 3 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 97.19887955182072\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  1 41  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  1  0  0  1 45  0  0]\n",
      " [ 0  0  0  0  1  0 25  2]\n",
      " [ 0  0  0  2  0  2  0 42]]\n"
     ]
    }
   ],
   "source": [
    "def select_features(X_train, y_train, X_test,n):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectFromModel(XGBClassifier(n_estimators=100),threshold=-np.inf, max_features=n)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    selected_feat= X_train.columns[(fs.get_support())]\n",
    "    print(selected_feat)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(5,25,5):\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test,n)\n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From XGboost Selection\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From XGboost Selection\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From XGboost Selection\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From XGboost Selection\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e8e3e4",
   "metadata": {},
   "source": [
    "# RFE Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f549c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc6ac828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['H3MeK4_N', 'CaNA_N', 'Genotype', 'Treatment', 'Behavior'], dtype='object')\n",
      "Logistic Regression From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "RM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From RFE Selection\n",
      "[17:43:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       0.98      1.00      0.99        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      0.98      0.99        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 1 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 99.71988795518207\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  1  0  0  0 46  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Index(['pS6_N', 'pCFOS_N', 'SYP_N', 'H3AcK18_N', 'EGR1_N', 'H3MeK4_N',\n",
      "       'CaNA_N', 'Genotype', 'Treatment', 'Behavior'],\n",
      "      dtype='object')\n",
      "Logistic Regression From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "RM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From RFE Selection\n",
      "[17:43:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Index(['Ubiquitin_N', 'pGSK3B_Tyr216_N', 'SHH_N', 'BAD_N', 'BCL2_N', 'pS6_N',\n",
      "       'pCFOS_N', 'SYP_N', 'H3AcK18_N', 'EGR1_N', 'H3MeK4_N', 'CaNA_N',\n",
      "       'Genotype', 'Treatment', 'Behavior'],\n",
      "      dtype='object')\n",
      "Logistic Regression From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "RM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From RFE Selection\n",
      "[17:43:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Index(['IL1B_N', 'P3525_N', 'pCASP9_N', 'PSD95_N', 'SNCA_N', 'Ubiquitin_N',\n",
      "       'pGSK3B_Tyr216_N', 'SHH_N', 'BAD_N', 'BCL2_N', 'pS6_N', 'pCFOS_N',\n",
      "       'SYP_N', 'H3AcK18_N', 'EGR1_N', 'H3MeK4_N', 'CaNA_N', 'Genotype',\n",
      "       'Treatment', 'Behavior'],\n",
      "      dtype='object')\n",
      "Logistic Regression From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "RM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From RFE Selection\n",
      "[17:43:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       0.98      1.00      0.99        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      0.98      0.99        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 1 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 99.71988795518207\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  1  0  0  0 46  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n"
     ]
    }
   ],
   "source": [
    "def select_features(X_train, y_train, X_test,n):\n",
    "    # configure to select a subset of features\n",
    "    fs = RFE(estimator = DecisionTreeClassifier(), n_features_to_select = n)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    selected_feat= X_train.columns[(fs.get_support())]\n",
    "    print(selected_feat)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(5,25,5):\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test,n)\n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From RFE Selection\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From RFE Selection\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From RFE Selection\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From RFE Selection\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e00be3",
   "metadata": {},
   "source": [
    "# Lasso Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "323bc3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0798e781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DYRK1A_N', 'ITSN1_N', 'Genotype', 'Treatment', 'Behavior'], dtype='object')\n",
      "Logistic Regression From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "RM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From L1 Based Feature Selection\n",
      "[17:43:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       0.96      0.98      0.97        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       0.98      1.00      0.99        42\n",
      "           4       1.00      0.96      0.98        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           0.99       357\n",
      "   macro avg       0.99      0.99      0.99       357\n",
      "weighted avg       0.99      0.99      0.99       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 1 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 3 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 1 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 99.15966386554622\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 49  0  1  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  2  0  0 45  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Index(['DYRK1A_N', 'ITSN1_N', 'BDNF_N', 'NR1_N', 'NR2A_N', 'pAKT_N', 'pBRAF_N',\n",
      "       'Genotype', 'Treatment', 'Behavior'],\n",
      "      dtype='object')\n",
      "Logistic Regression From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       0.98      1.00      0.99        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      0.98      0.99        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 2 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 99.71988795518207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  1  0  0  0  0 45]]\n",
      "RM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From L1 Based Feature Selection\n",
      "[17:43:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      0.98      0.99        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       0.98      1.00      0.99        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 3 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 99.71988795518207\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 49  0  1  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Index(['DYRK1A_N', 'ITSN1_N', 'BDNF_N', 'NR1_N', 'NR2A_N', 'pAKT_N', 'pBRAF_N',\n",
      "       'pCAMKII_N', 'pCREB_N', 'pELK_N', 'pERK_N', 'pJNK_N', 'Genotype',\n",
      "       'Treatment', 'Behavior'],\n",
      "      dtype='object')\n",
      "Logistic Regression From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From L1 Based Feature Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       0.98      1.00      0.99        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      0.98      0.99        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 2 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 99.71988795518207\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  1  0  0  0  0 45]]\n",
      "RM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From L1 Based Feature Selection\n",
      "[17:43:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      0.98      0.99        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 0\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 99.71988795518207\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 1  0  0  0 46  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Index(['DYRK1A_N', 'ITSN1_N', 'BDNF_N', 'NR1_N', 'NR2A_N', 'pAKT_N', 'pBRAF_N',\n",
      "       'pCAMKII_N', 'pCREB_N', 'pELK_N', 'pERK_N', 'pJNK_N', 'PKCA_N',\n",
      "       'pMEK_N', 'pNR1_N', 'pNR2A_N', 'pNR2B_N', 'Genotype', 'Treatment',\n",
      "       'Behavior'],\n",
      "      dtype='object')\n",
      "Logistic Regression From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       0.98      1.00      0.99        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      0.98      0.99        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 2 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 99.71988795518207\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  1  0  0  0  0 45]]\n",
      "RM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From L1 Based Feature Selection\n",
      "[17:43:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n"
     ]
    }
   ],
   "source": [
    "def select_features(X_train, y_train, X_test,n):\n",
    "    # configure to select a subset of features\n",
    "    # Use L1 penalty\n",
    "    estimator = LassoCV(cv=5, normalize = True)\n",
    "    fs = SelectFromModel(estimator,threshold=-np.inf, max_features=n)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    selected_feat= X_train.columns[(fs.get_support())]\n",
    "    print(selected_feat)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(5,25,5):\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test,n)\n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From L1 Based Feature Selection\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From L1 Based Feature Selection\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From L1 Based Feature Selection\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From L1 Based Feature Selection\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6842197",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab211142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.46876729e-01 1.75223526e-01 9.72894173e-02 7.37966586e-02\n",
      " 5.07545175e-02 4.39520936e-02 3.64207918e-02 2.99914110e-02\n",
      " 2.36663750e-02 2.05569520e-02 1.70214793e-02 1.39979068e-02\n",
      " 1.25589051e-02 1.06392519e-02 1.05776329e-02 9.11779878e-03\n",
      " 8.95927534e-03 7.93386446e-03 6.30350095e-03 6.06581552e-03\n",
      " 5.73952194e-03 5.50834549e-03 5.06887188e-03 5.00538714e-03\n",
      " 4.67466426e-03 4.27139949e-03 4.02978949e-03 3.90257958e-03\n",
      " 3.76580702e-03 3.36783978e-03 3.21336291e-03 3.01336687e-03\n",
      " 2.87442401e-03 2.69637110e-03 2.45100376e-03 2.22191774e-03\n",
      " 2.12279956e-03 2.09755227e-03 1.93547890e-03 1.84554421e-03\n",
      " 1.81236728e-03 1.68702965e-03 1.60594165e-03 1.42397405e-03\n",
      " 1.38894147e-03 1.33449052e-03 1.23530006e-03 1.16785030e-03\n",
      " 1.14412743e-03 1.13361173e-03 9.87629664e-04 9.29960811e-04\n",
      " 8.72917427e-04 8.08753072e-04 8.05639615e-04 7.77847004e-04\n",
      " 7.19815492e-04 7.02656933e-04 6.70994780e-04 6.40843464e-04\n",
      " 6.10856068e-04 5.38222187e-04 5.12591536e-04 5.00746088e-04\n",
      " 4.73662793e-04 4.55827733e-04 4.15838985e-04 3.99720349e-04\n",
      " 3.88728225e-04 3.46302677e-04 3.24397817e-04 2.94550873e-04\n",
      " 2.61086860e-04 2.36589987e-04 2.14633575e-04 2.03511611e-04\n",
      " 1.83391388e-04 1.69609321e-04 1.09109659e-04 4.86878499e-32]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAArwElEQVR4nO3deVQUZ6IF8NsNKCCCCq5gbDWMERMRZdFggjuiR0lGo6ijRB1cxo1EE5KZuEXnTZysJk+RoBKN+wIJqAgaSdylQWgggEJsFyIqGkVcR+B7fzDUE1m6Ubop6fs7p86hq7+vuF1OuFPV1dUKAAJEREQyo6zvAERERFVhQRERkSyxoIiISJZYUEREJEssKCIikiXz+g5Ql65du4YLFy7UdwwiIqqFDh06oFWrVpXWN6iCunDhAjw8POo7BhER1YJara5yPU/xERGRLLGgiIhIllhQREQkSw3qPSiihqB58+YIDg6GSqWCQqGo7zhEdUIIgfPnz+Orr77CzZs39Z9nqMXX11dkZ2eLnJwcERISUun58ePHC41GIzQajTh27Jjo3r279JxWqxVpaWkiJSVFqNVqvX6fvuO4cJHzsnTpUjFixAhhZmZW71m4cKmrxczMTIwcOVIsXbq00nM1/O02TBilUilyc3NFx44dhYWFhUhNTRVdu3atMKZPnz6iWbNmAoAYOnSoOHnypPScVqsV9vb2tfqdLCguDWHZsGEDy4lLg1zMzMzEhg0bKq2v7m+3wd6D8vT0RG5uLrRaLR49eoRt27bB39+/wpgTJ07g1q1bAICTJ0/CycnJUHGInhsKhQIlJSX1HYOozpWUlNTqtLXBCsrR0RGXLl2SHufl5cHR0bHa8VOnTkVsbKz0WAiB+Ph4JCUlISgoqNp5QUFBUKvVUKvVcHBwqJvwRERU7wx2kURVLSmEqHJsv379MHXqVPTt21da5+3tjfz8fLRs2RIHDhxAdnY2jhw5UmlueHg4wsPDAVT/YS+i59mQmVPrdHvxoet0jjl27Bi8vb313qaPjw8WLFiAESNGYMSIEXBxccGKFSuqHb906VIcPnwYP/30U7XbeRparRbu7u64cePGU83XJSEhAQsWLEBycnK1Y8LDw/HFF18gKyvrmX+foV5PXWY0JIMVVF5eHtq3by89dnJywuXLlyuNe+WVV7B27Vr4+fnhjz/+kNbn5+cDAAoKChAVFQVPT88qC4qI6l5tyulJMTExiImJqXHM4sWLn3r7clfTGR85UCqVss9YzmCn+NRqNZydnaFSqWBhYYGAgABER0dXGNO+fXtERkZi4sSJyMnJkdZbW1vDxsZG+nnIkCHIyMgwVFTJkJlTKyxEpqqoqAhA2RFNQkICdu7ciaysLGzatEka4+vri6ysLBw5cgR//vOfpfWBgYH45ptvYGtrC61WK51NsbKywsWLF2Fubo6IiAiMGjWqxu0sXrwY8+fPlx6np6ejQ4cOAICoqCgkJSUhIyNDrz+2gwcPxvHjx5GcnIwdO3agSZMmeOGFF3D27FnY29tDoVDg8OHDGDx4MDp06ICsrCx899130Gg02LlzJ6ysrCptc/Xq1VCr1cjIyMCSJUuk9QkJCejVq5e0H5cvX47U1FScOHFCut+cg4MDdu3ahcTERCQmJuLVV18FALRo0QJxcXE4ffo01qxZU+WZqBkzZlQ4Og0MDMTXX39d434pKirC0qVLcfLkSfTp06dCxupeh1arxZIlS5CcnIy0tDR06dIFANCkSROsX78eaWlp0Gg00r9ZVfv4WRmsoEpKSjB79mzExcUhKysLO3bsQGZmJqZPn47p06cDABYtWgR7e3usXr0aKSkp0im61q1b4+jRo0hNTUViYiL27t2LuLg4Q0Ulohq4ubkhODgYLi4u6NSpE7y9vdG4cWOEh4djxIgReO2119CmTZtK827fvg2NRgMfHx8AwIgRIxAXF4fi4mJpjD7bqcqUKVPg7u4Od3d3zJ07Fy1atKh2rL29PT766CMMGjQIvXr1QlJSEt59911cvHgRK1aswJo1azB//nxkZmbiwIEDAICXXnoJ3377LVxdXXH79m387W9/q7Tdf/zjH/Dw8ED37t3h4+ODV155pdIYGxsbnDx5Ej169MDhw4el0li5ciW+/PJLeHp6YtSoUVi7di2AslI+evQoevbsiejoaKmQH7dr164KRT527Fhs3769xv1iY2ODjIwM9O7dG8eOHdP7dVy/fh29evVCaGgoFixYAABYuHAhCgsL0b17d7i6uuLQoUPV7uNnZdAP6sbGxla48AEAwsLCpJ+DgoKq/H8/Wq0WPXr0MGQ0ItJTYmIifv/9dwBAamoqVCoV7ty5A61Wi9zcXADApk2bMG3atEpzt2/fjrFjx+Lnn39GQEAAVq9eXeH5l156Sa/tPGnu3Ll48803AZSdiXF2dsapU6eqHNu7d2+4uLhIf5gbNWqEEydOAADWrVuHt956CzNmzKjwN+fixYs4fvy4lGnu3Ln4/PPPK2x3zJgxmDZtGszNzdG2bVu4uLggPT29wpiHDx9iz549AIDk5GQMHjwYADBo0CC4uLhI42xtbWFjY4PXX39dKp99+/ZVeNuj3PXr13Hu3Dl4eXkhJycHXbp0kV5bdfuluLgYu3fvrnL/1PQ6IiMjpezluQYNGoSAgABp/q1btzB8+PBq9/Gz4J0kiKhGDx8+lH4uKSmBuXnZn43qLnp6XHR0NP71r3+hefPm6NWrFw4dOlRpTHXbKS4uhlL5/yd5LC0tAZSddhw0aBD69OmD+/fvIyEhQXquKgqFAgcOHMD48eMrPWdlZSV9vMXGxgZ37typMtOTj1UqFRYsWAAPDw/cunULERERVWZ49OiR9PPj+06pVKJPnz548OBBpTn67Nft27djzJgxyM7ORlRUFICa98uDBw9QWlpaaTu6Xkf5v/3j2RUKRaWMNe3jZ8F78RFRrWVnZ6Njx47o1KkTAGDcuHFVjrt79y4SExOxcuVK7Nmzp9IfyZq2c/78efTs2RNA2WnGjh07AgDs7Oxw8+ZN3L9/H126dEHv3r1rzHry5El4e3ujc+fOAMpKydnZGQCwYsUKbN68GYsWLZKuBgbKvp+ofLvjxo3D0aNHK2zT1tYWd+/eRWFhIVq1agU/P78aMzwpPj4es2fPlh67uroCAA4fPowJEyYAAIYOHVrtqcvIyEi88cYbGDdunHR6r7b75Wlfx5PZmzVrVuM+fhY8giKSOX0uCze2hw8fYtq0adi7dy+uX7+Oo0eP4uWXX65y7Pbt27Fr1y7pvSh9t7N7925MmjRJen/67NmzAID9+/djxowZ0Gg0OHPmDE6ePFlj1uvXr+Ptt9/G1q1b0bhxYwDARx99hLZt28LDwwPe3t4oLS3FqFGj8PbbbyMhIQGZmZkIDAxEWFgYcnJyEBoaWmGbaWlpSElJwa+//opz585Vel9Hl7lz52LVqlXQaDQwNzfH4cOHMXPmTCxduhRbt27Fn//8Z/zyyy/VfgHrrVu3kJmZCRcXF+m9+9rul6d9HcuXL8eqVauQnp6OkpISLF26FFFRUVXu48cvfnta9X77i7panvVWR0NmTq2w1Pfr4WKay8aNG+s9gykvHTp0EOnp6fWeo6EuVf3v2+i3OiIiInoWLCgiosdcuHChykvGyfhYUEQyI4SAmZlZfccgqnNmZmZ6XaVYjgVFJDPnz5/H8OHDWVLUoJiZmWH48OE4f/683nN4FR+RzHz11VcIDg7GqFGj+I261GA8/o26+mJBEcnMzZs3G/TNVIn0xVN8REQkSywoIiKSJRYUERHJEguKiIhkiQVFRESyxIIiIiJZYkEREZEssaCIiEiWWFBERCRLLCgiIpIlFhQREckSC4qIiGSJBUVERLLEgiIiIlliQRERkSyxoIiISJZYUEREJEssKCIikiUWFBERyRILioiIZIkFRUREssSCIiIiWWJBERGRLLGgiIhIllhQREQkSywoIiKSJYMWlK+vL7Kzs5GTk4OQkJBKz48fPx4ajQYajQbHjh1D9+7d9Z5LREQNm8EKSqlUYtWqVfDz84OLiwvGjRuHrl27Vhij1Wrh4+MDV1dXLFu2DN9++63ec4mIqGEzWEF5enoiNzcXWq0Wjx49wrZt2+Dv719hzIkTJ3Dr1i0AwMmTJ+Hk5KT3XCIiatgMVlCOjo64dOmS9DgvLw+Ojo7Vjp86dSpiY2NrPTcoKAhqtRpqtRoODg51lJ6IiOqbuaE2rFAoKq0TQlQ5tl+/fpg6dSr69u1b67nh4eEIDw8HAKjV6qeNS0REMmOwgsrLy0P79u2lx05OTrh8+XKlca+88grWrl0LPz8//PHHH7WaS0REDZfBTvGp1Wo4OztDpVLBwsICAQEBiI6OrjCmffv2iIyMxMSJE5GTk1OruURE1LAZ7AiqpKQEs2fPRlxcHMzMzLB+/XpkZmZi+vTpAICwsDAsWrQI9vb2WL16NQCguLgYHh4e1c4lIiLToQBQ9Zs7zyG1Wg0PD4+nnj9k5tQKj+ND1z1rJCIi0qG6v906T/E5OjoiMjIS165dw5UrV7Br164ar8YjIiKqCzoLKiIiAtHR0Wjbti0cHR0RExODiIgIY2QjIiITprOgWrZsie+++w4lJSUoKSnBhg0b0LJlS2NkIyIiE6azoK5fv44JEyZAqVRCqVRiwoQJuHHjhjGyERGRCdNZUFOmTMGYMWNw5coV5OfnY/To0ZgyZYoxshERkQnTeZn5pUuXeB88IiIyumoL6r333sOnn36Kr7/+usrbDM2bN8+gwYiIyLRVW1BZWVkAgKSkJKOFISIiKldtQe3ZswcAcO/ePezatavCc6NHjzZsKiIiMnk6L5L48MMP9VpHRERUl6o9gho6dCiGDRsGR0dHrFy5Ulpva2uL4uJio4QjIiLTVW1BXb58GUlJSRg5ciSSk5Ol9UVFRXjnnXeMEo6IiExXtQWVlpaGtLQ0bNmyhUdMRERkdDo/B6VSqfCvf/0LLi4usLS0lNZ37tzZoMGIiMi06XWz2NDQUBQXF6N///7YuHEjvv/+e2NkIyIiE6azoKysrHDo0CEoFApcvHgRS5cuxYABA4yRjYiITJjOU3wPHjyAQqFATk4OZs2ahd9//x2tWrUyRjYiIjJhOgsqODgY1tbWmDt3LpYtW4b+/fsjMDDQGNnqHb9hl4io/tRYUEqlEmPGjMH777+Pu3fv8i7mRERkNDW+B1VaWopevXoZKwsREZFE5ym+lJQU/Pjjj9i5cyfu3r0rrY+KijJoMCIiMm06C6pFixa4ceNGhSv3hBAsKCIiMiidBcX3nYiIqD7o/BwUERFRfWBBERGRLLGgiIhIlnQWVKtWrbB27Vrs27cPANC1a1e+L0VERAans6C+++47xMXFoV27dgCAs2fPIjg42NC5iIjIxOksKAcHB+zcuROlpaUAgJKSEpSUlBg8GBERmTadBXX37l20aNECQggAgJeXFwoLCw0ejIiITJvOz0G9++67iI6ORufOnXH06FG0bNkSo0ePNkY2IiIyYXrd6sjHxwddunSBQqHAmTNn+BXwRERkcDpP8f3tb3+DjY0NMjMz8euvv8LGxgYzZ840RjYiIjJhOgsqKCiowntOt27dQlBQkEFDERER6SwopVJZ6XGjRo0MFoiIiAjQ4z2ouLg47NixA2vWrIEQAjNmzMD+/fuNkY2IiEyYziOokJAQHDp0CDNnzsSsWbPw008/4f3339dr476+vsjOzkZOTg5CQkIqPd+lSxccP34cDx48wPz58ys8p9VqkZaWhpSUFKjVaj1fDhERNRQ6j6CEEFizZg3WrFlTqw0rlUqsWrUKgwcPRl5eHtRqNaKjo5GVlSWN+eOPPzB37ly88cYbVW6jf//+uHHjRq1+LxERNQw6j6BeffVVxMfH48yZM/jtt99w7tw5/Pbbbzo37OnpidzcXGi1Wjx69Ajbtm2Dv79/hTEFBQVISkrCo0ePnv4VEBFRg6TzCGrdunV45513kJycXKtbHDk6OuLSpUvS47y8PHh5eek9XwiB+Ph4CCEQFhaG8PBwvecSEdHzT2dBFRYWPtVFEQqFotK68tsl6cPb2xv5+flo2bIlDhw4gOzsbBw5cqTSuKCgIEybNg1A2X0DiYioYdB5ii8hIQH//ve/0bt3b7i5uUmLLnl5eWjfvr302MnJCZcvX9Y7WH5+PoCy04BRUVHw9PSsclx4eDg8PDzg4eGB69ev6719IiKSN51HUOWn5dzd3aV1QggMHDiwxnlqtRrOzs5QqVT4/fffERAQgPHjx+sVytraGkqlEnfu3IG1tTWGDBmCjz/+WK+5RETUMOgsqAEDBjzVhktKSjB79mzExcXBzMwM69evR2ZmJqZPnw4ACAsLQ+vWrZGUlARbW1uUlpYiODgYLi4ucHBwQFRUVFlAc3Ns2bIFcXFxT5WDiIieTzoLCgCGDRuGbt26wdLSUlq3bNkynfNiY2MRGxtbYV1YWJj089WrVyucBixXVFSEHj166BONiIgaKJ3vQYWGhmLs2LGYM2cOFAoF3nrrLXTo0MEY2YiIyITp9TmowMBA3Lx5Ex9//DH69OlT5VEPERFRXdJZUPfv3wcA3Lt3D23btsWjR4/QsWNHgwcjIiLTpvM9qD179sDOzg6ffvopTp8+DSEE1q5da4xsRERkwnQW1PLlywEAkZGR2LNnDywtLXH79m2DByMiItNWbUH1798fCQkJePPNN6t8vvwycCIiIkOotqB8fHyQkJCAESNGVHpOCMGCIiIig6q2oJYsWQKFQoHY2Fjs3LnTmJmIiIhqvopPCIHZs2cbKwsREZFE52XmBw4cwPz58+Hk5ITmzZtLCxERkSHpvIpvypQpAIBZs2ZJ64QQ6Ny5s+FSERGRydNZUJ06dTJGDiIiogr0ullst27d4OLiUuFmsd9//73BQhEREeksqEWLFqFfv35wcXHBvn374Ofnh6NHj7KgiIjIoHReJDF69GgMHDgQV65cwZQpU+Dq6orGjRsbIxsREZkwvW4WK4RAcXExmjZtimvXrvF9KSIiMjidp/iSkpJgZ2eH8PBwJCcn486dO0hMTDRGNiIiMmE6C6r88vKwsDDs378ftra2SE9PN3gwIiIybTpP8f3www8YN24crK2tceHCBZYTEREZhc6C+uKLL9C3b19kZmZix44dGDVqFC+SICIig9NZUIcPH8asWbPQqVMnfPvttxgzZgyuXbtmjGxERGTC9PqgrqWlJUaMGIGxY8eiZ8+e2LBhg6FzERGRidNZUNu2bYOXlxf279+PVatW4eeff4YQwhjZiIjIhOksqIiICIwfPx6lpaXGyENERARAj4KKi4szRg4iIqIKdF4kQUREVB9YUEREJEvVnuJzc3OrcWJKSkqdhyEiIipXbUF9/vnnAMouMXd3d4dGo4FCoUD37t1x6tQpvPbaa0YLSUREpqfaU3wDBgzAgAEDcOHCBfTs2RMeHh5wd3eHm5sbcnNzjZmRiIhMkM73oF566SVkZGRIj3/99Vf06NHDkJmIiIh0X2aelZWF8PBwbNq0CUII/OUvf0FWVpYxshERkQnTWVCTJ0/GzJkzMW/ePABl9+YLDQ01eDAiIjJtOgvq4cOHWLNmDfbt24ezZ88aIxMREZHu96BGjBiB1NRU7N+/HwDg6uqKH3/80eDBiIjItOksqMWLF8PT0xO3bt0CAGg0GqhUKgPHIiIiU6ezoIqLi3H79m1jZCEiIpLoLKiMjAyMGzcOZmZmePHFF/H111/j+PHjem3c19cX2dnZyMnJQUhISKXnu3TpguPHj+PBgweYP39+reYSEVHDprOg5syZg27duuHhw4fYunUrbt++jeDgYN0bViqxatUq+Pn5wcXFBePGjUPXrl0rjPnjjz8wd+5cfPbZZ7WeS0REDZvOq/ju37+Pjz76CB999FGtNuzp6Ync3FxotVoAZV986O/vX+EzVAUFBSgoKMDw4cNrPZeIiBo2nQXl7OyMBQsWQKVSwdz8/4cPHDiwxnmOjo64dOmS9DgvLw9eXl56harN3KCgIEybNg0A4ODgoNf2iYhI/nQW1M6dO7FmzRqsXbsWJSUlem9YoVBUWqfvV8XXZm54eDjCw8MBAGq1Wu98REQkbzoLqri4GGvWrKn1hvPy8tC+fXvpsZOTEy5fvmzwuYY2ZOZU6ef40HX1mISIqGHTeZFETEwMZs6ciTZt2qB58+bSootarYazszNUKhUsLCwQEBCA6OhovUI9y1wiImoYdB5BBQYGAgDee+89aZ0QAp07d65xXklJCWbPno24uDiYmZlh/fr1yMzMxPTp0wEAYWFhaN26NZKSkmBra4vS0lIEBwfDxcUFRUVFVc4lIiLTobOgOnXq9NQbj42NRWxsbIV1YWFh0s9Xr16tcCpP11wiIjId1RZU//79kZCQgDfffLPK56OiogwWioiIqNqC8vHxQUJCAkaMGFHpOSEEC4qIiAyq2oJasmQJAGDKlCnGykJERCTR+R4UAAwbNgzdunWDpaWltG7ZsmUGC0VERKTzMvPQ0FCMHTsWc+bMgUKhwFtvvYUOHToYIxsREZkwnQX16quvIjAwEDdv3sTHH3+MPn36VHvlHRERUV3RWVD3798HANy7dw9t27bFo0eP0LFjR4MHIyIi06bzPag9e/bAzs4On376KU6fPg0hBNauXWuMbEREZMJ0FtTy5csBAJGRkdizZw8sLS35DbtERGRw1RZUdR/QLcfPQRERkSFVW1BVfUC3HD+oS0REhlZtQfEDukREVJ90XsXXokULrFy5EsnJyUhKSsJXX32FFi1aGCMbERGZMJ0FtW3bNhQUFGDUqFEYPXo0CgoKsH37dmNkIyIiE6bXEdTy5ctx/vx5nD9/Hv/85z/RrFkzI0QjIiJTprOgEhISMHbsWCgUCulWR3v37jVGNiIiMmE6C2r69OnYsmULHj58iIcPH2Lbtm149913cfv2bRQWFhojIxERmSCdH9S1tbU1Rg4iIqIKdB5BPXm5uVKpxKJFiwwW6HkzZOZUaSEiorqjs6AGDhyIvXv3ok2bNnj55Zdx8uRJNG3a1BjZiIjIhOk8xTdhwgSMGTMG6enpuHfvHsaNG4fjx48bIxsREZkwnUdQL774IubNm4fdu3fj/PnzmDhxIqysrIyRjYiITJjOgoqJicHChQsxY8YM+Pj4ICcnB2q12hjZiIjIhOk8xefp6YmioiLp8RdffIHo6GiDhiIiIqr2COq9994DABQVFWH06NEVnps8ebJhUxERkcmrtqACAgKknz/88MMKzw0dOtRwiYiIiFBDQSkUiip/ruoxERFRXau2oIQQVf5c1WMiIqK6Vu1FEq6urigsLIRCoYCVlZV03z2FQgFLS0ujBSQiItNUbUGZm+u8wI+IiMhgdH4OioiIqD6woIiISJZYUEREJEssKCIikiUWFBERyRILioiIZMmgBeXr64vs7Gzk5OQgJCSkyjErV65ETk4ONBoN3NzcpPVarRZpaWlISUnh3dOJiEyQwT7spFQqsWrVKgwePBh5eXlQq9WIjo5GVlaWNMbPzw/Ozs5wdnaGl5cXQkND0bt3b+n5/v3748aNG4aKSEREMmawIyhPT0/k5uZCq9Xi0aNH2LZtG/z9/SuM8ff3x8aNGwEAp06dQrNmzdCmTRtDRSIioueIwQrK0dERly5dkh7n5eXB0dFR7zFCCMTHxyMpKQlBQUHV/p6goCCo1Wqo1Wo4ODjU8auovSEzp0oLERE9PYOd4qvqjudP3mS2pjHe3t7Iz89Hy5YtceDAAWRnZ+PIkSOVxoeHhyM8PBwA+F4VEVEDYrAjqLy8PLRv31567OTkhMuXL+s9Jj8/HwBQUFCAqKgoeHp6GioqERHJkMEKSq1Ww9nZGSqVChYWFggICKj0VfHR0dGYNGkSAMDLywuFhYW4cuUKrK2tYWNjAwCwtrbGkCFDkJGRYaioREQkQwY7xVdSUoLZs2cjLi4OZmZmWL9+PTIzMzF9+nQAQFhYGPbt24dhw4YhNzcX9+7dk75KvnXr1oiKiioLaG6OLVu2IC4uzlBRiYhIhgz6nRqxsbGIjY2tsC4sLKzC49mzZ1eap9Vq0aNHD0NGIyIimeOXPhnYk1fzxYeuq6ckRETPF97qiIiIZIkFRUREssSCIiIiWWJBERGRLLGgiIhIllhQREQkS7zM3Mh42TkRkX54BEVERLLEgiIiIlliQRERkSyxoIiISJZYUEREJEu8ik8GHr+yj1f1ERGV4REUERHJEguKiIhkiQVFRESyxIIiIiJZ4kUSMsSLJoiIeARFREQyxYIiIiJZ4im+5wBP+RGRKeIRFBERyRILioiIZImn+J5DPOVHRKaAR1BERCRLLCgiIpIlnuJrAB4/5QfwtB8RNQwsqAaIhUVEDQFP8RERkSzxCMpEPHnlH68EJCK54xEUERHJEo+gCEDNR1jl64iIjIkFRXphYRGRsbGg6KnxfS0iMiQWFBmMrgJ78qjsSSw5ItPGgiJZq03J6VOCLD2i54dBC8rX1xcrV66EmZkZ1q5dixUrVlQas3LlSgwbNgz37t3D22+/jZSUFL3nEj0Nlh7R88FgBaVUKrFq1SoMHjwYeXl5UKvViI6ORlZWljTGz88Pzs7OcHZ2hpeXF0JDQ9G7d2+95hLJRVWFZYgSrO02iJ53BisoT09P5ObmQqvVAgC2bdsGf3//CiXj7++PjRs3AgBOnTqFZs2aoU2bNlCpVDrnElHNnuY9v7ou1rr+HaaW29QpAAhDbHjUqFEYOnQogoKCAAB/+ctf4OXlhTlz5khjYmJi8Mknn+DYsWMAgIMHDyIkJAQqlUrn3HJBQUGYNm0aAKBLly44c+bMM2d3cHDA9evXn3k7hsacded5yAgwZ11jzrrzLBk7dOiAVq1aVVpvsCMohUJRaZ0QQq8x+swtFx4ejvDw8KdMWTW1Wg0PD4863aYhMGfdeR4yAsxZ15iz7hgio8EKKi8vD+3bt5ceOzk54fLly3qNadSokc65RETUsBnsXnxqtRrOzs5QqVSwsLBAQEAAoqOjK4yJjo7GpEmTAABeXl4oLCzElStX9JpLREQNnzDU4ufnJ86cOSNyc3PF3//+dwFATJ8+XUyfPl0a87//+78iNzdXpKWliV69etU411hLUFCQUX8fc9b/8jxkZE7mlPNiiIwGu0iCiIjoWfDrNoiISJZYUEREJEssqMf4+voiOzsbOTk5CAkJqe84knXr1uHq1atIT0+X1jVv3hzx8fE4e/Ys4uPj0axZs/oL+F9OTk44dOgQMjMzkZGRgblz5wKQX9bGjRvj1KlTSE1NRUZGBpYsWSLLnEDZHVlOnz6NmJgYAPLMqNVqkZaWhpSUFKjVagDyzGlnZ4edO3ciKysLmZmZ6N27t+xy/ulPf0JKSoq0FBYWYt68ebLLCQDBwcHIyMhAeno6tmzZgsaNGxskZ72/uSaHRalUitzcXNGxY0dhYWEhUlNTRdeuXes9FwDx2muvCTc3N5Geni6tW7FihQgJCREAREhIiPjkk0/qPWebNm2Em5ubACBsbGzEmTNnRNeuXWWZtUmTJgKAMDc3FydPnhReXl6yzPnOO++IzZs3i5iYGNn+u2u1WmFvb19hnRxzfvfdd2Lq1KkCgLCwsBB2dnayzFm+KJVKkZ+fL1544QXZ5WzXrp04d+6csLS0FADE9u3bRWBgoCFy1v8/hByW3r17i/3790uPP/jgA/HBBx/Ue67ypUOHDhUKKjs7W7Rp00YAZcWQnZ1d7xmfXH744QcxaNAgWWe1srISycnJwtPTU3Y5HR0dxcGDB0X//v2lgpJbRqDqgpJbzqZNm4pz585VWi+3nI8vgwcPFkePHpVlznbt2omLFy+K5s2bCzMzMxETEyMGDx5c5zl5iu+/HB0dcenSJelxXl4eHB0d6zFRzVq3bo0rV64AAK5cuVLlbULqU4cOHeDm5oZTp07JMqtSqURKSgquXbuGAwcOIDExUXY5v/rqK7z//vsoLS2V1sktIwAIIRAfH4+kpCTp9mRyy9mpUycUFBQgIiICp0+fRnh4OKytrWWX83EBAQHYunUrAPntz8uXL+Ozzz7DxYsXkZ+fj8LCQhw4cKDOc7Kg/qs2t1eimjVp0gS7d+9GcHAwioqK6jtOlUpLS+Hm5gYnJyd4enqiW7du9R2pguHDh+PatWs4ffp0fUfRydvbG7169YKfnx9mzZqF1157rb4jVWJubo6ePXsiNDQUPXv2xN27d/HBBx/Ud6xqWVhYYOTIkdi5c2d9R6lSs2bN4O/vj44dO6Jdu3Zo0qQJJkyYUOe/hwX1X/rcmklOrl69ijZt2gAA2rRpg2vXrtVzojLm5ubYvXs3Nm/ejKioKADyzQoAhYWF+PnnnzF06FBZ5fT29sbIkSOh1Wqxbds2DBgwAN9//72sMpbLz88HABQUFCAqKgqenp6yy5mXl4e8vDwkJiYCAHbt2oWePXvKLmc5Pz8/nD59Wsojt5yDBg2CVqvF9evXUVxcjMjISLz66qt1npMF9V/P2+2VoqOjERgYCAAIDAzEjz/+WM+Jyqxbtw5ZWVn48ssvpXVyy+rg4AA7OzsAgKWlJQYNGoTs7GxZ5fz73/+O9u3bo2PHjggICMChQ4cwceJEWWUEAGtra9jY2Eg/DxkyBBkZGbLLefXqVVy6dAl/+tOfAAADBw5EZmam7HKWGzdunHR6D5Dff0MXL15E7969YWVlBaBsf2ZlZRkkZ72/GSiXpT5vr1TTsmXLFnH58mXxn//8R1y6dElMmTJFtGjRQhw8eFCcPXtWHDx4UDRv3rzec3p7ewshhNBoNCIlJUWkpKQIPz8/2WV95ZVXxOnTp4VGoxHp6eli4cKFAoDscpYvPj4+0kUScsvYsWNHkZqaKlJTU0VGRob0343ccgIQrq6uQq1WC41GI6KiokSzZs1kmdPKykpcv35d2NraSuvkmHPJkiUiKytLpKeni40bN4pGjRrVeU7e6oiIiGSJp/iIiEiWWFBERCRLLCgiIpIlFhQREckSC4qIiGSJBUUNTnFxMVJSUpCeno4dO3ZIn9V40rFjx55q+7169cLKlSufOp9c765R1+bNm1ftvifSBy8zpwanqKgITZs2BQBs2rQJycnJFT44rFQqK9zfztgez9eQabVauLu748aNG/UdhZ5TPIKiBu3IkSN48cUX4ePjg0OHDmHz5s3S92qVH8n4+PggISFB+q6gTZs2SfPd3d1x7NgxpKam4tSpU7CxsYGPj4/0/UyLFy/Gxo0b8dNPP+Hs2bP461//CqDsfoQHDx5EcnIy0tLSMHLkSJ1ZJ06cCI1Gg9TUVGzcuBEA8MILL+DgwYPQaDQ4ePCgdDuuiIgIrF69GocOHcJvv/2G119/HevWrUNmZiYiIiKkbRYVFeGzzz5DcnIyDh48CAcHBwCAq6srTpw4AY1Gg8jISOl7exISEvDJJ5/g1KlTOHPmDPr27QugrNT//e9/IzExERqNBtOmTatx382ZMwft2rVDQkICDh06BKVSiYiICKSnpyMtLQ3BwcG1/8ckk1Tvn0jmwqUul6KiIgFAmJmZiR9++EHMmDFD+Pj4iDt37giVSlVpnI+Pj7h165ZwdHQUCoVCHD9+XHh7ewsLCwvx22+/CXd3dwGUfWWDmZlZhTs7LF68WKSmpgpLS0thb28vLl68KNq2bSvMzMxE06ZNBQBhb28vcnJyKv3exxcXFxeRnZ0tfW1F+Sfwo6OjxaRJkwQAMXnyZBEVFSUAiIiICLF161YBQIwcOVIUFhaKl19+WSgUCpGUlCRcXV0FACGEEOPHjxcAxMKFC8U333wjAAiNRiNef/11AUAsXbpUfPnllwKASEhIEJ999pkAyu6scuDAAQFABAUFiX/84x8CgGjUqJFQq9VCpVJVu++Ail/D0bNnTxEfHy+9Xjs7u3r/3wkX+S88gqIGx8rKCikpKUhKSsLFixexbt06AEBiYiLOnz9f5ZzExET8/vvvEEIgNTUVKpUKXbp0QX5+PpKSkgCUHY2UlJRUmvvjjz/iwYMHuHHjBhISEuDp6QmFQoH/+Z//kY58HB0d0bp162ozDxgwALt27ZJOh928eRMA0KdPH2zZsgUA8P3330tHNACko7j09HRcvXoVGRkZEELg119/hUqlAgCUlJRg+/btAMpOd/bt2xe2trZo1qwZDh8+DADYsGEDXn/9dWm7kZGRAIDk5GRpO0OGDMGkSZOQkpKCU6dOwd7eHs7OztXuuyedO3cOnTp1wtdffw1fX1/cvn272n1BVM68vgMQ1bX79+/Dzc2t0vq7d+9WO+fhw4fSzyUlJTA3N4dCodDrK1eeHCOEwIQJE9CyZUv06tULxcXF0Gq1sLS0rHYbT/O7yjOXlpZWyF9aWgpz86r/09bnd5Rvq3w/lOebM2cO4uPjK4z18fGpct896datW3B1dYWvry9mzZqFMWPGYOrUqTqzkGnjERRRNbKzs9GuXTu4u7sDAGxsbGBmZlZpnL+/Pxo3bowWLVqgX79+UKvVsLOzw7Vr11BcXIx+/fpVeVTxuJ9++gljxoxBixYtAADNmzcHABw/fhwBAQEAgAkTJuDo0aO1eg1mZmYYPXo0AGD8+PE4evQobt++jZs3b0pHYxMnTsQvv/xS43bi4uIwc+ZMqXycnZ1hbW1d45zHLwaxt7eHUqlEZGQkFi5ciJ49e9bqdZBp4hEUUTUePXqEsWPH4ptvvoGVlRXu37+PQYMGVRqXmJiIvXv34oUXXsCyZcuQn5+PzZs3IyYmBmq1GqmpqcjKyqrxd2VmZuKf//wnfvnlF5SUlCAlJQWTJ0/G3LlzsX79erz33nsoKCjA5MmTa/Ua7ty5g27duiEpKQmFhYUYO3YsgLKvQlizZg2sra1x7tw5ndtdu3YtVCoVTp8+DYVCgYKCArzxxhs1zvn2228RGxuL/Px8BAcHIyIiAkpl2f8n/vDDD2v1Osg08TJzomewePFi3LlzB59//nl9R6mSqVzSTg0TT/EREZEs8QiKiIhkiUdQREQkSywoIiKSJRYUERHJEguKiIhkiQVFRESy9H9QirxUvN9JQAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)\n",
    "with plt.style.context('dark_background'):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(range(len(explained_variance)), explained_variance, alpha=0.5, align='center',label='individual explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14d4158d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio of  5  Components:\n",
      "[0.24687673 0.17522353 0.09728942 0.07379666 0.05075452]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From PCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.60      0.57        53\n",
      "           1       0.63      0.76      0.69        50\n",
      "           2       0.41      0.34      0.37        44\n",
      "           3       0.51      0.50      0.51        42\n",
      "           4       0.57      0.53      0.55        47\n",
      "           5       0.69      0.51      0.59        47\n",
      "           6       0.42      0.46      0.44        28\n",
      "           7       0.82      0.89      0.85        46\n",
      "\n",
      "    accuracy                           0.59       357\n",
      "   macro avg       0.57      0.58      0.57       357\n",
      "weighted avg       0.58      0.59      0.58       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 7 2 0 0 1 7 3 4 1 5 1 5 1 6 4 1 0 4 1 5 3 3 0 4 2 1 0 1 5 6 0 6 0 1\n",
      " 0 6 7 1 0 5 0 1 1 1 2 2 5 3 7 1 0 1 0 6 5 2 6 3 6 0 1 5 7 1 3 6 0 0 0 6 0\n",
      " 2 0 0 2 0 3 1 4 0 7 2 2 1 7 1 1 3 1 3 4 2 1 0 6 0 0 1 1 4 3 7 6 4 4 5 7 1\n",
      " 3 7 7 1 3 0 3 7 5 1 7 7 0 3 5 3 1 2 7 3 5 2 6 1 5 5 4 4 7 1 2 7 3 6 0 4 6\n",
      " 6 4 3 1 0 2 2 4 1 5 7 4 5 7 4 0 2 5 4 3 3 0 3 1 0 2 1 3 2 0 4 3 3 3 2 1 3\n",
      " 0 6 2 5 7 5 4 5 7 2 1 2 7 6 2 1 0 1 4 3 1 4 7 2 1 7 3 4 2 2 7 4 1 4 3 7 6\n",
      " 1 3 6 3 0 0 7 3 6 7 0 4 7 7 0 0 3 6 1 1 4 0 1 7 7 7 4 5 0 2 6 1 6 0 0 6 0\n",
      " 7 7 0 0 0 5 7 1 6 4 4 1 4 5 5 5 1 7 4 3 0 3 7 0 6 0 0 7 2 5 4 1 0 4 3 0 4\n",
      " 5 4 4 7 7 4 5 5 1 4 5 5 1 0 0 1 3 6 4 6 7 4 0 6 3 1 3 4 1 1 1 3 0 7 1 7 5\n",
      " 6 6 2 7 4 4 0 7 2 2 1 4 2 7 2 2 7 5 2 7 7 0 5 2]\n",
      "\n",
      " Accuracy: \n",
      " 58.543417366946784\n",
      "\n",
      " Confusion Matrix: \n",
      " [[32  0 10  1  7  0  1  2]\n",
      " [ 0 38  0 11  0  1  0  0]\n",
      " [16  0 15  0  3  0 10  0]\n",
      " [ 0  8  0 21  0 10  0  3]\n",
      " [ 7  0  7  0 25  0  6  2]\n",
      " [ 0 14  0  8  0 24  0  1]\n",
      " [ 0  0  5  0  9  0 13  1]\n",
      " [ 4  0  0  0  0  0  1 41]]\n",
      "SVM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        53\n",
      "           1       0.64      0.76      0.70        50\n",
      "           2       0.74      0.77      0.76        44\n",
      "           3       0.60      0.67      0.63        42\n",
      "           4       0.69      0.66      0.67        47\n",
      "           5       0.71      0.47      0.56        47\n",
      "           6       0.63      0.68      0.66        28\n",
      "           7       0.90      0.96      0.93        46\n",
      "\n",
      "    accuracy                           0.71       357\n",
      "   macro avg       0.71      0.71      0.70       357\n",
      "weighted avg       0.71      0.71      0.71       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 1 3 7 2 0 0 1 0 1 4 1 3 1 3 1 6 4 1 0 4 1 5 3 3 0 6 2 5 0 1 5 4 0 4 0 1\n",
      " 0 4 7 5 0 5 0 1 1 5 2 0 5 3 7 3 0 1 4 6 5 2 6 3 6 0 1 3 7 1 3 6 0 2 0 6 0\n",
      " 6 0 0 4 2 3 1 4 0 7 0 0 1 6 1 1 1 1 3 4 2 3 0 6 0 0 1 1 0 3 7 4 4 2 3 7 1\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 4 3 7 1 1 2 4 3 5 0 4 1 5 5 4 4 7 1 4 7 3 2 2 4 6\n",
      " 4 4 3 1 0 2 2 6 5 5 7 4 5 7 6 2 6 5 4 3 1 2 3 1 7 2 5 3 2 0 0 1 3 3 2 1 3\n",
      " 0 2 2 5 7 5 4 1 7 2 1 2 7 6 2 1 0 1 4 3 5 4 0 0 5 7 3 4 2 2 7 0 1 2 3 7 6\n",
      " 1 3 2 1 0 0 7 3 6 7 0 4 7 7 0 0 3 6 1 1 0 2 3 7 7 3 4 5 0 2 2 1 6 0 4 6 0\n",
      " 7 7 7 0 2 3 7 1 2 4 6 1 4 5 5 1 1 7 4 3 2 3 7 2 6 0 0 7 2 5 4 1 2 6 1 7 4\n",
      " 5 4 4 7 7 4 5 3 1 4 5 5 1 2 0 5 1 6 6 2 7 4 0 6 3 1 3 2 1 1 1 3 2 7 3 7 3\n",
      " 6 4 2 7 4 4 7 7 6 6 1 4 2 7 6 4 7 5 2 3 7 0 3 2]\n",
      "\n",
      " Accuracy: \n",
      " 70.86834733893558\n",
      "\n",
      " Confusion Matrix: \n",
      " [[37  0  7  1  3  0  3  2]\n",
      " [ 0 38  0  8  0  4  0  0]\n",
      " [ 3  0 34  0  4  0  3  0]\n",
      " [ 0  8  0 28  0  5  0  1]\n",
      " [ 8  0  3  0 31  0  5  0]\n",
      " [ 0 13  0 10  0 22  0  2]\n",
      " [ 1  0  2  0  6  0 19  0]\n",
      " [ 1  0  0  0  1  0  0 44]]\n",
      "RM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86        53\n",
      "           1       0.78      0.78      0.78        50\n",
      "           2       0.82      0.84      0.83        44\n",
      "           3       0.65      0.76      0.70        42\n",
      "           4       0.84      0.81      0.83        47\n",
      "           5       0.78      0.68      0.73        47\n",
      "           6       0.78      0.64      0.71        28\n",
      "           7       0.86      0.93      0.90        46\n",
      "\n",
      "    accuracy                           0.80       357\n",
      "   macro avg       0.80      0.79      0.79       357\n",
      "weighted avg       0.80      0.80      0.80       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 2 0 0 1 0 3 4 1 1 1 5 1 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 3 0 4 0 5\n",
      " 0 2 7 5 4 5 0 1 1 5 2 0 7 1 7 3 0 1 4 6 3 2 4 3 7 0 1 3 7 1 3 6 0 2 0 4 0\n",
      " 2 0 0 4 2 3 1 4 0 7 4 0 1 6 1 1 1 1 3 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 5 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 5 5 3 1 2 4 1 5 0 4 1 1 5 4 4 7 3 4 7 3 2 2 4 6\n",
      " 2 4 3 3 0 2 2 0 3 3 5 4 5 7 6 7 6 5 4 3 1 2 1 3 7 2 5 3 2 0 0 1 5 3 2 3 3\n",
      " 0 2 6 5 7 5 4 5 7 2 1 0 7 6 2 1 0 3 4 3 3 4 4 0 5 7 0 4 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 6 7 3 6 7 0 0 7 7 4 0 7 2 1 1 0 2 5 7 7 3 0 5 0 6 4 1 6 0 4 2 0\n",
      " 7 7 0 2 2 3 7 1 2 4 4 1 4 5 5 1 1 7 4 5 2 3 7 7 6 0 0 7 4 5 4 1 2 6 7 7 0\n",
      " 5 4 6 7 7 4 5 5 1 4 5 5 1 2 7 1 1 6 0 2 7 6 0 7 3 1 1 0 1 1 3 3 2 5 5 7 3\n",
      " 6 3 4 7 4 6 7 7 0 6 1 4 2 7 0 4 3 3 2 3 7 0 3 2]\n",
      "\n",
      " Accuracy: \n",
      " 79.83193277310924\n",
      "\n",
      " Confusion Matrix: \n",
      " [[46  0  5  0  0  0  1  1]\n",
      " [ 0 39  0  8  0  3  0  0]\n",
      " [ 2  0 37  0  2  0  1  2]\n",
      " [ 0  5  0 32  0  4  0  1]\n",
      " [ 4  0  1  1 38  0  3  0]\n",
      " [ 0  6  0  7  0 32  0  2]\n",
      " [ 2  0  2  0  5  0 18  1]\n",
      " [ 0  0  0  1  0  2  0 43]]\n",
      "Xgboost From PCA\n",
      "[17:43:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.68      0.73        53\n",
      "           1       0.71      0.70      0.71        50\n",
      "           2       0.58      0.73      0.65        44\n",
      "           3       0.54      0.67      0.60        42\n",
      "           4       0.62      0.62      0.62        47\n",
      "           5       0.51      0.43      0.47        47\n",
      "           6       0.67      0.36      0.47        28\n",
      "           7       0.63      0.74      0.68        46\n",
      "\n",
      "    accuracy                           0.63       357\n",
      "   macro avg       0.63      0.61      0.61       357\n",
      "weighted avg       0.63      0.63      0.62       357\n",
      "\n",
      "Prediction Vector: \n",
      " [7 0 3 0 2 0 0 5 0 3 4 5 5 1 3 1 6 4 1 0 4 1 7 3 3 0 2 2 1 2 1 5 3 0 4 0 5\n",
      " 0 2 3 5 4 5 0 1 1 1 2 0 7 3 7 4 0 1 4 4 3 2 4 3 7 0 1 5 7 1 3 6 0 2 0 4 0\n",
      " 2 0 0 4 2 3 1 4 0 7 2 2 1 0 3 1 1 1 3 4 2 3 2 6 3 0 1 1 0 5 7 4 2 0 7 7 5\n",
      " 3 7 7 1 3 2 3 7 1 1 7 7 0 5 5 3 1 2 2 3 5 0 4 1 7 5 4 4 7 3 4 7 3 2 7 4 6\n",
      " 4 4 3 1 4 2 2 7 1 3 4 4 5 5 4 7 6 5 6 3 1 2 1 1 5 2 1 1 2 5 2 1 3 5 2 5 3\n",
      " 0 2 6 5 7 5 2 1 7 2 1 4 7 7 2 1 0 3 4 3 3 4 7 4 3 1 0 4 2 2 4 4 3 2 3 7 2\n",
      " 3 3 2 5 0 5 7 3 6 7 3 4 7 7 4 0 7 2 1 1 0 2 5 7 0 3 0 5 0 6 2 1 2 0 4 6 0\n",
      " 7 7 0 2 2 3 4 1 7 4 6 1 4 5 1 1 1 7 0 5 2 5 7 7 6 0 0 7 4 7 4 3 7 7 7 7 0\n",
      " 5 4 2 7 7 4 5 1 5 4 5 5 2 2 7 1 3 2 7 6 0 6 0 7 3 3 3 0 1 1 3 3 2 5 5 7 5\n",
      " 2 4 4 7 4 2 5 7 2 6 1 2 2 3 4 2 3 3 2 3 7 0 3 2]\n",
      "\n",
      " Accuracy: \n",
      " 62.745098039215684\n",
      "\n",
      " Confusion Matrix: \n",
      " [[36  0  8  2  4  2  0  1]\n",
      " [ 0 35  0 10  0  5  0  0]\n",
      " [ 1  0 32  0  3  0  2  6]\n",
      " [ 0  3  0 28  1  9  0  1]\n",
      " [ 4  0  7  0 29  0  3  4]\n",
      " [ 1 10  1  9  0 20  0  6]\n",
      " [ 2  0  7  0  7  0 10  2]\n",
      " [ 2  1  0  3  3  3  0 34]]\n",
      "Explained Variance Ratio of  10  Components:\n",
      "[0.24687673 0.17522353 0.09728942 0.07379666 0.05075452 0.04395209\n",
      " 0.03642078 0.02999141 0.02366627 0.02055673]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAhEUlEQVR4nO3df5xVdb3v8debUQMcNQSOt0Qc7IKIHjCcEJMLQmqYHOwohqhlnYQgVNTrSb3Xwp/3nltYHszkEKlZJmpqAgd/QIWVgjGgoqIYBzwyiYnEERFRkc/9Y6+hzbBnWDOwZpaz38/HYz/2+vH9rv3Zi2E+s77ru75fRQRmZmZ50661AzAzMyvFCcrMzHLJCcrMzHLJCcrMzHLJCcrMzHJpr9YOYE/q0qVLVFVVtXYYZmbWBEuWLHkzIrrW396mElRVVRU1NTWtHYaZmTWBpP8std1NfGZmlktOUGZmlktOUGZmlktt6h6UWVvwwQcfUFtby5YtW1o7FLM9qn379nTr1o299947VflME5Sk4cC/AhXAjIj4l3r7zwEuT1Y3ARMi4tlk3yvA28CHwNaIqM4yVrO8qK2tZb/99qOqqgpJrR2O2R4REaxfv57a2lp69OiRqk5mCUpSBXALcBJQCyyWNCsilhcVWw0MiYgNkk4BpgPHFu0fGhFvZhWjWR5t2bLFycnaHEl07tyZdevWpa6T5T2oAcDKiFgVEe8DM4HTigtExJMRsSFZXQR0yzAes48MJydri5r6c51lgjoYWFO0Xptsa8jXgYeL1gN4TNISSeMaqiRpnKQaSTVNycxmZpZvWd6DKpUqS04+JWkohQQ1qGjz8RHxmqS/A+ZJeikifrfTASOmU2gapLq62pNbWZvzg3kv79HjXXJSr12W+exnP8uTTz6Z+pgLFixgypQpzJkzh1mzZrF8+XKuuOKKBst/5zvfYfDgwZx44okNHqc56h7W79KlS7Pq78oJJ5zAlClTqK5u+Jb4+eefz6WXXkqfPn12+/Oy+j57MsYsZZmgaoFDita7Aa/VLySpLzADOCUi1tdtj4jXkvc3JD1IoclwpwRlZnteU5JTfSNHjmTkyJGNlrn22mubffy8mzFjRmuH0KgPP/ww9zHWyTJBLQZ6SuoB/Bk4Czi7uICk7sADwJcj4uWi7fsC7SLi7WT5ZCDzn+g9/ZdqY9L8FWvWWiorK9m0aRMLFizg6quvpkuXLjz//PMcc8wx/PznP0cSjzzyCBdffDFdunShf//+2+vecccd1NTUcMMNN9CvXz9WrVpFu3bt2Lx5M4cffjirVq1i7NixjBgxglGjRjV4nKuvvprKykouu+wyAI466ijmzJlDVVUVX/ziF1mzZg1btmxh0qRJjBvX4F0AAB577DEmT57Me++9x6c+9Sluv/121q9fz4knnsjChQs58MADGTJkCN/+9rfp1asXw4cP59hjj+Xpp5+mV69e3HnnnXTs2HGHY06YMIHFixfz7rvvMmrUKK655hpgx6usyspKJk2axJw5c+jQoQMPPfQQBx10EOvWrWP8+PG8+uqrANx0000cf/zxrF+/njFjxrBu3ToGDBhAqRnPb731VlavXs13v/vd7ed7yZIl3HzzzQ2el8rKSi699FIeffRRbrzxRq666qrtMTb0PaqqqjjvvPOYPXs2H3zwAffddx+9e/dm06ZNXHjhhdTU1CCJyZMnc8YZZ5Q8x5WVlU36uasvs3tQEbEVuAB4FHgRuDciXpA0XtL4pNh3gM7AjyQ9I6luIL2DgD9Iehb4I/DvEfFIVrGaWcOefvppbrrpJpYvX86qVat44okn2LJlC2PHjmX27Nn8/ve/5/XXX9+p3gEHHEC/fv14/PHHAZg9ezaf//znd3gGJs1xSrnttttYsmQJNTU1TJ06lfXr1zdY9s033+T6669n/vz5LF26lOrqar7//e9z6KGHcvnllzN+/HhuvPFG+vTpw8knnwzAihUrGDduHMuWLWP//ffnRz/60U7HveGGG6ipqWHZsmU8/vjjLFu2bKcy77zzDgMHDuTZZ59l8ODB/PjHPwZg0qRJXHLJJSxevJj777+f888/H4BrrrmGQYMG8fTTTzNy5MjtCazYqFGjeOCBB7av33PPPYwePbrR8/LOO+9w1FFH8dRTTzFo0KAdjtfY9+jSpQtLly5lwoQJTJkyBYDrrruOAw44gOeee45ly5YxbNiwBs/x7sr0OaiImAvMrbdtWtHy+cD5JeqtAvplGZuZpTNgwAC6dSt0sD366KN55ZVXqKyspEePHvTs2ROAc889l+nTp+9Ud/To0dxzzz0MHTqUmTNn8s1vfnOH/S+99FKq49Q3depUHnzwQQDWrFnDn/70Jzp37lyy7KJFi1i+fDnHH388AO+//z7HHXccULgXc9999zFt2jSeeeaZ7XUOOeSQ7eXPPfdcpk6duv1Krs69997L9OnT2bp1K2vXrmX58uX07dt3hzL77LMPI0aMAOCYY45h3rx5AMyfP5/ly//2xM3GjRt5++23+d3vfrc9+Zx66ql06tRpp+/TtWtXDjvsMBYtWkTPnj1ZsWLF9lgbOi8VFRWcccYZJc9PY9/j9NNP3x57XVzz589n5syZ2+t36tSJOXPmNHiOd4dHkjCzRn3sYx/bvlxRUcHWrVuBdF2GR44cyZVXXslf//pXlixZwrBhw3Yq09Bx9tprL7Zt27Z9vW5kjQULFjB//nwWLlxIx44dOeGEExoddSMiOOmkk7j77rt32rd582Zqa2sB2LRpE/vtt1/JmOqvr169milTprB48WI6derEV7/61ZIx7L333tvrFp+7bdu2sXDhQjp06LBTnTTndfTo0dx777307t2bf/zHf0RSo+elffv2VFRU7HScXX2Pun/74tgjYqcYGzvHu8Nj8ZlZk/Xu3ZvVq1fzH//xHwAN/mKqrKxkwIABTJo0iREjRuz0S7Kx41RVVbF06VIAli5dyurVqwF466236NSpEx07duSll15i0aJFjcY6cOBAnnjiCVauXAkUktLLLxfuN19++eWcc845XHvttYwdO3Z7nVdffZWFCxduj6l+s9jGjRvZd999OeCAA/jLX/7Cww8/TFOcfPLJ/PCHP9y+Xnf1NnjwYO666y4AHn74YTZs2FCqOqeffjq/+tWvuPvuu7c37zX1vDT3e9SPfcOGDY2e493hKyiznMtjh5r27dszffp0Tj31VLp06cKgQYN4/vnnS5YdPXo0Z555JgsWLGjScc444wzuvPNOjj76aD7zmc/Qq1fhPAwfPpxp06bRt29fDj/8cAYOHNhorF27duWOO+5gzJgxvPfeewBcf/31rF27lsWLF/PEE09QUVHB/fffz+23387QoUM54ogj+OlPf8o3vvENevbsyYQJE3Y4Zr9+/fj0pz/NkUceyWGHHba9aSutqVOnMnHiRPr27cvWrVsZPHgw06ZNY/LkyYwZM4b+/fszZMgQunfvXrJ+p06d6NOnD8uXL2fAgAHNOi/N/R5XXXUVEydO5KijjqKiooLJkydz+umnlzzHdf9mzaVSvUQ+qqqrq2N3Jix0Lz7LgxdffJEjjjiitcMoW6+88gojRoxoMOHa7in18y1pSanxVt3EZ2ZmueQEZWZWpKqqyldPOeEEZZZDbanp3axOU3+unaDMcqZ9+/asX7/eScralLr5oNq3b5+6jnvxmeVMt27dqK2tbdK8OWYfBXUz6qblBGWWM3vvvXfqGUfN2jI38ZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS5lmqAkDZe0QtJKSVeU2H+OpGXJ60lJ/dLWNTOzti2zBCWpArgFOAXoA4yR1KdesdXAkIjoC1wHTG9CXTMza8OyvIIaAKyMiFUR8T4wEzituEBEPBkRG5LVRUC3tHXNzKxtyzJBHQysKVqvTbY15OvAw02tK2mcpBpJNevWrduNcM3MLE+yTFAqsS1KFpSGUkhQlze1bkRMj4jqiKju2rVrswI1M7P82SvDY9cChxStdwNeq19IUl9gBnBKRKxvSl0zM2u7sryCWgz0lNRD0j7AWcCs4gKSugMPAF+OiJebUtfMzNq2zK6gImKrpAuAR4EK4LaIeEHS+GT/NOA7QGfgR5IAtibNdSXrZhWrmZnlT5ZNfETEXGBuvW3TipbPB85PW9fMzMrHLpv4JHWT9KCkdZL+Iul+Sd12Vc/MzGx3pLkHdTuF+z+foNDVe3ayzczMLDNpElTXiLg9IrYmrzsA9+c2M7NMpUlQb0o6V1JF8joXWL/LWmZmZrshTYL6J+BLwOvAWmBUss3MzCwzu+zFFxGvAiNbIBYzM7PtGkxQkr4VEd+VdDMlhhmKiIsyjczMzMpaY1dQLybvNS0RiJmZWbEGE1REzE4WN0fEfcX7JJ2ZaVRmZlb20nSSuDLlNjMzsz2msXtQpwBfAA6WNLVo1/7A1qwDMzOz8tbYPajXKNx/GgksKdr+NnBJlkGZmZk1dg/qWeBZSb+IiA9aMCYzM7NUo5lXSfq/QB+gfd3GiDgss6jMzKzspR0s9lYK952GAncCP8syKDMzszQJqkNE/BpQRPxnRFwNDMs2LDMzK3dpmvi2SGoH/CmZ5fbPwN9lG5aZmZW7NAnqYqAjcBFwHYVmvvMyjKns/WDeyy36eZec1KtFP8/MLI1GE5SkCuBLEfHPwCbgay0SlZmZlb1G70FFxIfAMZLUQvGYmZkB6Zr4ngYeknQf8E7dxoh4ILOozMys7KVJUAdSmEG3uOdeAE5QZmaWmTQTFvq+k5mZtbg0z0GZmZm1OCcoMzPLJScoMzPLpV0mKEkHSfqJpIeT9T6Svp59aGZmVs7SXEHdATwKfDJZf5nC6BJmZmaZSZOgukTEvcA2gIjYCnyYaVRmZlb20iSodyR1pvDsE5IGAm9lGpWZmZW9NA/qXgrMAj4l6QmgKzAq06jMzKzspXlQd6mkIcDhgIAVngLezMyylqYX30SgMiJeiIjngUpJ38w+NDMzK2dp7kGNjYj/qluJiA3A2MwiMjMzI12Calc83UYyR9Q+2YVkZmaWrpPEo8C9kqZR6Mk3Hngk06jMzKzspbmCuhz4DTABmAj8GvhWmoNLGi5phaSVkq4osb+3pIWS3pN0Wb19r0h6TtIzkmrSfJ6ZmbUdaXrxbQNuTV6pJU2BtwAnAbXAYkmzImJ5UbG/AhcBX2zgMEMj4s2mfK6ZmbUNaXrxHS9pnqSXJa2StFrSqhTHHgCsjIhVEfE+MBM4rbhARLwREYsBd1s3M7MdpLkH9RPgEmAJTRvi6GBgTdF6LXBsE+oH8JikAP4tIqY3oa6ZmX3EpUlQb0XEw804tkpsiybUPz4iXpP0d8A8SS9FxO92+hBpHDAOoHv37s0I08zM8ihNJ4nfSvqepOMk9a97pahXCxxStN4NeC1tYBHxWvL+BvAghSbDUuWmR0R1RFR37do17eHNzCzn0lxB1TXLVRdtC2DYLuotBnpK6gH8GTgLODtNUJL2BdpFxNvJ8snAtWnqmplZ25CmF9/Q5hw4IrZKuoDCc1QVwG0R8YKk8cn+aZL+G1AD7A9sk3Qx0AfoAjyYPB+8F/CLiPCzV2ZmZSTNFRSSTgWOBNrXbYuIXV7RRMRcYG69bdOKll+n0PRX30agX5rYzMysbUrTzXwaMBq4kELHhzOBQzOOy8zMylyaThKfjYivABsi4hrgOHbs/GBmZrbHpUlQ7ybvmyV9ksJDtT2yC8nMzCzdPag5kj4OfA9YSqEH34wsgzIzM0vTi++6ZPF+SXOA9hHxVrZhmZlZuWswQUkaFhG/kXR6iX1ExAPZhmZmZuWssSuoIRSm2fiHEvsCcIIyM7PMNJigImKypHbAwxFxbwvGZGZm1ngvvmQuqAtaKBYzM7Pt0nQznyfpMkmHSDqw7pV5ZGZmVtbSdDP/p+R9YtG2AA7b8+GYmZkVpOlm7odyzcysxaUdLPYoCqOMFw8We2dWQZmZme0yQUmaDJxAIUHNBU4B/gA4QZmZWWbSdJIYBXwOeD0ivkZhGoyPZRqVmZmVvVSDxSbdzbdK2h94A3eQMDOzjKW5B1WTDBb7Y2AJsAn4Y5ZBmZmZpenF981kcZqkR4D9I2JZtmGZmVm5SzOj7kOSzpa0b0S84uRkZmYtIc09qO8Dg4Dlku6TNEpS+11VMjMz2x1pmvgeBx6XVAEMA8YCtwH7ZxybmZmVsbQP6nagMO3GaKA/8NMsgzIzM0vzoO49wLHAI8AtwIKk27mZmVlm0lxB3Q6cHREfZh2MmZlZnTT3oB5piUDMzMyKpenFZ2Zm1uKcoMzMLJcabOKT1L+xihGxdM+HY2ZmVtDYPagbk/f2QDXwLCCgL/AUhYd3zczMMtFgE19EDI2IocB/Av0jojoijgE+DaxsqQDNzKw8pbkH1TsinqtbiYjngaMzi8jMzIx0z0G9KGkG8HMggHOBFzONyszMyl6aBPU1YAIwKVn/HXBrZhGZmZmR7kHdLZKmAXMjYkULxGRmZpZqPqiRwDMUxuJD0tGSZmUcl5mZlbk0nSQmAwOA/wKIiGeAqswiMjMzI12C2hoRb2UeiZmZWZE0Cep5SWcDFZJ6SroZeDLNwSUNl7RC0kpJV5TY31vSQknvSbqsKXXNzKxtS5OgLgSOBN4D7gY2AhfvqlIyA+8twClAH2CMpD71iv0VuAiY0oy6ZmbWhqXpxbcZ+N/JqykGACsjYhWApJnAacDyomO/Abwh6dSm1jUzs7YtzYy6vYDLKHSM2F4+IobtourBwJqi9VoKM/OmkbqupHHAOIDu3bunPLyZmeVdmgd17wOmATOApsyqqxLbYk/XjYjpwHSA6urqtMc3M7OcS5OgtkZEc0aOqAUOKVrvBrzWAnVtD/nBvJdb9PMuOalXi36emeVbmk4SsyV9U9InJB1Y90pRbzHQU1IPSfsAZwFpH/DdnbpmZtYGpLmCOi95/+eibQEc1liliNgq6QLgUaACuC0iXpA0Ptk/TdJ/A2qA/YFtki4G+kTExlJ1m/C9zMzsIy5NL74ezT14RMwF5tbbNq1o+XUKzXep6pqZWflobMr3YRHxG0mnl9ofEQ9kF5aZmZW7xq6ghgC/Af6hxL4AnKDMzCwzDSaoiJicvH+t5cIxMzMrSNNJgmSkhyOB9nXbIuLarIIyMzNLMx/UNGA0hTH5BJwJHJpxXGZmVubSPAf12Yj4CrAhIq4BjmPHh2jNzMz2uDQJ6t3kfbOkTwIfAM3uem5mZpZGmntQcyR9HPgesJRCD74ZWQZlZmaW5kHd65LF+yXNAdp7hl0zM8taYw/qlnxAN9nnB3XNzCxTjV1BlXpAt44f1DUzs0w19qCuH9A1M7NWk+Y5qM6SpkpaKmmJpH+V1LklgjMzs/KVppv5TGAdcAYwKlm+J8ugzMzM0nQzP7CoJx/A9ZK+mFE8ZmZmQLorqN9KOktSu+T1JeDfsw7MzMzKW5oE9Q3gF8B7yWsmcKmktyVtzDI4MzMrX2ke1N2vJQIxMzMrtssEJenrEfGTovUK4Kpk4FizzP1g3sst+nmXnNSrRT/PzEpL08T3OUlzJX1C0t8DiwBfVZmZWabSNPGdLWk08BywGRgTEU9kHpmZmZW1NA/q9gQmAfcDrwBfltQx47jMzKzMpWnimw18OyK+AQwB/gQszjQqMzMre2ke1B0QERsBIiKAGyXNyjYsMzMrdw1eQUn6FkBEbJR0Zr3dHkjWzMwy1VgT31lFy1fW2zc8g1jMzMy2ayxBqYHlUutmZmZ7VGMJKhpYLrVuZma2RzXWSaJfMtaegA5F4+4JaJ95ZGZmVtYam1G3oiUDMTMzK5bmOSgzM7MW5wRlZma55ARlZma55ARlZma55ARlZma55ARlZma5lGmCkjRc0gpJKyVdUWK/JE1N9i+T1L9o3yuSnpP0jKSaLOM0M7P8STOaebMkU8PfApwE1AKLJc2KiOVFxU4BeiavY4Fbk/c6QyPizaxiNDOz/MryCmoAsDIiVkXE+8BM4LR6ZU4D7oyCRcDHJX0iw5jMzOwjIrMrKOBgYE3Rei07Xh01VOZgYC2F8f4ekxTAv0XE9FIfImkcMA6ge/fueyZysxJ+MO/lFv28S07q1aKfZ5Y3WV5BlRrxvP4gs42VOT4i+lNoBpwoaXCpD4mI6RFRHRHVXbt2bX60ZmaWK1kmqFrgkKL1bsBractERN37G8CDFJoMzcysTGSZoBYDPSX1kLQPhQkQ608VPwv4StKbbyDwVkSslbSvpP0AJO0LnAw8n2GsZmaWM5ndg4qIrZIuAB4FKoDbIuIFSeOT/dOAucAXgJXAZv42lfxBwIOS6mL8RUQ8klWsZmaWP1l2kiAi5lJIQsXbphUtBzCxRL1VQL8sYzMzs3zLNEGZ2Z7n3oRWLjzUkZmZ5ZITlJmZ5ZITlJmZ5ZITlJmZ5ZITlJmZ5ZITlJmZ5ZK7mZtZs7Vkl3d3dy8/voIyM7NccoIyM7NccoIyM7NccoIyM7NccoIyM7Ncci8+M/vIc2/CtslXUGZmlktOUGZmlktOUGZmlktOUGZmlkvuJGFmtoe4s8ae5SsoMzPLJScoMzPLJTfxmZm1MW2lqdFXUGZmlktOUGZmlktOUGZmlktOUGZmlktOUGZmlktOUGZmlktOUGZmlktOUGZmlktOUGZmlktOUGZmlktOUGZmlktOUGZmlktOUGZmlktOUGZmlktOUGZmlkuZJihJwyWtkLRS0hUl9kvS1GT/Mkn909Y1M7O2LbMEJakCuAU4BegDjJHUp16xU4CeyWsccGsT6pqZWRuW5RXUAGBlRKyKiPeBmcBp9cqcBtwZBYuAj0v6RMq6ZmbWhikisjmwNAoYHhHnJ+tfBo6NiAuKyswB/iUi/pCs/xq4HKjaVd2iY4yjcPUFcDiwIpMv1LguwJut8Ll55fOxI5+PHfl87MjnAw6NiK71N+6V4QeqxLb62bChMmnqFjZGTAemNy20PUtSTURUt2YMeeLzsSOfjx35fOzI56NhWSaoWuCQovVuwGspy+yToq6ZmbVhWd6DWgz0lNRD0j7AWcCsemVmAV9JevMNBN6KiLUp65qZWRuW2RVURGyVdAHwKFAB3BYRL0gan+yfBswFvgCsBDYDX2usblax7gGt2sSYQz4fO/L52JHPx458PhqQWScJMzOz3eGRJMzMLJecoMzMLJecoHaDh2PakaRDJP1W0ouSXpA0qbVjam2SKiQ9nTzzV/YkfVzSLyW9lPycHNfaMbUmSZck/1eel3S3pPatHVOeOEE1k4djKmkr8D8j4ghgIDDR54RJwIutHUSO/CvwSET0BvpRxudG0sHARUB1RBxFoUPYWa0bVb44QTWfh2OqJyLWRsTSZPltCr98Dm7dqFqPpG7AqcCM1o4lDyTtDwwGfgIQEe9HxH+1alCtby+gg6S9gI74ec8dOEE138HAmqL1Wsr4l3F9kqqATwNPtXIorekm4FvAtlaOIy8OA9YBtyfNnjMk7dvaQbWWiPgzMAV4FVhL4TnQx1o3qnxxgmq+1MMxlRtJlcD9wMURsbG142kNkkYAb0TEktaOJUf2AvoDt0bEp4F3gLK9dyupE4VWlx7AJ4F9JZ3bulHlixNU86UZyqnsSNqbQnK6KyIeaO14WtHxwEhJr1Bo/h0m6eetG1KrqwVqI6LuqvqXFBJWuToRWB0R6yLiA+AB4LOtHFOuOEE1n4djqkeSKNxfeDEivt/a8bSmiLgyIrpFRBWFn43fRERZ/3UcEa8DayQdnmz6HLC8FUNqba8CAyV1TP7vfI4y7jRSSpaDxbZpH8HhmFrC8cCXgeckPZNs+18RMbf1QrKcuRC4K/mjbhXJ8GblKCKekvRLYCmFHrBP42GPduChjszMLJfcxGdmZrnkBGVmZrnkBGVmZrnkBGVmZrnkBGVmZrnkBGVtjqQPJT2TjBB9n6SODZR7spnHr5Y0dTfi29Tcuh8lki5u6NybpeFu5tbmSNoUEZXJ8l3AkuIHhyVVRMSHeYivLUtG0aiOiDdbOxb7aPIVlLV1vwf+u6QTkrmqfgE8B3+7kkn2LSiap+iu5Ml+JH1G0pOSnpX0R0n7JeXnJPuvlvQzSb+R9CdJY5PtlZJ+LWmppOck7XKke0lfkbQs+ayfJdsOTY6zLHnvnmy/Q9KtyXdaJWmIpNuSOZbuKDrmJkk3JnH8WlLXZPvRkhYlx30wGReO5Dz8v+S7vizpfyTbKyR9T9LipM43Gjt3ki6iML7cb5MYK5KYn0/OxyV74N/W2rqI8MuvNvUCNiXvewEPAROAEygMTtqjRLkTgLcojKfYDlgIDALqRjv4TFJu/+SYJwBzkm1XA88CHYAuFEa4/2RSbv+kTBdgJX9rsdhUIuYjgRVAl2T9wOR9NnBesvxPwK+S5TsojPEnCgOObgT+Pol/CXB0Ui6Ac5Ll7wA/TJaXAUOS5WuBm5LlBcCNyfIXgPnJ8jjgqmT5Y0ANhUFOS567pNwrRd/nGGBe0ff9eGv/nPiV/5evoKwt6pAMtVRDYbyznyTb/xgRqxuo88eIqI2IbcAzQBVwOLA2IhYDRMTGiNhaou5DEfFuFJqyfkthrjAB/0fSMmA+halYDmok5mHAL5NjEBF/TbYfB/wiWf4ZhcRZZ3ZEBIUrwr9ExHNJ/C8k8UNhqo97kuWfA4MkHUAhQTyebP8phXma6tQN8ruk6DgnA19JzutTQGegZ7Kv1LmrbxVwmKSbJQ2nkFDNGuWx+Kwtejciji7ekLTYvdNInfeKlj+k8H9DpJtCpX6ZAM4BugLHRMQHyf2Yxqbzbs5n1cW8jR3j30bD/7fTfEbdserOQ118F0bEo8UFJZ1A6XO344dGbJDUD/g8MBH4EoUrQrMG+QrKrGEvAZ+U9BmA5P5TqV/8p0lqL6kzhSavxcABFOaD+kDSUODQXXzWr4EvJcdA0oHJ9if52zTg5wB/aOJ3aAeMSpbPBv4QEW8BG+ruL1EY4PfxUpWLPApMUGE6FST10q4nG3wb2C8p3wVoFxH3A9+mvKfZsJR8BWXWgIh4X9Jo4GZJHYB3KczhU98fgX8HugPXRcRrSe/B2ZJqKDR7vbSLz3pB0g3A45I+pDCy9VeBi4DbJP0zhdlomzr69zvAkZKWULhXNDrZfh4wLekGnmZU8RkUmu6WJh1I1gFf3EWd6cDDktYCF1OYSbfuj+Irm/Y1rBy5m7nZbpB0NYVOD1NaO5ZSyqVLu7VNbuIzM7Nc8hWUmZnlkq+gzMwsl5ygzMwsl5ygzMwsl5ygzMwsl5ygzMwsl/4/Tdr0hkx8M5YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78        53\n",
      "           1       0.94      0.98      0.96        50\n",
      "           2       0.78      0.89      0.83        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       0.89      0.83      0.86        47\n",
      "           5       0.98      0.94      0.96        47\n",
      "           6       0.92      0.86      0.89        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           0.91       357\n",
      "   macro avg       0.91      0.91      0.91       357\n",
      "weighted avg       0.91      0.91      0.91       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 4 1 3 5 5 3 6 4 5 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 0 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 4 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 0 0 1 4 1 1 1 1 5 4 2 3 0 6 0 0 1 1 4 3 7 4 2 2 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 0 4 6\n",
      " 2 4 3 1 0 2 2 4 1 3 7 4 5 7 6 0 6 5 4 1 1 2 1 3 7 2 1 1 2 0 2 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 2 7 4 6 5 0 1 4 3 5 4 0 2 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 2 7 7 0 0 3 2 1 5 2 2 3 7 7 3 2 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 6 1 4 5 5 1 1 7 4 3 2 1 7 0 4 0 0 7 4 5 4 1 0 4 5 7 4\n",
      " 5 4 6 7 7 4 5 1 5 4 5 5 5 2 7 1 3 6 4 2 7 6 0 4 3 1 1 2 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 2 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 90.75630252100841\n",
      "\n",
      " Confusion Matrix: \n",
      " [[41  0 11  0  1  0  0  0]\n",
      " [ 0 49  0  0  0  1  0  0]\n",
      " [ 4  0 39  0  0  0  1  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 7  0  0  0 39  0  1  0]\n",
      " [ 0  3  0  0  0 44  0  0]\n",
      " [ 0  0  0  0  4  0 24  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92        53\n",
      "           1       0.89      1.00      0.94        50\n",
      "           2       0.96      1.00      0.98        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       0.97      0.83      0.90        47\n",
      "           5       1.00      0.87      0.93        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           0.96       357\n",
      "   macro avg       0.96      0.96      0.96       357\n",
      "weighted avg       0.96      0.96      0.95       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 0 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 4 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 1 1 4 0 7 2 0 1 6 1 1 1 1 5 4 2 3 0 6 0 0 1 1 0 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 0 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 0 2 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 0 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 1 7 2 4 0 0 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 1 1 4 5 1 1 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 95.51820728291317\n",
      "\n",
      " Confusion Matrix: \n",
      " [[51  0  1  0  1  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 7  0  1  0 39  0  0  0]\n",
      " [ 0  6  0  0  0 41  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "RM From PCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        53\n",
      "           1       0.98      1.00      0.99        50\n",
      "           2       0.95      0.91      0.93        44\n",
      "           3       0.95      0.95      0.95        42\n",
      "           4       1.00      0.94      0.97        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       0.96      0.89      0.93        28\n",
      "           7       0.83      0.96      0.89        46\n",
      "\n",
      "    accuracy                           0.96       357\n",
      "   macro avg       0.96      0.95      0.95       357\n",
      "weighted avg       0.96      0.96      0.96       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 2 3 2 6 3 1 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 6 0 1 6 1 1 1 1 5 4 2 3 0 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 7 4 6\n",
      " 2 4 7 5 4 0 0 4 1 3 7 4 5 7 6 7 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 7 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 3 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 7 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 3 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 7 4 0 4 7 4 5 4 1 7 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 7 2 7 6 0 7 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 2 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 95.51820728291317\n",
      "\n",
      " Confusion Matrix: \n",
      " [[51  1  1  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 40  0  0  0  0  4]\n",
      " [ 0  0  0 40  0  0  0  2]\n",
      " [ 1  0  0  0 44  0  1  1]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  1  0  0  0 25  2]\n",
      " [ 0  0  0  2  0  0  0 44]]\n",
      "Xgboost From PCA\n",
      "[17:43:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86        53\n",
      "           1       0.90      0.92      0.91        50\n",
      "           2       0.88      0.86      0.87        44\n",
      "           3       0.95      0.90      0.93        42\n",
      "           4       0.95      0.83      0.89        47\n",
      "           5       0.88      0.94      0.91        47\n",
      "           6       0.89      0.89      0.89        28\n",
      "           7       0.78      0.85      0.81        46\n",
      "\n",
      "    accuracy                           0.88       357\n",
      "   macro avg       0.89      0.88      0.88       357\n",
      "weighted avg       0.89      0.88      0.88       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 5 0 4 0 5\n",
      " 0 2 7 1 0 5 0 1 1 5 2 0 5 1 7 3 2 3 4 6 3 2 6 7 1 0 1 3 7 1 1 6 0 2 6 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 0 0 1 4 1 1 1 1 5 4 2 3 0 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 6 3 7 7 1 7 1 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 7 4 6\n",
      " 2 4 7 5 0 2 0 4 1 3 7 4 5 5 6 7 6 5 4 1 1 2 1 3 7 2 1 1 2 0 2 1 1 1 2 3 3\n",
      " 0 2 2 3 7 5 2 5 7 2 1 0 7 0 2 5 0 5 4 3 5 4 7 0 5 6 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 1 4 0 7 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 3 6 4 1 4 5 5 5 1 7 4 3 2 5 7 7 4 0 4 7 4 1 4 1 7 0 5 7 4\n",
      " 5 4 6 7 0 4 5 5 5 4 5 5 5 2 7 1 3 6 0 2 7 6 0 7 3 1 1 4 1 1 5 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 5 7 0 6 1 4 2 7 2 4 7 3 2 3 7 0 3 2]\n",
      "\n",
      " Accuracy: \n",
      " 88.23529411764706\n",
      "\n",
      " Confusion Matrix: \n",
      " [[46  1  4  0  1  0  1  0]\n",
      " [ 0 46  0  1  0  3  0  0]\n",
      " [ 0  0 38  1  0  0  1  4]\n",
      " [ 0  0  0 38  0  0  0  4]\n",
      " [ 6  0  1  0 39  0  0  1]\n",
      " [ 0  2  0  0  0 44  0  1]\n",
      " [ 1  0  0  0  1  0 25  1]\n",
      " [ 1  2  0  0  0  3  1 39]]\n",
      "Explained Variance Ratio of  15  Components:\n",
      "[0.24687673 0.17522353 0.09728942 0.07379666 0.05075452 0.04395209\n",
      " 0.03642079 0.02999141 0.02366637 0.02055692 0.01702143 0.01399751\n",
      " 0.01255855 0.01063702 0.01057155]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96        53\n",
      "           1       1.00      0.98      0.99        50\n",
      "           2       0.94      1.00      0.97        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      0.98      0.99        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       0.98      1.00      0.99        46\n",
      "\n",
      "    accuracy                           0.99       357\n",
      "   macro avg       0.99      0.99      0.99       357\n",
      "weighted avg       0.99      0.99      0.99       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 7 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 2 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 2 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 0 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 2 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 98.59943977591037\n",
      "\n",
      " Confusion Matrix: \n",
      " [[50  0  2  0  0  0  0  1]\n",
      " [ 1 49  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  1  0 46  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      0.96      0.98        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           0.99       357\n",
      "   macro avg       1.00      0.99      0.99       357\n",
      "weighted avg       0.99      0.99      0.99       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 0 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 0 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Accuracy: \n",
      " 99.43977591036415\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 2  0  0  0 45  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "RM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        53\n",
      "           1       0.94      1.00      0.97        50\n",
      "           2       0.98      0.98      0.98        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       0.98      0.98      0.98        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      0.93      0.96        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           0.99       357\n",
      "   macro avg       0.99      0.98      0.99       357\n",
      "weighted avg       0.99      0.99      0.99       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 2 3 2 6 3 1 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 4 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 1 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 1 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 98.59943977591037\n",
      "\n",
      " Confusion Matrix: \n",
      " [[52  1  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  1 43  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  1  0  0 46  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  1  0  1  0 26  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From PCA\n",
      "[17:44:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92        53\n",
      "           1       0.84      0.94      0.89        50\n",
      "           2       0.93      0.89      0.91        44\n",
      "           3       0.93      0.95      0.94        42\n",
      "           4       0.94      0.94      0.94        47\n",
      "           5       0.94      0.96      0.95        47\n",
      "           6       0.92      0.82      0.87        28\n",
      "           7       0.98      0.96      0.97        46\n",
      "\n",
      "    accuracy                           0.92       357\n",
      "   macro avg       0.93      0.92      0.92       357\n",
      "weighted avg       0.93      0.92      0.92       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 3 0 3 4 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 0 5 0 1 1 5 2 2 5 1 7 3 2 1 4 6 3 2 6 3 1 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 4 1 1 1 1 5 4 2 3 4 5 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 1 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 1 4 6\n",
      " 2 4 1 5 4 0 0 6 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 0 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 6 5 7 2 1 0 7 4 2 5 0 5 4 3 5 4 4 0 5 1 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 1 2 1 5 0 2 3 7 7 3 2 3 0 6 2 3 4 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 3 6 4 1 4 5 5 1 1 7 4 3 2 5 7 1 4 0 4 7 4 1 4 1 1 4 5 7 4\n",
      " 5 4 6 7 5 4 5 5 5 4 5 5 5 0 7 1 3 6 6 2 7 6 0 7 3 1 1 3 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 2 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 92.43697478991596\n",
      "\n",
      " Confusion Matrix: \n",
      " [[48  1  3  1  0  0  0  0]\n",
      " [ 1 47  0  1  0  1  0  0]\n",
      " [ 1  3 39  1  0  0  0  0]\n",
      " [ 0  2  0 40  0  0  0  0]\n",
      " [ 1  0  0  0 44  0  2  0]\n",
      " [ 0  2  0  0  0 45  0  0]\n",
      " [ 0  0  0  0  3  1 23  1]\n",
      " [ 0  1  0  0  0  1  0 44]]\n",
      "Explained Variance Ratio of  20  Components:\n",
      "[0.24687673 0.17522353 0.09728942 0.07379666 0.05075452 0.04395209\n",
      " 0.03642079 0.02999141 0.02366637 0.02055695 0.01702147 0.01399789\n",
      " 0.01255882 0.01063917 0.0105776  0.00911705 0.00895912 0.00793295\n",
      " 0.00630083 0.00605789]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       0.98      1.00      0.99        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 4 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 99.71988795518207\n",
      "\n",
      " Confusion Matrix: \n",
      " [[52  0  0  0  1  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From PCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "RM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        53\n",
      "           1       0.96      1.00      0.98        50\n",
      "           2       0.98      0.98      0.98        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      0.93      0.96        28\n",
      "           7       0.98      1.00      0.99        46\n",
      "\n",
      "    accuracy                           0.99       357\n",
      "   macro avg       0.99      0.99      0.99       357\n",
      "weighted avg       0.99      0.99      0.99       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 2 3 2 6 3 1 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 1 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 7 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 98.8795518207283\n",
      "\n",
      " Confusion Matrix: \n",
      " [[52  1  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  1 43  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  1  0  0  0 26  1]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From PCA\n",
      "[17:44:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92        53\n",
      "           1       0.81      0.96      0.88        50\n",
      "           2       0.90      0.86      0.88        44\n",
      "           3       0.93      0.95      0.94        42\n",
      "           4       0.90      0.91      0.91        47\n",
      "           5       0.98      0.94      0.96        47\n",
      "           6       1.00      0.71      0.83        28\n",
      "           7       0.88      0.93      0.91        46\n",
      "\n",
      "    accuracy                           0.91       357\n",
      "   macro avg       0.92      0.90      0.90       357\n",
      "weighted avg       0.91      0.91      0.91       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 3 0 3 4 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 0 5 0 1 1 5 2 2 5 1 7 3 2 1 4 6 3 2 6 3 1 0 1 3 7 1 1 7 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 4 1 1 1 1 5 4 2 3 4 5 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 1 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 1 4 6\n",
      " 2 4 1 5 0 0 0 7 1 3 7 4 5 7 6 4 6 5 4 1 1 2 1 3 7 2 7 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 7 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 1 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 4 4 0 1 2 1 5 0 2 3 7 7 3 2 3 0 6 2 3 7 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 3 7 4 1 4 5 5 1 1 7 4 3 2 5 7 1 4 0 4 7 4 1 4 1 1 4 5 7 4\n",
      " 5 4 6 7 2 4 5 5 5 4 5 1 5 0 7 1 3 6 6 2 7 6 0 1 3 1 1 3 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 4 7 7 0 6 1 4 2 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 90.75630252100841\n",
      "\n",
      " Confusion Matrix: \n",
      " [[48  1  3  1  0  0  0  0]\n",
      " [ 0 48  0  1  0  0  0  1]\n",
      " [ 1  3 38  1  1  0  0  0]\n",
      " [ 0  2  0 40  0  0  0  0]\n",
      " [ 2  0  0  0 43  0  0  2]\n",
      " [ 0  3  0  0  0 44  0  0]\n",
      " [ 0  1  0  0  3  1 20  3]\n",
      " [ 0  1  1  0  1  0  0 43]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def select_features(X_train, X_test,n):\n",
    "    global pca\n",
    "    # configure to select a subset of features\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    pca = PCA(n_components = n)\n",
    "    X_train_fs = pca.fit_transform(X_train)\n",
    "    X_test_fs = pca.transform(X_test)\n",
    "    return X_train_fs, X_test_fs\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(5,25,5):\n",
    "    X_train_fs, X_test_fs = select_features(X_train, X_test,n)\n",
    "    \n",
    "    print (\"Explained Variance Ratio of \",n,\" Components:\")\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    print(explained_variance)\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(range(n), explained_variance, alpha=0.5, align='center',label='individual explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From PCA\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From PCA\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From PCA\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From PCA\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3fd6e7",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60d6be2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.96572524e-01 3.85744029e-01 1.17683447e-01 1.46914513e-30\n",
      " 1.19366594e-30 6.31460065e-31 5.77735233e-31]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "sc = StandardScaler()\n",
    "y_train = y_train.to_numpy(dtype='int')\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "X_train = lda.fit_transform(X_train,y_train)\n",
    "X_test = lda.transform(X_test)\n",
    "explained_variance = lda.explained_variance_ratio_\n",
    "print(explained_variance)\n",
    "with plt.style.context('dark_background'):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(range(len(explained_variance)), explained_variance, alpha=0.5, align='center',label='individual explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d89199f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio\n",
      "[0.24687673 0.17522353 0.09728942 0.07379666 0.05075452 0.04395209\n",
      " 0.03642079 0.02999141 0.02366637 0.02055695 0.01702147 0.01399789\n",
      " 0.01255882 0.01063917 0.0105776  0.00911705 0.00895912 0.00793295\n",
      " 0.00630083 0.00605789]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjDklEQVR4nO3dfZhVZb3/8ffHUUNFDYE6JiB4fiiBguKImITASfLpYCmGpqWWoqSldnnSrjpiar/f6YTVoUwOmU8dEzW00AMqWGohFA8iKgISos4Rn4gDIvmAfH9/rDXjZth7WAOzZtbMfF7Xta+99lr3vfZ337PZX9Za97pvRQRmZmZFs1NLB2BmZlaOE5SZmRWSE5SZmRWSE5SZmRWSE5SZmRXSzi0dQFPq0qVL9OzZs6XDMDOzMhYsWPBmRHTNWr5NJaiePXsyf/78lg7DzMzKkPRiY8r7FJ+ZmRWSE5SZmRWSE5SZmRVSm7oGZdbavP/++9TU1PDOO++0dChmTaZDhw5069aNXXbZZYf2k2uCknQc8B9AFXBTRPxbve1nAlekLzcA4yLiqXTbKuAt4ANgU0RU5xmrWUuoqalhzz33pGfPnkhq6XDMdlhEsGbNGmpqaujVq9cO7Su3BCWpCrgBOBaoAeZJmhYRS0qKvQAcExFrJR0PTAaOLNk+PCLezCtGs5b2zjvvODlZmyKJzp0788Ybb+zwvvK8BjUIWBERKyPiPWAKcHJpgYh4IiLWpi/nAt1yjMeskJycrK1pqu90nglqP+Dlktc16bpKvgrMKHkdwMOSFkgaW6mSpLGS5kua3xQZ28zMiiHPa1DlUmjZyackDSdJUENKVh8dEa9I+hgwU9LSiHh8qx1GTCY5NUh1dbUnt7JW7cczlzfp/i479sBtlvnUpz7FE088kXmfjz76KBMmTOCBBx5g2rRpLFmyhCuvvLJi+auuuoqhQ4fymc98puJ+tkftjfldunTZrvrbMmzYMCZMmEB1deXL3+eddx7f/OY36du37w6/X16fpyljbG55JqgaoHvJ627AK/ULSeoP3AQcHxFratdHxCvp8+uS7iM5ZbhVgjKzHdOY5FTfqFGjGDVqVINlrrnmmu3ef9HddNNNLR1Cgz744IPCx9iQPE/xzQN6S+olaVfgdGBaaQFJPYB7gS9FxPKS9XtI2rN2GRgJPJNjrEDyv9fGPsxau44dOwLJEc2wYcMYPXo0ffr04cwzz6R2xu0HH3yQPn36MGTIEO699966urfeeisXX3wx69ato2fPnmzevBmAjRs30r17d95//33OOeccfvOb3zS4n6uvvpoJEybUvT744INZtWoVAJ/73Oc4/PDD6devH5MnT97m53n44Yc56qijGDhwIKeddhobNmzgxRdfpHfv3rz55pts3ryZT3/60zz88MOsWrWKPn36cPbZZ9O/f39Gjx7Nxo0bt9rnuHHjqK6upl+/fowfP75u/bBhw+qGV+vYsSPf+c53GDBgAIMHD+a1114D4I033uDUU0/liCOO4IgjjmD27NkArFmzhpEjR3LYYYdxwQUXUG528xtvvJFvfetbW7T317/+9QbbpWPHjlx11VUceeSRzJkzZ4sYK32Onj17Mn78eAYOHMghhxzC0qVLAdiwYQPnnnsuhxxyCP3792fq1KkV2zgPuSWoiNgEXAw8BDwH3B0Rz0q6UNKFabGrgM7AzyUtklQ7kN7HgT9Jegr4C/DfEfFgXrGaWeLJJ5/kJz/5CUuWLGHlypXMnj2bd955h/PPP5/777+fP/7xj7z66qtb1dt7770ZMGAAjz32GAD3338/n/3sZ7e4DybLfsq5+eabWbBgAfPnz2fixImsWbOmYtk333yT6667jlmzZrFw4UKqq6v50Y9+xP77788VV1zBhRdeyPXXX0/fvn0ZOXIkAMuWLWPs2LEsXryYvfbai5///Odb7ff73/8+8+fPZ/HixTz22GMsXrx4qzJvv/02gwcP5qmnnmLo0KH84he/AOCSSy7hsssuY968eUydOpXzzjsPgO9973sMGTKEJ598klGjRvHSSy9ttc/Ro0dvkcjvuusuxowZ02C7vP322xx88MH8+c9/ZsiQIVvsr6HP0aVLFxYuXMi4cePq/rNw7bXXsvfee/P000+zePFiRowYUbGN85DrfVARMR2YXm/dpJLl84DzytRbCQzIMzYz29qgQYPo1i3pTHvooYeyatUqOnbsSK9evejduzcAZ511VtkjmTFjxnDXXXcxfPhwpkyZwte+9rUtti9dujTTfuqbOHEi9913HwAvv/wyzz//PJ07dy5bdu7cuSxZsoSjjz4agPfee4+jjjoKSK7F3HPPPUyaNIlFixbV1enevXtd+bPOOouJEydy+eWXb7Hfu+++m8mTJ7Np0yZWr17NkiVL6N+//xZldt11V0466SQADj/8cGbOnAnArFmzWLLkw7tr1q9fz1tvvcXjjz9el3xOPPFEOnXqtNXn6dq1KwcccABz586ld+/eLFu2rC7WSu1SVVXFqaeeWrZ9Gvocp5xySl3stXHNmjWLKVOm1NXv1KkTDzzwQMU2bmoeScLM6nzkIx+pW66qqmLTpk1Atm7Do0aN4tvf/jZ/+9vfWLBgASNGjNiqTKX97LzzznWnB4G6kTUeffRRZs2axZw5c9h9990ZNmxYg6NuRATHHnssd95551bbNm7cSE1NDZCcutpzzz3LxlT/9QsvvMCECROYN28enTp14pxzzikbwy677FJXt7TtNm/ezJw5c9htt922qpOlXceMGcPdd99Nnz59+PznP4+kBtulQ4cOVFVVbbWfbX2O2r99aewRsVWMDbVxU/NYfGbWoD59+vDCCy/w17/+FaDiD1PHjh0ZNGgQl1xyCSeddNJWP5IN7adnz54sXLgQgIULF/LCCy8AsG7dOjp16sTuu+/O0qVLmTt3boOxDh48mNmzZ7NixQogSUrLlyfXiq+44grOPPNMrrnmGs4///y6Oi+99BJz5sypi6n+abH169ezxx57sPfee/Paa68xY8YMGmPkyJH87Gc/q3tde/Q2dOhQ7rjjDgBmzJjB2rVry1XnlFNO4be//S133nln3em9xrbL9n6O+rGvXbu2wTZuaj6CMiuQLN3Cm1uHDh2YPHkyJ554Il26dGHIkCE880z5PktjxozhtNNO49FHH23Ufk499VRuv/12Dj30UI444ggOPDBph+OOO45JkybRv39/DjroIAYPHtxgrF27duXWW2/ljDPO4N133wXguuuuY/Xq1cybN4/Zs2dTVVXF1KlTueWWWxg+fDif/OQnue2227jgggvo3bs348aN22KfAwYM4LDDDqNfv34ccMABdae2spo4cSIXXXQR/fv3Z9OmTQwdOpRJkyYxfvx4zjjjDAYOHMgxxxxDjx49ytbv1KkTffv2ZcmSJQwaNGi72mV7P8d3v/tdLrroIg4++GCqqqoYP348p5xyStk2rv2bNSWV6znSWlVXV8eOTFi4Pb3yiviDYq3Hc889xyc/+cmWDqPdWrVqFSeddFLFhGvbr9x3W9KCxoyr6lN8ZmZWSE5QZtZu9ezZ00dPBeYEZdbC2tJpdjNouu+0E5RZC+rQoQNr1qxxkrI2o3Y+qA4dOuzwvtyLz6wFdevWjZqamiaZO8esKGpn1N1RTlBmLWiXXXbZ4VlHzdoqn+IzM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCyjVBSTpO0jJJKyRdWWb7mZIWp48nJA3IWtfMzNq23BKUpCrgBuB4oC9whqS+9Yq9ABwTEf2Ba4HJjahrZmZtWJ5HUIOAFRGxMiLeA6YAJ5cWiIgnImJt+nIu0C1rXTMza9vyTFD7AS+XvK5J11XyVWBGY+tKGitpvqT5b7zxxg6Ea2ZmRZJnglKZdVG2oDScJEFd0di6ETE5Iqojorpr167bFaiZmRXPzjnuuwboXvK6G/BK/UKS+gM3AcdHxJrG1DUzs7YrzyOoeUBvSb0k7QqcDkwrLSCpB3Av8KWIWN6YumZm1rbldgQVEZskXQw8BFQBN0fEs5IuTLdPAq4COgM/lwSwKT1dV7ZuXrGamVnx5HmKj4iYDkyvt25SyfJ5wHlZ65qZWfuxzVN8krpJuk/SG5JekzRVUrdt1TMzM9sRWa5B3UJy/Wdfkq7e96frzMzMcpMlQXWNiFsiYlP6uBVwf24zM8tVlgT1pqSzJFWlj7OANdusZWZmtgOyJKivAF8AXgVWA6PTdWZmZrnZZi++iHgJGNUMsZiZmdWpmKAkfSsi/l3STykzzFBEfCPXyMzMrF1r6AjqufR5fnMEYmZmVqpigoqI+9PFjRFxT+k2SaflGpWZmbV7WTpJfDvjOjMzsybT0DWo44ETgP0kTSzZtBewKe/AzMysfWvoGtQrJNefRgELSta/BVyWZ1BmZmYNXYN6CnhK0q8j4v1mjMnMzCzTaOY9Jf0/oC/QoXZlRByQW1RmZtbuZR0s9kaS607DgduBX+UZlJmZWZYEtVtEPAIoIl6MiKuBEfmGZWZm7V2WU3zvSNoJeD6d5fZ/gI/lG5aZmbV3WRLUpcDuwDeAa0lO852dY0yt2o9nLm90ncuOPTCHSMzMWrcGE5SkKuALEfEvwAbg3GaJyszM2r0Gr0FFxAfA4ZLUTPGYmZkB2U7xPQn8TtI9wNu1KyPi3tyiMjOzdi9LgtqHZAbd0p57AThBmZlZbrJMWOjrTmZm1uyy3AdlZmbW7JygzMyskJygzMyskLaZoCR9XNIvJc1IX/eV9NX8QzMzs/YsyxHUrcBDwCfS18tJRpcwMzPLTZYE1SUi7gY2A0TEJuCDXKMyM7N2L0uCeltSZ5J7n5A0GFiXa1RmZtbuZblR95vANOAfJc0GugKjc43KzMzavSw36i6UdAxwECBgmaeANzOzvGXpxXcR0DEino2IZ4COkr6Wf2hmZtaeZbkGdX5E/G/ti4hYC5yfW0RmZmZkS1A7lU63kc4RtWt+IZmZmWXrJPEQcLekSSQ9+S4EHsw1KjMza/eyHEFdAfweGAdcBDwCfCvLziUdJ2mZpBWSriyzvY+kOZLelXR5vW2rJD0taZGk+Vnez8zM2o4svfg2Azemj8zSU4E3AMcCNcA8SdMiYklJsb8B3wA+V2E3wyPizca8r5mZtQ1ZevEdLWmmpOWSVkp6QdLKDPseBKyIiJUR8R4wBTi5tEBEvB4R8wB3Wzczsy1kuQb1S+AyYAGNG+JoP+Dlktc1wJGNqB/Aw5IC+M+ImNyIumZm1splSVDrImLGduxbZdZFI+ofHRGvSPoYMFPS0oh4fKs3kcYCYwF69OixHWGamVkRZekk8QdJP5R0lKSBtY8M9WqA7iWvuwGvZA0sIl5Jn18H7iM5ZViu3OSIqI6I6q5du2bdvZmZFVyWI6ja03LVJesCGLGNevOA3pJ6Af8DnA58MUtQkvYAdoqIt9LlkcA1WeqamVnbkKUX3/Dt2XFEbJJ0Mcl9VFXAzRHxrKQL0+2TJP0DMB/YC9gs6VKgL9AFuC+9P3hn4NcR4XuvzMzakSxHUEg6EegHdKhdFxHbPKKJiOnA9HrrJpUsv0py6q++9cCALLGZmVnblKWb+SRgDPB1ko4PpwH75xyXmZm1c1k6SXwqIr4MrI2I7wFHsWXnBzMzsyaXJUH9PX3eKOkTJDfV9sovJDMzs2zXoB6Q9FHgh8BCkh58N+UZlJmZWZZefNemi1MlPQB0iIh1+YZlZmbtXcUEJWlERPxe0illthER9+YbmpmZtWcNHUEdQzLNxj+X2RaAE5SZmeWmYoKKiPGSdgJmRMTdzRiTmZlZw7340rmgLm6mWMzMzOpk6WY+U9LlkrpL2qf2kXtkZmbWrmXpZv6V9PmiknUBHND04ZiZmSWydDP3TblmZtbssg4WezDJKOOlg8XenldQZmZm20xQksYDw0gS1HTgeOBPgBOUmZnlJksnidHAPwGvRsS5JNNgfCTXqMzMrN3LNFhs2t18k6S9gNdxBwkzM8tZlmtQ89PBYn8BLAA2AH/JMygzM7Msvfi+li5OkvQgsFdELM43LDMza++yzKj7O0lflLRHRKxycjIzs+aQ5RrUj4AhwBJJ90gaLanDtiqZmZntiCyn+B4DHpNUBYwAzgduBvbKOTYzM2vHst6ouxvJtBtjgIHAbXkGZWZmluVG3buAI4EHgRuAR9Nu52ZmZrnJcgR1C/DFiPgg72DMzMxqZbkG9WBzBGJmZlYqSy8+MzOzZucEZWZmhVTxFJ+kgQ1VjIiFTR+OmZlZoqFrUNenzx2AauApQEB/4M8kN++amZnlouIpvogYHhHDgReBgRFRHRGHA4cBK5orQDMza5+yXIPqExFP176IiGeAQ3OLyMzMjGz3QT0n6Sbgv4AAzgKeyzUqMzNr97IkqHOBccAl6evHgRtzi8jMzIxsN+q+I2kSMD0iljVDTGZmZpnmgxoFLCIZiw9Jh0qalnNcZmbWzmXpJDEeGAT8L0BELAJ65haRmZkZ2RLUpohYl3skZmZmJbIkqGckfRGoktRb0k+BJ7LsXNJxkpZJWiHpyjLb+0iaI+ldSZc3pq6ZmbVtWRLU14F+wLvAncB64NJtVUpn4L0BOB7oC5whqW+9Yn8DvgFM2I66ZmbWhmXpxbcR+E76aIxBwIqIWAkgaQpwMrCkZN+vA69LOrGxdc3MrG3LMqPugcDlJB0j6spHxIhtVN0PeLnkdQ3JzLxZZK4raSwwFqBHjx4Zd29mZkWX5Ubde4BJwE1AY2bVVZl10dR1I2IyMBmguro66/7NzKzgsiSoTRGxPSNH1ADdS153A15phrqt2o9nLt+uepcde2ATR2Jm1rKydJK4X9LXJO0raZ/aR4Z684DeknpJ2hU4Hch6g++O1DUzszYgyxHU2enzv5SsC+CAhipFxCZJFwMPAVXAzRHxrKQL0+2TJP0DMB/YC9gs6VKgb0SsL1e3EZ/LzMxauSy9+Hpt784jYjowvd66SSXLr5KcvstU18zM2o+GpnwfERG/l3RKue0RcW9+YZmZWXvX0BHUMcDvgX8usy0AJygzM8tNxQQVEePT53ObLxwzM7NElk4SpCM99AM61K6LiGvyCsrMzCzLfFCTgDEkY/IJOA3YP+e4zMysnctyH9SnIuLLwNqI+B5wFFveRGtmZtbksiSov6fPGyV9Angf2O6u52ZmZllkuQb1gKSPAj8EFpL04Lspz6DMzMyy3Kh7bbo4VdIDQAfPsGtmZnlr6Ebdsjfoptt8o66ZmeWqoSOocjfo1vKNumZmlquGbtT1DbpmZtZistwH1VnSREkLJS2Q9B+SOjdHcGZm1n5l6WY+BXgDOBUYnS7flWdQZmZmWbqZ71PSkw/gOkmfyykeMzMzINsR1B8knS5pp/TxBeC/8w7MzMzatywJ6gLg18C76WMK8E1Jb0lan2dwZmbWfmW5UXfP5gjEzMys1DYTlKSvRsQvS15XAd9NB461AvrxzOWNrnPZsQfmEImZ2fbLcorvnyRNl7SvpEOAuYCPqszMLFdZTvF9UdIY4GlgI3BGRMzOPTIzM2vXstyo2xu4BJgKrAK+JGn3nOMyM7N2LsspvvuBf42IC4BjgOeBeblGZWZm7V6WG3UHRcR6gIgI4HpJ0/INy8zM2ruKR1CSvgUQEeslnVZvsweSNTOzXDV0iu/0kuVv19t2XA6xmJmZ1WkoQanCcrnXZmZmTaqhBBUVlsu9NjMza1INdZIYkI61J2C3knH3BHTIPTIzM2vXGppRt6o5AzEzMyuV5T4oMzOzZucEZWZmheQEZWZmheQEZWZmheQEZWZmheQEZWZmhZRrgpJ0nKRlklZIurLMdkmamG5fLGlgybZVkp6WtEjS/DzjNDOz4skymvl2SaeGvwE4FqgB5kmaFhFLSoodD/ROH0cCN6bPtYZHxJt5xWhmZsWV5xHUIGBFRKyMiPeAKcDJ9cqcDNweibnARyXtm2NMZmbWSuR2BAXsB7xc8rqGLY+OKpXZD1hNMt7fw5IC+M+ImFzuTSSNBcYC9OjRo2kib+d+PHP5dtW77NgDmzgSM2vP8jyCKjfief1BZhsqc3REDCQ5DXiRpKHl3iQiJkdEdURUd+3adfujNTOzQskzQdUA3UtedwNeyVomImqfXwfuIzllaGZm7USeCWoe0FtSL0m7kkyAWH+q+GnAl9PefIOBdRGxWtIekvYEkLQHMBJ4JsdYzcysYHK7BhURmyRdDDwEVAE3R8Szki5Mt08CpgMnACuAjXw4lfzHgfsk1cb464h4MK9YzcysePLsJEFETCdJQqXrJpUsB3BRmXorgQF5xmZmZsWWa4Ky9mt7egK6F6CZlfJQR2ZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkjuZm6F5a7qZu2bj6DMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQ3IvP2ixPXW/WuvkIyszMCskJyszMCskJyszMCskJyszMCsmdJMwa4OGWzFqOj6DMzKyQnKDMzKyQfIrPLGc+TWi2fXwEZWZmheQEZWZmheRTfGYF51OE1l75CMrMzArJCcrMzArJp/jM2gGfJrTWyAnKzLbJU5dYS/ApPjMzKyQfQZlZs2iK04w+Vdm++AjKzMwKyUdQZtZuNMW1NB/FNR8nKDOzZuQOJ9k5QZmZtTLt5Xqer0GZmVkhOUGZmVkh5ZqgJB0naZmkFZKuLLNdkiam2xdLGpi1rpmZtW25JShJVcANwPFAX+AMSX3rFTse6J0+xgI3NqKumZm1YXkeQQ0CVkTEyoh4D5gCnFyvzMnA7ZGYC3xU0r4Z65qZWRumiMhnx9Jo4LiIOC99/SXgyIi4uKTMA8C/RcSf0tePAFcAPbdVt2QfY0mOvgAOApbl8oGgC/BmTvtuKq0hRmgdcbaGGKF1xNkaYoTWEWdriBEqx7l/RHTNupM8u5mrzLr62bBSmSx1k5URk4HJjQut8STNj4jqvN9nR7SGGKF1xNkaYoTWEWdriBFaR5ytIUZoujjzTFA1QPeS192AVzKW2TVDXTMza8PyvAY1D+gtqZekXYHTgWn1ykwDvpz25hsMrIuI1RnrmplZG5bbEVREbJJ0MfAQUAXcHBHPSrow3T4JmA6cAKwANgLnNlQ3r1gzyv00YhNoDTFC64izNcQIrSPO1hAjtI44W0OM0ERx5tZJwszMbEd4JAkzMyskJygzMyskJ6gSOzI0UzPG2F3SHyQ9J+lZSZeUKTNM0jpJi9LHVc0dZxrHKklPpzHML7O9RdtT0kElbbRI0npJl9Yr0yJtKelmSa9LeqZk3T6SZkp6Pn3uVKFuswwTViHGH0pamv4975P00Qp1G/xuNEOcV0v6n5K/6wkV6rZkW95VEt8qSYsq1G2Wtqz025Pr9zIi/Eiuw1UBfwUOIOnm/hTQt16ZE4AZJPdpDQb+3AJx7gsMTJf3BJaXiXMY8EAB2nQV0KWB7S3envX+/q+S3EjY4m0JDAUGAs+UrPt34Mp0+UrgBxU+R4Pf45xjHAnsnC7/oFyMWb4bzRDn1cDlGb4TLdaW9bZfD1zVkm1Z6bcnz++lj6A+tCNDMzWbiFgdEQvT5beA54D9mjOGJtTi7Vnin4C/RsSLLfT+W4iIx4G/1Vt9MnBbunwb8LkyVZttmLByMUbEwxGxKX05l+QexhZVoS2zaNG2rCVJwBeAO/N476wa+O3J7XvpBPWh/YCXS17XsPUPf5YyzUZST+Aw4M9lNh8l6SlJMyT1a97I6gTwsKQFSoakqq9I7Xk6lX8AitCWAB+P5D5B0uePlSlTpDb9CskRcjnb+m40h4vTU5E3VzgtVZS2/DTwWkQ8X2F7s7dlvd+e3L6XTlAf2pGhmZqdpI7AVODSiFhfb/NCklNVA4CfAr9t5vBqHR0RA0lGpb9I0tB62wvRnkpuBh8F3FNmc1HaMquitOl3gE3AHRWKbOu7kbcbgX8EDgVWk5xCq68QbQmcQcNHT83altv47alYrcy6bbalE9SHdmRopmYlaReSL8gdEXFv/e0RsT4iNqTL04FdJHVp5jCJiFfS59eB+0gO80sVoj1J/mEvjIjX6m8oSlumXqs9BZo+v16mTIu3qaSzgZOAMyO9AFFfhu9GriLitYj4ICI2A7+o8P5FaMudgVOAuyqVac62rPDbk9v30gnqQzsyNFOzSc9H/xJ4LiJ+VKHMP6TlkDSI5O+8pvmiBEl7SNqzdpnk4vkz9Yq1eHumKv4PtQhtWWIacHa6fDbwuzJlWnSYMEnHkcxIMCoiNlYok+W7kat61zo/X+H9izDk2meApRFRU25jc7ZlA789+X0v8+750ZoeJL3KlpP0NvlOuu5C4MJ0WSQTKf4VeBqoboEYh5AcGi8GFqWPE+rFeTHwLElPmbnAp1ogzgPS938qjaWo7bk7ScLZu2Rdi7clScJcDbxP8r/PrwKdgUeA59PnfdKynwCmN/Q9bsYYV5Bca6j9bk6qH2Ol70Yzx/mr9Du3mOSHct+itWW6/tba72JJ2RZpywZ+e3L7XnqoIzMzKySf4jMzs0JygjIzs0JygjIzs0JygjIzs0JygjIzs0JygrI2Q9IH6YjOz0i6R9LuFco9sZ37r5Y0cQfi27C9dVsTSZdWanuzxnA3c2szJG2IiI7p8h3Agii5oVBSVUR8UIT42jJJq0juaXuzpWOx1s1HUNZW/RH4P0rmc/qDpF+T3JhZdySTbntU0m+UzGF0R8moEUdIeiIdJPYvkvZMyz+Qbr9a0q8k/V7JPDjnp+s7SnpE0kIlc/Rsc8RmSV9OBy19StKv0nX7p/tZnD73SNffKunG9DOtlHRMOtjpc5JuLdnnBknXp3E8Iqlruv5QSXP14XxNndL1j0r6QfpZl0v6dLq+SskcT/PSOhc01HaSvkFyg+Yf0hir0pifSdvjsib421p7kecd3H740ZwPYEP6vDPJcCvjSOZzehvoVabcMGAdybhgOwFzSO6W3xVYCRyRltsr3ecw0rmhSOYTegrYDehCMnrCJ9Jye6VlupCMrKDS960Xcz9gGel8Pnx4F/79wNnp8leA36bLt5JMVSCS6QrWA4ek8S8ADk3LBclYeABXAT9LlxcDx6TL1wA/SZcfBa5Pl08AZqXLY4HvpssfAeYDvSq1XVpuVcnnORyYWfJ5P9rS3xM/Ws/DR1DWluymZNbR+cBLJOOGAfwlIl6oUOcvEVETyaChi4CewEHA6oiYB3UDxm4qU/d3EfH3SE5l/YFkkE4B/1fSYmAWyZQCH28g5hHAb9J9EBG1cwIdBfw6Xf4VSeKsdX9EBMkR4WsR8XQa/7Np/ACb+XCA0f8ChkjamyRBPJauv41korxatYN/LijZz0iS8RIXkUyt0BnonW4r13b1rQQOkPTTdJy+rKNfm7FzSwdg1oT+HhGHlq5Iz9i93UCdd0uWPyD5NyGyTatQv0wAZwJdgcMj4v30ekyHBvaxPe9VG/Nmtox/M5X/TWd5j9p91bZDbXxfj4iHSgtKGkb5ttvyTSPWShoAfBa4iGTiva9kiMXMR1BmZSwFPiHpCID0+lO5H/6TJXWQ1JnklNc8YG/g9TQ5DQf238Z7PQJ8Id0HkvZJ1z9BMuIzJEnvT438DDsBo9PlLwJ/ioh1wNra60vAl4DHylUu8RAwTsk0C0g6MB01uyFvkUwJjpKpSXaKiKnAv5JMa26WiY+gzOqJiPckjQF+Kmk34O8k0x7U9xfgv4EewLUR8Urae/B+SfNJTnst3cZ7PSvp+8Bjkj4AngTOAb4B3CzpX4A3gHMb+THeBvpJWkByrWhMuv5sYFLaDXxlhv3eRHLqbmHageQNyk/pXWoyMEPSauBS4BZJtf8Z/nbjPoa1Z+5mbrYdJF1N0ulhQkvHUk576dJubZtP8ZmZWSH5CMrMzArJR1BmZlZITlBmZlZITlBmZlZITlBmZlZITlBmZlZI/x/ir/WRclLm7QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From LDA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      1.00      0.26        53\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.00      0.00      0.00        44\n",
      "           3       0.00      0.00      0.00        42\n",
      "           4       0.00      0.00      0.00        47\n",
      "           5       0.00      0.00      0.00        47\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.15       357\n",
      "   macro avg       0.02      0.12      0.03       357\n",
      "weighted avg       0.02      0.15      0.04       357\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 14.84593837535014\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0]\n",
      " [44  0  0  0  0  0  0  0]\n",
      " [42  0  0  0  0  0  0  0]\n",
      " [47  0  0  0  0  0  0  0]\n",
      " [47  0  0  0  0  0  0  0]\n",
      " [28  0  0  0  0  0  0  0]\n",
      " [46  0  0  0  0  0  0  0]]\n",
      "SVM From LDA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "RM From LDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "Xgboost From LDA\n",
      "[17:46:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        42\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        47\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 5 3 0 4 0 0 1 0 3 6 1 3 5 5 3 6 4 1 0 4 1 5 3 3 0 6 2 5 2 1 5 7 0 4 0 5\n",
      " 0 2 7 1 4 5 0 1 1 5 2 0 5 1 7 3 2 1 4 6 3 2 6 3 0 0 1 3 7 1 1 6 0 2 0 6 0\n",
      " 0 0 0 4 2 5 1 4 0 7 4 0 1 6 1 1 1 1 5 4 2 3 4 6 0 0 1 1 4 3 7 4 2 0 5 7 5\n",
      " 3 7 7 1 3 2 3 7 5 1 7 7 0 1 5 3 1 6 4 3 5 6 4 1 5 5 4 2 7 1 4 7 5 2 2 4 6\n",
      " 2 4 3 5 4 0 0 4 1 3 7 4 5 7 6 2 6 5 4 1 1 2 1 3 7 2 1 1 2 0 0 1 5 1 2 3 3\n",
      " 0 2 2 3 7 5 4 5 7 2 1 0 7 4 2 5 0 1 4 3 5 4 4 0 5 7 0 6 2 2 7 0 5 2 3 7 2\n",
      " 3 3 2 5 0 0 7 3 6 7 0 0 7 7 4 0 3 2 1 5 0 2 3 7 7 3 0 3 0 6 2 3 6 0 4 6 0\n",
      " 7 7 0 2 2 3 7 1 2 6 4 1 4 5 5 1 1 7 4 3 2 5 7 2 4 0 4 7 4 5 4 1 2 4 5 7 4\n",
      " 5 4 6 7 7 4 5 5 5 4 5 5 5 2 7 1 3 6 6 2 7 6 0 6 3 1 1 0 1 1 1 5 2 5 5 7 3\n",
      " 6 4 4 7 4 6 7 7 0 6 1 4 0 7 2 4 3 3 2 3 7 0 3 0]\n",
      "\n",
      " Accuracy: \n",
      " 100.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[53  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0 42  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0 47  0  0]\n",
      " [ 0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 46]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 100.0,\n",
       " 'model_obj': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "               gamma=0, gpu_id=-1, importance_type=None,\n",
       "               interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
       "               max_depth=6, min_child_weight=1, missing=nan,\n",
       "               monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "               num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "               random_state=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "               subsample=1, tree_method='exact', validate_parameters=1,\n",
       "               verbosity=None)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_features(X_train, X_test,y_train):\n",
    "    global lda\n",
    "    # configure to select a subset of features\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    y_train = y_train.to_numpy(dtype='int')\n",
    "    lda = LinearDiscriminantAnalysis(solver='svd')\n",
    "    X_train_fs = lda.fit_transform(X_train,y_train)\n",
    "    X_test_fs = lda.transform(X_test)\n",
    "    return X_train_fs, X_test_fs\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "\n",
    "X_train_fs, X_test_fs  = select_features(X_train, X_test,y_train)\n",
    "    \n",
    "print (\"Explained Variance Ratio\")\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(range(len(explained_variance)), explained_variance, alpha=0.5, align='center',label='individual explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "    # fit the model\n",
    "print (\"Logistic Regression From LDA\")\n",
    "LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "print (\"SVM From LDA\")\n",
    "SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "print (\"RM From LDA\")\n",
    "RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "print (\"Xgboost From LDA\")\n",
    "XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053750f",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9b48180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.74      0.39        53\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.00      0.00      0.00        44\n",
      "           3       0.00      0.00      0.00        42\n",
      "           4       0.00      0.00      0.00        47\n",
      "           5       0.47      0.53      0.50        47\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.33      1.00      0.50        46\n",
      "\n",
      "    accuracy                           0.31       357\n",
      "   macro avg       0.13      0.28      0.17       357\n",
      "weighted avg       0.14      0.31      0.19       357\n",
      "\n",
      "Prediction Vector: \n",
      " [0 7 5 0 0 0 0 5 0 5 0 3 5 5 5 5 0 0 5 0 0 7 7 7 7 0 0 0 5 0 7 5 7 0 0 7 7\n",
      " 0 0 7 5 0 5 0 7 5 5 0 0 7 7 7 7 0 7 0 0 5 0 0 7 0 7 7 7 7 7 7 0 3 0 0 0 0\n",
      " 0 0 0 0 0 7 7 0 0 7 0 0 7 0 5 7 7 7 7 0 0 7 0 7 0 7 7 7 0 7 7 0 0 0 7 7 5\n",
      " 5 7 7 3 7 0 7 7 7 5 7 7 0 7 2 7 5 0 0 7 5 7 0 7 7 5 0 0 7 7 0 7 7 3 0 0 7\n",
      " 0 0 7 5 0 0 0 0 5 5 7 0 5 7 0 0 0 5 0 7 7 0 7 7 7 0 5 7 3 7 0 7 5 7 0 7 7\n",
      " 0 3 0 5 7 5 0 7 7 3 7 0 7 0 0 5 7 7 0 7 5 0 0 0 5 7 3 0 0 0 7 0 5 0 7 7 0\n",
      " 7 7 3 7 3 3 7 5 0 7 7 0 7 7 0 0 7 3 7 5 0 0 7 7 7 7 0 5 7 0 0 7 0 7 0 0 0\n",
      " 7 7 0 0 0 5 7 7 0 0 0 5 0 5 5 5 5 7 0 7 0 5 7 0 0 0 0 7 0 7 0 7 0 0 7 7 0\n",
      " 5 0 0 7 7 0 7 5 2 0 2 2 7 0 7 5 7 0 0 0 7 0 7 0 7 5 7 0 7 5 7 7 0 2 5 7 5\n",
      " 0 0 0 7 0 0 7 7 0 7 7 0 0 7 0 0 7 5 0 7 7 7 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 30.81232492997199\n",
      "\n",
      " Confusion Matrix: \n",
      " [[39  0  0  4  0  0  0 10]\n",
      " [ 0  0  0  2  0 15  0 33]\n",
      " [38  0  0  6  0  0  0  0]\n",
      " [ 1  0  0  0  0 13  0 28]\n",
      " [47  0  0  0  0  0  0  0]\n",
      " [ 0  0  5  0  0 25  0 17]\n",
      " [24  0  0  0  0  0  0  4]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "SVM From TSNE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.51      0.31        53\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.00      0.00      0.00        44\n",
      "           3       0.00      0.00      0.00        42\n",
      "           4       0.00      0.00      0.00        47\n",
      "           5       0.40      0.53      0.46        47\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.31      1.00      0.47        46\n",
      "\n",
      "    accuracy                           0.27       357\n",
      "   macro avg       0.12      0.26      0.15       357\n",
      "weighted avg       0.13      0.27      0.17       357\n",
      "\n",
      "Prediction Vector: \n",
      " [0 7 5 0 0 7 4 5 0 5 0 5 5 5 5 5 0 0 5 4 0 7 7 7 7 0 0 0 5 0 7 5 7 0 7 7 7\n",
      " 7 7 7 5 0 5 4 7 5 5 0 0 7 7 7 7 0 7 0 7 5 4 0 7 0 7 7 7 7 7 7 0 3 7 0 0 4\n",
      " 0 4 0 0 0 7 7 0 0 7 0 0 7 0 5 7 7 7 7 0 0 7 0 7 7 7 7 7 0 7 7 7 7 0 7 7 5\n",
      " 5 7 7 5 7 0 5 7 7 5 7 7 7 7 4 5 5 0 0 5 5 7 7 7 7 5 0 7 7 7 0 7 7 3 0 0 7\n",
      " 7 0 7 5 0 0 0 0 5 5 7 0 5 7 0 0 0 5 0 7 7 0 7 7 7 4 5 7 3 7 0 7 5 7 0 7 5\n",
      " 0 3 0 5 7 5 0 7 7 3 7 0 7 7 0 5 7 7 0 5 5 0 0 0 5 7 3 0 0 0 7 0 5 0 7 7 0\n",
      " 7 7 3 7 3 3 7 5 0 7 7 0 7 7 0 7 7 3 7 5 0 0 7 7 7 7 0 5 7 0 0 7 0 7 0 0 7\n",
      " 7 7 0 0 0 5 7 7 0 0 7 5 0 5 5 5 5 7 0 7 0 5 7 0 0 4 0 7 0 7 0 7 0 0 7 7 0\n",
      " 5 0 0 7 7 0 7 5 4 0 4 4 7 0 7 5 5 0 0 0 7 7 7 0 5 5 7 0 7 5 7 7 0 4 5 7 5\n",
      " 0 7 0 7 0 0 7 7 0 7 7 0 0 7 0 0 7 5 0 7 7 7 4 0]\n",
      "\n",
      " Accuracy: \n",
      " 27.450980392156865\n",
      "\n",
      " Confusion Matrix: \n",
      " [[27  0  0  4  6  0  0 16]\n",
      " [ 0  0  0  0  0 17  0 33]\n",
      " [31  0  0  6  2  0  0  5]\n",
      " [ 0  0  0  0  1 20  0 21]\n",
      " [41  0  0  0  0  0  0  6]\n",
      " [ 0  0  0  0  5 25  0 17]\n",
      " [22  0  0  0  0  0  0  6]\n",
      " [ 0  0  0  0  0  0  0 46]]\n",
      "RM From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.19      0.17        53\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.26      0.34      0.30        44\n",
      "           3       0.13      0.07      0.09        42\n",
      "           4       0.00      0.00      0.00        47\n",
      "           5       0.45      0.55      0.50        47\n",
      "           6       0.10      0.07      0.08        28\n",
      "           7       0.45      0.98      0.62        46\n",
      "\n",
      "    accuracy                           0.28       357\n",
      "   macro avg       0.19      0.28      0.22       357\n",
      "weighted avg       0.20      0.28      0.22       357\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 5 2 0 6 4 5 0 5 4 3 5 5 5 5 0 2 3 4 0 7 0 0 0 2 4 2 5 2 7 5 7 2 1 7 7\n",
      " 6 6 7 5 2 5 4 3 5 5 2 2 0 7 7 0 4 7 2 6 5 0 0 0 0 7 7 7 7 7 7 4 3 6 2 0 4\n",
      " 2 4 2 2 2 5 7 0 2 7 2 2 3 4 5 3 7 3 7 0 0 7 2 7 6 7 3 3 0 7 7 1 6 0 0 7 5\n",
      " 5 7 7 3 0 2 5 7 0 3 7 7 6 7 0 5 5 2 0 5 5 7 1 7 0 5 2 6 7 3 2 0 7 1 4 2 7\n",
      " 6 0 7 5 2 2 2 0 5 5 7 0 5 7 4 4 2 5 2 7 7 2 7 7 7 0 5 7 1 7 0 7 5 7 0 3 5\n",
      " 2 1 2 5 7 5 0 7 7 1 7 0 7 6 0 5 7 3 0 5 5 2 0 0 5 7 3 4 2 2 7 2 5 2 0 7 2\n",
      " 3 7 1 7 3 3 7 5 4 7 7 0 7 7 2 6 7 1 3 5 0 6 7 7 7 7 0 5 7 2 2 3 4 7 2 0 6\n",
      " 7 7 2 6 2 5 7 7 0 4 6 5 0 5 5 3 5 7 2 7 6 5 7 4 0 4 2 7 0 0 2 7 4 0 0 7 2\n",
      " 5 2 4 7 7 0 0 5 4 0 0 4 0 6 7 5 5 4 0 6 7 6 7 0 5 5 7 0 7 5 3 7 2 0 5 7 5\n",
      " 0 1 2 7 2 4 7 7 2 7 3 0 2 7 2 2 7 5 0 7 7 7 0 2]\n",
      "\n",
      " Accuracy: \n",
      " 28.291316526610643\n",
      "\n",
      " Confusion Matrix: \n",
      " [[10  0 17  4  6  0  6 10]\n",
      " [ 0  0  0 16  0 12  0 22]\n",
      " [ 8  6 15  0  5  0 10  0]\n",
      " [ 7  0  0  3  0 20  0 12]\n",
      " [19  4 22  0  0  0  2  0]\n",
      " [13  0  0  0  2 26  0  6]\n",
      " [ 7  0  3  0 12  0  2  4]\n",
      " [ 1  0  0  0  0  0  0 45]]\n",
      "Xgboost From TSNE\n",
      "[17:46:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.19      0.15        53\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.33      0.34      0.34        44\n",
      "           3       0.18      0.07      0.10        42\n",
      "           4       0.00      0.00      0.00        47\n",
      "           5       0.45      0.55      0.50        47\n",
      "           6       0.10      0.07      0.08        28\n",
      "           7       0.43      0.98      0.60        46\n",
      "\n",
      "    accuracy                           0.28       357\n",
      "   macro avg       0.20      0.28      0.22       357\n",
      "weighted avg       0.20      0.28      0.22       357\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 5 2 0 6 4 5 0 5 4 3 5 5 5 5 0 0 3 4 0 7 0 0 0 2 4 2 5 2 7 5 7 2 0 7 7\n",
      " 6 6 7 5 2 5 4 7 5 5 2 2 0 7 7 0 4 7 2 6 5 0 0 0 0 7 7 7 7 7 7 4 3 6 2 0 4\n",
      " 2 4 2 2 2 5 7 0 2 7 2 2 3 4 5 7 7 3 7 0 0 7 2 7 6 7 3 7 0 7 7 0 6 0 0 7 5\n",
      " 5 7 7 3 0 2 5 7 0 3 7 7 6 7 0 5 5 0 0 5 5 7 0 7 0 5 0 6 7 7 0 0 7 1 4 0 7\n",
      " 6 0 7 5 2 2 2 0 5 5 7 0 5 7 4 4 2 5 2 7 7 2 7 7 7 0 5 7 1 7 0 7 5 7 0 3 5\n",
      " 2 1 2 5 7 5 0 7 7 1 7 0 7 6 0 5 7 3 0 5 5 0 0 0 5 7 3 4 2 2 7 2 5 2 0 7 2\n",
      " 3 7 1 7 3 3 7 5 4 7 7 0 7 7 2 6 7 1 7 5 0 6 7 7 7 7 0 5 7 0 2 3 4 7 2 0 6\n",
      " 7 7 2 6 2 5 7 7 0 4 6 5 0 5 5 3 5 7 0 7 6 5 7 4 0 4 2 7 0 0 0 7 4 0 0 7 0\n",
      " 5 0 4 7 7 0 0 5 4 0 0 4 0 6 7 5 5 4 0 6 7 6 7 0 5 5 7 0 7 5 3 7 2 0 5 7 5\n",
      " 0 0 2 7 0 4 7 7 2 7 7 0 2 7 2 2 7 5 0 7 7 7 0 2]\n",
      "\n",
      " Accuracy: \n",
      " 28.291316526610643\n",
      "\n",
      " Confusion Matrix: \n",
      " [[10  0 17  4  6  0  6 10]\n",
      " [ 0  0  0 10  0 12  0 28]\n",
      " [ 8  6 15  0  5  0 10  0]\n",
      " [ 7  0  0  3  0 20  0 12]\n",
      " [33  0 12  0  0  0  2  0]\n",
      " [13  0  0  0  2 26  0  6]\n",
      " [ 9  0  1  0 12  0  2  4]\n",
      " [ 1  0  0  0  0  0  0 45]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.19      0.16        53\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.15      0.09      0.11        44\n",
      "           3       0.24      0.48      0.32        42\n",
      "           4       0.19      0.17      0.18        47\n",
      "           5       0.00      0.00      0.00        47\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.26      0.59      0.36        46\n",
      "\n",
      "    accuracy                           0.19       357\n",
      "   macro avg       0.12      0.19      0.14       357\n",
      "weighted avg       0.13      0.19      0.15       357\n",
      "\n",
      "Prediction Vector: \n",
      " [7 7 3 4 0 0 7 7 0 3 4 5 3 3 3 3 0 2 3 7 7 5 7 7 7 4 2 0 3 0 5 3 0 4 0 7 7\n",
      " 0 0 0 3 4 3 7 7 3 3 0 2 7 7 7 7 7 3 0 0 1 4 0 7 7 7 3 3 7 3 3 4 7 0 4 0 7\n",
      " 4 7 0 4 0 3 3 0 0 0 4 4 7 4 3 7 7 7 7 0 4 3 4 7 0 7 3 7 0 3 7 0 0 2 7 7 3\n",
      " 1 7 7 3 0 2 1 3 7 5 7 7 0 3 1 3 3 0 7 3 1 7 0 5 7 1 2 0 7 7 0 7 3 4 7 0 7\n",
      " 0 2 7 3 4 2 2 0 3 1 0 7 1 7 4 7 4 3 0 3 7 0 3 3 7 4 3 3 4 7 2 7 3 3 2 7 1\n",
      " 4 4 0 3 3 1 0 7 3 4 5 2 0 0 4 3 7 7 7 3 3 0 0 2 1 7 3 4 0 0 0 0 3 0 0 7 4\n",
      " 7 1 4 7 3 7 7 1 0 7 7 2 7 3 4 0 3 4 7 3 2 7 3 7 3 3 2 3 7 0 0 7 4 7 0 0 0\n",
      " 7 7 4 7 0 3 0 3 0 4 0 3 7 1 1 3 3 7 2 3 7 3 0 7 0 7 4 7 0 7 0 3 7 0 7 7 0\n",
      " 1 2 4 7 7 2 7 3 3 2 1 3 7 7 7 3 3 4 0 4 3 0 4 0 1 3 3 2 7 3 7 3 2 1 3 3 1\n",
      " 0 0 0 3 2 4 7 3 4 7 7 0 2 0 2 4 7 1 4 3 3 4 1 2]\n",
      "\n",
      " Accuracy: \n",
      " 19.327731092436977\n",
      "\n",
      " Confusion Matrix: \n",
      " [[10  0 13  2 11  0  0 17]\n",
      " [ 0  0  0 28  0  6  0 16]\n",
      " [17  0  4  0 13  0  0 10]\n",
      " [ 2 11  0 20  0  0  0  9]\n",
      " [26  0  8  0  8  0  0  5]\n",
      " [ 0 11  0 22  0  0  0 14]\n",
      " [12  0  1  0 11  0  0  4]\n",
      " [ 9  0  0 10  0  0  0 27]]\n",
      "SVM From TSNE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        53\n",
      "           1       0.28      0.46      0.35        50\n",
      "           2       0.07      0.02      0.03        44\n",
      "           3       0.09      0.02      0.04        42\n",
      "           4       0.26      0.53      0.34        47\n",
      "           5       0.00      0.00      0.00        47\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.19      0.43      0.26        46\n",
      "\n",
      "    accuracy                           0.20       357\n",
      "   macro avg       0.11      0.18      0.13       357\n",
      "weighted avg       0.12      0.20      0.14       357\n",
      "\n",
      "Prediction Vector: \n",
      " [7 7 1 4 2 6 4 7 4 1 7 1 1 1 1 1 0 4 1 4 7 3 7 7 7 4 4 4 1 4 3 1 0 4 0 4 7\n",
      " 6 0 0 1 4 1 4 7 1 1 4 4 7 7 0 7 7 1 2 2 1 4 0 7 7 7 1 7 7 1 7 4 7 6 4 0 4\n",
      " 4 4 4 4 4 1 1 4 4 0 4 4 7 7 1 7 7 7 7 4 4 1 4 7 6 7 3 7 4 1 7 0 0 4 7 0 1\n",
      " 1 0 7 1 0 4 1 3 7 3 7 7 6 1 1 1 1 2 7 1 1 7 0 3 7 1 4 0 7 7 4 0 7 4 7 4 7\n",
      " 0 4 7 1 4 4 4 7 1 1 0 7 1 7 7 7 4 1 2 7 7 4 1 3 7 4 1 7 4 7 4 7 1 7 4 7 1\n",
      " 4 4 4 1 7 1 7 7 7 4 3 4 0 2 4 1 4 7 7 1 1 4 7 4 1 7 1 4 4 2 0 4 1 4 0 0 4\n",
      " 7 1 4 7 1 7 0 1 7 0 7 4 0 1 4 6 7 4 7 1 4 7 1 0 7 7 4 1 7 2 4 7 4 7 2 0 6\n",
      " 0 0 4 7 4 1 0 1 4 4 2 1 7 1 1 1 1 7 4 1 7 1 0 7 4 4 4 7 2 7 4 7 7 7 7 7 4\n",
      " 1 4 4 0 7 4 7 1 1 4 1 1 7 4 7 1 1 4 7 4 3 2 4 7 1 1 1 4 7 1 7 7 4 1 1 3 1\n",
      " 0 0 2 3 4 4 7 7 4 7 7 2 4 0 4 4 7 1 4 7 7 7 1 4]\n",
      "\n",
      " Accuracy: \n",
      " 19.607843137254903\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 0  2  0  0 35  0  6 10]\n",
      " [ 0 23  0  6  0  0  0 21]\n",
      " [ 4  0  1  0 29  0  1  9]\n",
      " [ 2 26  0  1  0  0  0 13]\n",
      " [ 4  0  9  0 25  0  0  9]\n",
      " [ 0 31  0  0  0  0  0 16]\n",
      " [ 5  0  4  0  9  0  0 10]\n",
      " [21  1  0  4  0  0  0 20]]\n",
      "RM From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        53\n",
      "           1       0.20      0.26      0.22        50\n",
      "           2       0.32      0.27      0.30        44\n",
      "           3       0.28      0.17      0.21        42\n",
      "           4       0.24      0.21      0.23        47\n",
      "           5       0.15      0.06      0.09        47\n",
      "           6       0.26      0.39      0.31        28\n",
      "           7       0.18      0.35      0.24        46\n",
      "\n",
      "    accuracy                           0.20       357\n",
      "   macro avg       0.20      0.21      0.20       357\n",
      "weighted avg       0.20      0.20      0.19       357\n",
      "\n",
      "Prediction Vector: \n",
      " [7 7 1 2 2 6 4 7 6 1 6 1 1 1 1 1 0 0 1 3 7 3 7 7 6 2 6 6 1 6 3 1 0 2 6 7 7\n",
      " 6 6 0 1 6 1 4 7 1 1 4 4 7 7 0 6 7 5 2 2 1 2 0 7 7 7 5 3 7 3 7 6 7 2 4 0 4\n",
      " 2 4 6 2 4 5 5 4 6 0 2 2 7 7 5 7 7 7 3 4 0 1 2 7 6 7 1 7 6 1 7 6 2 4 7 0 1\n",
      " 1 0 7 1 6 4 1 3 7 3 0 7 6 5 3 1 1 2 7 1 1 7 6 3 7 1 0 2 0 7 4 0 3 2 7 4 7\n",
      " 6 4 3 1 6 4 4 7 1 1 0 7 1 7 6 7 6 1 2 5 7 4 5 3 7 2 1 5 2 7 4 7 1 5 0 7 1\n",
      " 2 2 4 1 7 1 7 7 3 2 3 4 0 2 2 1 7 7 7 1 1 4 6 4 1 7 5 6 6 2 0 6 1 6 6 0 6\n",
      " 7 1 4 3 5 7 0 1 7 0 7 4 0 5 2 6 3 2 7 1 4 7 3 0 3 1 4 1 7 2 4 7 6 7 2 0 6\n",
      " 0 0 2 7 4 1 0 5 6 6 2 5 7 1 1 1 5 7 0 1 7 5 0 7 0 4 6 7 4 7 0 5 7 6 7 7 4\n",
      " 1 0 6 0 7 4 7 5 1 4 1 1 7 4 7 1 1 6 7 4 3 2 7 7 1 1 5 4 7 1 7 3 4 1 1 3 1\n",
      " 0 6 2 3 0 6 7 7 2 7 7 2 4 0 4 2 3 1 0 3 7 7 1 4]\n",
      "\n",
      " Accuracy: \n",
      " 20.168067226890756\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 0  0  8  1 19  2 10 13]\n",
      " [ 0 13  0  6  0 14  0 17]\n",
      " [ 3  0 12  0 12  0  8  9]\n",
      " [ 0 26  0  7  0  0  4  5]\n",
      " [ 7  0 13  0 10  0 10  7]\n",
      " [ 0 27  0  5  0  3  0 12]\n",
      " [ 5  0  4  0  0  0 11  8]\n",
      " [23  0  0  6  0  1  0 16]]\n",
      "Xgboost From TSNE\n",
      "[17:46:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.09      0.11        53\n",
      "           1       0.21      0.26      0.23        50\n",
      "           2       0.27      0.16      0.20        44\n",
      "           3       0.27      0.26      0.27        42\n",
      "           4       0.21      0.15      0.17        47\n",
      "           5       0.33      0.06      0.11        47\n",
      "           6       0.18      0.32      0.23        28\n",
      "           7       0.26      0.54      0.35        46\n",
      "\n",
      "    accuracy                           0.22       357\n",
      "   macro avg       0.23      0.23      0.21       357\n",
      "weighted avg       0.23      0.22      0.20       357\n",
      "\n",
      "Prediction Vector: \n",
      " [7 7 1 4 2 6 4 7 6 1 4 1 1 1 1 1 0 0 1 4 7 3 7 7 7 6 6 6 1 6 3 1 0 6 6 7 7\n",
      " 6 6 0 1 6 1 4 7 1 1 6 4 7 7 7 7 7 3 2 2 1 2 0 7 7 7 3 3 7 3 3 6 7 6 4 0 4\n",
      " 2 4 6 2 6 5 3 0 6 0 2 2 7 4 5 7 7 7 3 0 0 3 2 7 6 7 3 7 6 3 7 6 6 4 7 0 1\n",
      " 1 7 7 1 7 0 1 3 7 1 7 7 6 3 3 1 1 2 7 1 1 7 6 3 3 1 0 6 7 7 4 7 3 2 7 4 7\n",
      " 6 0 3 1 6 0 0 4 1 1 0 7 1 7 4 7 6 1 2 5 7 6 3 3 7 2 1 3 2 7 0 7 1 3 0 7 1\n",
      " 6 4 6 1 7 1 7 7 3 2 3 4 0 2 2 1 7 7 7 1 1 0 4 4 1 7 3 6 6 6 0 6 1 6 7 0 6\n",
      " 7 1 4 3 3 7 0 1 4 0 7 4 7 3 6 6 3 2 7 1 4 7 3 0 3 3 4 1 7 2 6 7 6 7 2 0 6\n",
      " 7 7 4 7 6 1 0 3 6 6 2 5 7 1 1 1 5 7 0 3 7 5 0 7 0 4 6 7 0 7 4 5 7 4 7 7 0\n",
      " 1 0 6 7 7 4 7 5 1 0 1 1 7 7 7 1 1 6 7 4 3 2 7 7 1 1 5 0 7 1 7 3 4 1 1 3 1\n",
      " 0 6 2 3 0 6 7 7 2 7 7 2 0 0 4 2 3 1 0 3 7 7 1 4]\n",
      "\n",
      " Accuracy: \n",
      " 22.408963585434176\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 5  0  3  2 17  0 13 13]\n",
      " [ 0 13  0 15  0  6  0 16]\n",
      " [ 4  0  7  0  5  0 18 10]\n",
      " [ 0 22  0 11  0  0  0  9]\n",
      " [13  0 12  0  7  0  9  6]\n",
      " [ 0 27  0  6  0  3  0 11]\n",
      " [ 5  0  4  0  4  0  9  6]\n",
      " [14  0  0  7  0  0  0 25]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        53\n",
      "           1       0.64      0.18      0.28        50\n",
      "           2       0.00      0.00      0.00        44\n",
      "           3       0.09      0.29      0.14        42\n",
      "           4       0.28      0.19      0.23        47\n",
      "           5       0.05      0.02      0.03        47\n",
      "           6       0.07      0.29      0.11        28\n",
      "           7       0.17      0.07      0.09        46\n",
      "\n",
      "    accuracy                           0.12       357\n",
      "   macro avg       0.16      0.13      0.11       357\n",
      "weighted avg       0.17      0.12      0.11       357\n",
      "\n",
      "Prediction Vector: \n",
      " [6 3 6 6 3 4 6 0 4 6 6 0 6 6 6 6 3 3 3 7 6 3 6 3 3 5 3 3 6 6 0 6 3 4 3 3 3\n",
      " 4 3 7 6 4 6 6 3 6 7 4 4 3 3 6 3 3 5 3 3 6 6 3 0 6 3 5 4 3 5 3 3 3 3 3 3 7\n",
      " 4 6 6 7 3 1 1 4 3 3 7 6 3 6 1 3 6 6 3 3 3 3 7 6 2 5 7 3 6 3 6 6 4 6 3 3 6\n",
      " 1 3 3 0 3 4 0 7 3 1 3 6 3 6 6 3 6 3 6 0 6 6 3 1 1 6 4 3 3 3 4 3 6 3 6 4 6\n",
      " 3 3 5 6 6 4 6 6 6 6 3 6 6 6 6 3 7 6 3 3 3 6 1 0 6 6 6 1 4 6 6 3 6 3 6 2 5\n",
      " 5 6 3 6 4 6 6 3 3 4 3 5 6 6 6 6 5 0 6 3 6 6 6 7 6 0 5 3 3 3 3 4 6 3 3 3 3\n",
      " 3 0 3 5 3 6 3 6 3 0 3 7 3 6 7 4 6 4 3 0 4 6 0 3 3 1 3 6 6 3 3 3 0 6 3 3 4\n",
      " 6 3 6 6 3 0 3 5 6 3 3 1 4 6 6 6 3 3 4 5 6 0 3 6 3 6 7 6 3 3 4 1 6 6 1 5 6\n",
      " 3 3 3 0 6 7 3 0 6 7 6 6 3 6 6 3 0 3 6 6 6 3 3 6 5 6 3 4 1 6 0 3 4 6 6 7 6\n",
      " 3 3 3 6 4 3 5 6 6 5 3 3 4 3 3 7 5 6 3 3 5 3 6 4]\n",
      "\n",
      " Accuracy: \n",
      " 11.76470588235294\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 0  0  1 11 14  6 17  4]\n",
      " [ 6  9  0 19  0  4 11  1]\n",
      " [ 0  0  0 20  7  0 17  0]\n",
      " [ 8  2  1 12  1  5 13  0]\n",
      " [ 0  0  0 16  9  0 14  8]\n",
      " [ 3  3  0 12  0  1 27  1]\n",
      " [ 1  0  0 17  0  1  8  1]\n",
      " [ 3  0  0 22  1  3 14  3]]\n",
      "SVM From TSNE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        53\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.13      1.00      0.22        44\n",
      "           3       0.00      0.00      0.00        42\n",
      "           4       0.00      0.00      0.00        47\n",
      "           5       0.00      0.00      0.00        47\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.12       357\n",
      "   macro avg       0.02      0.12      0.03       357\n",
      "weighted avg       0.02      0.12      0.03       357\n",
      "\n",
      "Prediction Vector: \n",
      " [2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 5 2 2 2 2 6 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 3 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      " Accuracy: \n",
      " 12.324929971988796\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 0  0 52  0  0  1  0  0]\n",
      " [ 0  0 50  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0]\n",
      " [ 0  0 42  0  0  0  0  0]\n",
      " [ 0  0 47  0  0  0  0  0]\n",
      " [ 0  1 43  2  1  0  0  0]\n",
      " [ 0  0 28  0  0  0  0  0]\n",
      " [ 1  0 44  0  0  0  1  0]]\n",
      "RM From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.02      0.02        53\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.25      0.23      0.24        44\n",
      "           3       0.07      0.19      0.11        42\n",
      "           4       0.11      0.11      0.11        47\n",
      "           5       0.16      0.15      0.15        47\n",
      "           6       0.14      0.18      0.16        28\n",
      "           7       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.10       357\n",
      "   macro avg       0.09      0.11      0.10       357\n",
      "weighted avg       0.09      0.10      0.09       357\n",
      "\n",
      "Prediction Vector: \n",
      " [6 3 2 2 3 4 2 3 2 0 2 3 0 0 0 0 3 0 3 5 2 3 6 3 5 4 1 3 0 2 3 0 4 4 3 5 3\n",
      " 4 3 3 0 2 2 1 3 0 2 5 4 5 3 6 0 1 0 3 3 0 2 3 4 6 3 0 2 3 0 3 3 3 3 5 3 5\n",
      " 2 1 6 2 3 0 0 4 1 4 5 2 3 2 3 3 6 5 3 3 4 3 4 6 4 5 5 3 2 4 6 4 4 6 5 4 6\n",
      " 0 3 3 3 3 3 0 5 3 3 3 6 4 0 5 3 0 3 2 0 0 6 3 3 5 0 3 1 3 3 3 3 4 3 6 3 6\n",
      " 3 3 5 0 6 3 6 6 0 0 4 2 0 0 2 5 2 0 3 3 3 4 3 3 0 2 0 3 2 5 6 3 0 7 2 4 0\n",
      " 5 2 3 0 3 0 6 3 3 2 3 0 0 0 6 0 5 4 6 3 0 6 6 4 0 0 5 7 3 3 4 2 0 3 3 4 5\n",
      " 3 0 5 5 3 4 4 0 3 4 3 5 3 1 2 4 0 2 3 0 4 0 0 4 5 5 5 0 5 3 3 0 4 2 3 3 4\n",
      " 6 3 2 2 3 0 4 0 6 2 3 3 2 0 4 0 3 0 1 0 5 0 4 6 3 5 2 6 3 5 3 3 6 2 5 5 4\n",
      " 3 3 3 4 6 4 1 3 0 3 6 0 4 5 6 3 0 1 6 2 5 3 7 6 0 0 3 3 3 6 4 3 4 6 0 5 0\n",
      " 3 3 3 5 2 3 5 6 2 5 3 3 3 4 5 5 5 0 4 5 5 1 2 4]\n",
      "\n",
      " Accuracy: \n",
      " 10.084033613445378\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 1  4  9  7 13 13  5  1]\n",
      " [13  0  0 30  2  2  2  1]\n",
      " [ 1  2 10 13  5  7  6  0]\n",
      " [23  0  3  8  3  5  0  0]\n",
      " [ 2  1 11 20  5  2  6  0]\n",
      " [22  1  2  8  3  7  4  0]\n",
      " [ 0  2  5 13  1  1  5  1]\n",
      " [ 5  1  0 11 13  8  8  0]]\n",
      "Xgboost From TSNE\n",
      "[17:46:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.06      0.04        53\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.26      0.25      0.26        44\n",
      "           3       0.02      0.05      0.03        42\n",
      "           4       0.03      0.02      0.02        47\n",
      "           5       0.00      0.00      0.00        47\n",
      "           6       0.13      0.21      0.16        28\n",
      "           7       0.24      0.20      0.21        46\n",
      "\n",
      "    accuracy                           0.09       357\n",
      "   macro avg       0.09      0.10      0.09       357\n",
      "weighted avg       0.08      0.09      0.08       357\n",
      "\n",
      "Prediction Vector: \n",
      " [6 3 2 2 3 4 2 0 2 0 2 0 0 0 0 0 3 0 3 7 2 0 6 0 5 5 3 3 0 2 0 0 4 5 3 1 0\n",
      " 4 3 3 0 2 2 7 3 0 2 5 4 7 3 6 0 1 0 3 3 0 2 3 4 6 3 0 2 0 0 0 3 3 3 7 3 7\n",
      " 2 7 6 2 3 0 0 5 1 4 5 2 3 2 0 3 6 7 3 3 5 0 2 6 4 7 7 3 2 4 6 6 4 6 7 4 6\n",
      " 0 0 3 0 3 3 0 7 3 0 3 6 4 0 7 0 0 3 2 0 0 6 3 0 7 2 3 6 0 3 3 3 4 3 6 3 6\n",
      " 3 6 7 0 6 3 6 6 0 0 4 2 0 0 2 7 2 0 3 0 3 4 0 0 6 2 0 0 2 3 6 3 0 5 2 4 0\n",
      " 7 2 3 0 3 0 6 3 3 2 0 0 0 0 6 0 7 4 6 0 0 6 6 5 0 0 7 6 3 3 4 2 0 3 3 4 7\n",
      " 0 0 7 7 0 4 4 0 3 4 3 5 0 7 2 4 0 2 3 0 5 0 0 4 7 7 1 0 7 3 3 0 4 2 3 3 4\n",
      " 6 0 2 2 3 0 4 0 2 2 3 0 2 0 4 0 3 0 6 0 6 0 4 6 3 6 2 6 3 7 3 0 6 2 7 7 4\n",
      " 3 3 3 4 6 5 3 0 0 3 6 0 4 7 6 3 0 3 6 2 7 3 0 6 0 0 0 3 0 6 4 0 6 6 0 7 0\n",
      " 3 3 3 7 6 3 7 6 2 7 3 3 3 4 6 5 7 0 4 7 7 7 2 4]\n",
      "\n",
      " Accuracy: \n",
      " 8.96358543417367\n",
      "\n",
      " Confusion Matrix: \n",
      " [[ 3  3  9  7  9  5  6 11]\n",
      " [30  0  0 13  2  1  2  2]\n",
      " [ 1  1 11 13  3  2  9  4]\n",
      " [29  0  3  2  3  1  0  4]\n",
      " [ 2  0 11 19  1  4 10  0]\n",
      " [24  0  3  6  3  0  4  7]\n",
      " [ 0  0  5 15  1  0  6  1]\n",
      " [ 9  0  0  6 13  0  9  9]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "def select_features(X_train, X_test,n):\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    tsne = TSNE(n_components = n)\n",
    "    X_train_fs = tsne.fit_transform(X_train)\n",
    "    X_test_fs = tsne.fit_transform(X_test)\n",
    "    return X_train_fs, X_test_fs\n",
    " \n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(1,4):\n",
    "    X_train_fs, X_test_fs  = select_features(X_train, X_test,n)\n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From TSNE\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From TSNE\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From TSNE\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From TSNE\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8af388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
