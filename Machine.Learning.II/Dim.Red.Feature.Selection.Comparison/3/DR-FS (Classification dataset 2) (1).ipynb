{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b127ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b1e169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"D:\\\\Ayesha\\\\IBA Data Science\\\\Semester 3\\\\ML II\\\\default of credit card clients.xls\",header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a1b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('ID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b5f310c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0      20000    2          2         1   24      2      2     -1     -1   \n",
       "1     120000    2          2         2   26     -1      2      0      0   \n",
       "2      90000    2          2         2   34      0      0      0      0   \n",
       "\n",
       "   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0     -2  ...          0          0          0         0       689         0   \n",
       "1      0  ...       3272       3455       3261         0      1000      1000   \n",
       "2      0  ...      14331      14948      15549      1518      1500      1000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0         0         0         0                           1  \n",
       "1      1000         0      2000                           1  \n",
       "2      1000      1000      5000                           0  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f059544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost, RF, SVM and LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7e822b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop('default payment next month',axis=1)\n",
    "Y=data['default payment next month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b06a459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validationmetrics(model, testX, testY, verbose=True):  \n",
    "    global predictions\n",
    "    \n",
    "    predictions = model.predict(testX)\n",
    "    \n",
    "    if model.__class__.__module__.startswith('lightgbm'):\n",
    "        for i in range(0, predictions.shape[0]):\n",
    "            predictions[i]= 1 if predictions[i] >= 0.5 else 0\n",
    "    \n",
    "    #Accuracy\n",
    "    accuracy = accuracy_score(testY, predictions)*100\n",
    "    \n",
    "    result1 = classification_report(testY, predictions)\n",
    "    print(\"Classification Report:\",)\n",
    "    print (result1)\n",
    "    \n",
    "    #Precision\n",
    "    precision = precision_score(testY, predictions, pos_label=1, labels=[0,1])*100\n",
    "    \n",
    "    #Recall\n",
    "    recall = recall_score(testY, predictions,pos_label=1,labels=[0,1])*100\n",
    "    \n",
    "    #get FPR (specificity) and TPR (sensitivity)\n",
    "    fpr , tpr, _ = roc_curve(testY, predictions)\n",
    "    \n",
    "    #AUC\n",
    "    auc_val = auc(fpr, tpr)\n",
    "    \n",
    "    #F-Score\n",
    "    f_score = f1_score(testY, predictions)\n",
    "    \n",
    "\n",
    "    if verbose:\n",
    "        print(\"Prediction Vector: \\n\", predictions)\n",
    "        print(\"\\n Accuracy: \\n\", accuracy)\n",
    "        print(\"\\n Precision of event Happening: \\n\", precision)\n",
    "        print(\"\\n Recall of event Happening: \\n\", recall)\n",
    "        print(\"\\n AUC: \\n\",auc_val)\n",
    "        print(\"\\n F-Score:\\n\", f_score)\n",
    "        #confusion Matrix\n",
    "        print(\"\\n Confusion Matrix: \\n\", confusion_matrix(testY, predictions,labels=[0,1]))\n",
    "    \n",
    "    res_map = {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"auc_val\": auc_val,\n",
    "                \"f_score\": f_score,\n",
    "                \"model_obj\": model\n",
    "              }\n",
    "    \n",
    "    return res_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f38a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogReg(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf  = LogisticRegression()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def SVM(trainX, testX, trainY, testY, svmtype=\"SVC\", verbose=True, clf=None):\n",
    "    # for one vs all\n",
    "    if not clf:\n",
    "        if svmtype == \"Linear\":\n",
    "            clf = svm.LinearSVC()\n",
    "        else:\n",
    "            clf = svm.SVC()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def RandomForest(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf  = RandomForestClassifier()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def XgBoost(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf = XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "    clf.fit(trainX,trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a09fc5",
   "metadata": {},
   "source": [
    "# Random Forest Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f23601a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PAY_0        0.093571\n",
       "AGE          0.066619\n",
       "BILL_AMT1    0.060665\n",
       "LIMIT_BAL    0.058743\n",
       "BILL_AMT2    0.054517\n",
       "BILL_AMT3    0.052130\n",
       "BILL_AMT4    0.050841\n",
       "BILL_AMT6    0.050739\n",
       "BILL_AMT5    0.050346\n",
       "PAY_AMT1     0.050145\n",
       "PAY_2        0.048232\n",
       "PAY_AMT2     0.047292\n",
       "PAY_AMT6     0.046635\n",
       "PAY_AMT3     0.045989\n",
       "PAY_AMT4     0.043852\n",
       "PAY_AMT5     0.043674\n",
       "PAY_3        0.028069\n",
       "PAY_5        0.023493\n",
       "EDUCATION    0.020444\n",
       "PAY_4        0.018949\n",
       "PAY_6        0.018817\n",
       "MARRIAGE     0.014032\n",
       "SEX          0.012207\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "model.fit(X,Y)\n",
    "pd.Series(model.feature_importances_,index=X.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77b873b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LIMIT_BAL', 'AGE', 'PAY_0', 'BILL_AMT1', 'BILL_AMT2'], dtype='object')\n",
      "Logistic Regression From Random Forest Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "SVM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.64646464646464\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.49980494148244475\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7687    3]\n",
      " [2210    0]]\n",
      "RM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.88      7690\n",
      "           1       0.62      0.36      0.45      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.73      0.65      0.67      9900\n",
      "weighted avg       0.79      0.81      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.72727272727272\n",
      "\n",
      " Precision of event Happening: \n",
      " 61.87106918238994\n",
      "\n",
      " Recall of event Happening: \n",
      " 35.61085972850679\n",
      "\n",
      " AUC: \n",
      " 0.6465198383044325\n",
      "\n",
      " F-Score:\n",
      " 0.4520390580126364\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7205  485]\n",
      " [1423  787]]\n",
      "Xgboost From Random Forest Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:08:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      7690\n",
      "           1       0.69      0.33      0.45      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.76      0.64      0.67      9900\n",
      "weighted avg       0.80      0.82      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.75757575757576\n",
      "\n",
      " Precision of event Happening: \n",
      " 69.12878787878788\n",
      "\n",
      " Recall of event Happening: \n",
      " 33.03167420814479\n",
      "\n",
      " AUC: \n",
      " 0.6439620121330517\n",
      "\n",
      " F-Score:\n",
      " 0.44703000612369864\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7364  326]\n",
      " [1480  730]]\n",
      "Index(['LIMIT_BAL', 'AGE', 'PAY_0', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3',\n",
      "       'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1'],\n",
      "      dtype='object')\n",
      "Logistic Regression From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.50      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.64      0.50      0.44      9900\n",
      "weighted avg       0.72      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 50.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.04524886877828054\n",
      "\n",
      " AUC: \n",
      " 0.5001612248380396\n",
      "\n",
      " F-Score:\n",
      " 0.0009041591320072334\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7689    1]\n",
      " [2209    1]]\n",
      "SVM From Random Forest Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "RM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.89      7690\n",
      "           1       0.64      0.35      0.45      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.74      0.64      0.67      9900\n",
      "weighted avg       0.79      0.81      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.98989898989899\n",
      "\n",
      " Precision of event Happening: \n",
      " 63.66666666666667\n",
      "\n",
      " Recall of event Happening: \n",
      " 34.57013574660633\n",
      "\n",
      " AUC: \n",
      " 0.6445021741816663\n",
      "\n",
      " F-Score:\n",
      " 0.44809384164222876\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7254  436]\n",
      " [1446  764]]\n",
      "Xgboost From Random Forest Selection\n",
      "[12:09:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      7690\n",
      "           1       0.70      0.33      0.45      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.77      0.64      0.67      9900\n",
      "weighted avg       0.80      0.82      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.84848484848484\n",
      "\n",
      " Precision of event Happening: \n",
      " 69.76076555023923\n",
      "\n",
      " Recall of event Happening: \n",
      " 32.98642533936651\n",
      "\n",
      " AUC: \n",
      " 0.6443859628476778\n",
      "\n",
      " F-Score:\n",
      " 0.44792626728110596\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7374  316]\n",
      " [1481  729]]\n",
      "Index(['LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_2', 'BILL_AMT1', 'BILL_AMT2',\n",
      "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
      "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT6'],\n",
      "      dtype='object')\n",
      "Logistic Regression From Random Forest Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.50      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.64      0.50      0.44      9900\n",
      "weighted avg       0.72      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 50.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.09049773755656108\n",
      "\n",
      " AUC: \n",
      " 0.5003224496760793\n",
      "\n",
      " F-Score:\n",
      " 0.001806684733514002\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7688    2]\n",
      " [2208    2]]\n",
      "SVM From Random Forest Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "RM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      7690\n",
      "           1       0.65      0.36      0.46      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.74      0.65      0.67      9900\n",
      "weighted avg       0.79      0.81      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.3030303030303\n",
      "\n",
      " Precision of event Happening: \n",
      " 64.79802143446001\n",
      "\n",
      " Recall of event Happening: \n",
      " 35.56561085972851\n",
      "\n",
      " AUC: \n",
      " 0.650064725299943\n",
      "\n",
      " F-Score:\n",
      " 0.4592462751971955\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7263  427]\n",
      " [1424  786]]\n",
      "Xgboost From Random Forest Selection\n",
      "[12:10:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      7690\n",
      "           1       0.69      0.34      0.45      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.76      0.65      0.67      9900\n",
      "weighted avg       0.80      0.82      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.75757575757576\n",
      "\n",
      " Precision of event Happening: \n",
      " 68.73840445269018\n",
      "\n",
      " Recall of event Happening: \n",
      " 33.52941176470588\n",
      "\n",
      " AUC: \n",
      " 0.6457354853514878\n",
      "\n",
      " F-Score:\n",
      " 0.4507299270072993\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7353  337]\n",
      " [1469  741]]\n",
      "Index(['LIMIT_BAL', 'EDUCATION', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4',\n",
      "       'PAY_5', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4',\n",
      "       'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
      "       'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6'],\n",
      "      dtype='object')\n",
      "Logistic Regression From Random Forest Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "SVM From Random Forest Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "RM From Random Forest Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      7690\n",
      "           1       0.64      0.36      0.46      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.74      0.65      0.67      9900\n",
      "weighted avg       0.79      0.81      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.13131313131314\n",
      "\n",
      " Precision of event Happening: \n",
      " 63.812600969305336\n",
      "\n",
      " Recall of event Happening: \n",
      " 35.74660633484163\n",
      "\n",
      " AUC: \n",
      " 0.6496042930526217\n",
      "\n",
      " F-Score:\n",
      " 0.4582366589327147\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7242  448]\n",
      " [1420  790]]\n",
      "Xgboost From Random Forest Selection\n",
      "[12:11:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      7690\n",
      "           1       0.68      0.34      0.46      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.76      0.65      0.67      9900\n",
      "weighted avg       0.80      0.82      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.77777777777779\n",
      "\n",
      " Precision of event Happening: \n",
      " 68.28828828828829\n",
      "\n",
      " Recall of event Happening: \n",
      " 34.29864253393665\n",
      "\n",
      " AUC: \n",
      " 0.6486063466098654\n",
      "\n",
      " F-Score:\n",
      " 0.4566265060240964\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7338  352]\n",
      " [1452  758]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_features(X_train, y_train, X_test,n):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectFromModel(RandomForestClassifier(n_estimators=100),threshold=-np.inf, max_features=n)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    selected_feat= X_train.columns[(fs.get_support())]\n",
    "    print(selected_feat)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    " \n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(5,25,5):\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test,n)\n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From Random Forest Selection\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From Random Forest Selection\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From Random Forest Selection\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From Random Forest Selection\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3696200",
   "metadata": {},
   "source": [
    "Logistic Regression with Random Forest selection performs well on 10 features. the accuracy is 82.8, Precision 87 and recall 91.\n",
    "SVM with with Random Forest selection performs well on 10 features as accuracy is 81, precision is 83, recall is 94.\n",
    "RF with random forest selection performs very well on 15 features as accuracy is 85.2, precision is 90 and recall is 90.9.\n",
    "Xgboost with random forest selection performs well on 10 features as accuracy is 85.2, precision is 88 and recall is 93.\n",
    "We concluded that LR, SVM, Xgboost with 10 features works really better with Random Forest selection as it is useful in minimizing the features. So if we want to select one model from random forest selection we will choose Xgboost (with 10 features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11914295",
   "metadata": {},
   "source": [
    "# XGBOOST SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89ba3205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:11:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PAY_0        0.369486\n",
       "PAY_2        0.133631\n",
       "PAY_3        0.052888\n",
       "PAY_4        0.040230\n",
       "PAY_6        0.037193\n",
       "PAY_5        0.036620\n",
       "PAY_AMT2     0.024072\n",
       "LIMIT_BAL    0.023817\n",
       "BILL_AMT1    0.022776\n",
       "PAY_AMT3     0.022579\n",
       "BILL_AMT2    0.020286\n",
       "PAY_AMT1     0.019711\n",
       "EDUCATION    0.019459\n",
       "PAY_AMT4     0.019295\n",
       "BILL_AMT3    0.018596\n",
       "PAY_AMT6     0.018429\n",
       "BILL_AMT5    0.018013\n",
       "PAY_AMT5     0.017983\n",
       "MARRIAGE     0.017965\n",
       "BILL_AMT6    0.017443\n",
       "BILL_AMT4    0.016913\n",
       "AGE          0.016321\n",
       "SEX          0.016294\n",
       "dtype: float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= XGBClassifier(n_estimators=100,random_state=0)\n",
    "model.fit(X,Y)\n",
    "pd.Series(model.feature_importances_,index=X.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf6934bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:12:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Index(['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5'], dtype='object')\n",
      "Logistic Regression From XGboost Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89      7690\n",
      "           1       0.72      0.22      0.33      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.77      0.60      0.61      9900\n",
      "weighted avg       0.79      0.81      0.76      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.64646464646465\n",
      "\n",
      " Precision of event Happening: \n",
      " 72.07207207207207\n",
      "\n",
      " Recall of event Happening: \n",
      " 21.71945701357466\n",
      "\n",
      " AUC: \n",
      " 0.5965036569794469\n",
      "\n",
      " F-Score:\n",
      " 0.3337969401947149\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7504  186]\n",
      " [1730  480]]\n",
      "SVM From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      7690\n",
      "           1       0.67      0.36      0.47      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.75      0.66      0.68      9900\n",
      "weighted avg       0.80      0.82      0.80      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.72727272727272\n",
      "\n",
      " Precision of event Happening: \n",
      " 66.55656482246077\n",
      "\n",
      " Recall of event Happening: \n",
      " 36.470588235294116\n",
      "\n",
      " AUC: \n",
      " 0.6560200413065096\n",
      "\n",
      " F-Score:\n",
      " 0.4712072493422975\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7285  405]\n",
      " [1404  806]]\n",
      "RM From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      7690\n",
      "           1       0.65      0.36      0.46      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.74      0.65      0.67      9900\n",
      "weighted avg       0.79      0.81      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.3030303030303\n",
      "\n",
      " Precision of event Happening: \n",
      " 64.55798864557988\n",
      "\n",
      " Recall of event Happening: \n",
      " 36.01809954751131\n",
      "\n",
      " AUC: \n",
      " 0.6516769736803395\n",
      "\n",
      " F-Score:\n",
      " 0.46238745280278826\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7253  437]\n",
      " [1414  796]]\n",
      "Xgboost From XGboost Selection\n",
      "[12:12:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      7690\n",
      "           1       0.66      0.37      0.47      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.75      0.66      0.68      9900\n",
      "weighted avg       0.80      0.82      0.80      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.7070707070707\n",
      "\n",
      " Precision of event Happening: \n",
      " 66.28571428571428\n",
      "\n",
      " Recall of event Happening: \n",
      " 36.742081447963805\n",
      "\n",
      " AUC: \n",
      " 0.656857351323044\n",
      "\n",
      " F-Score:\n",
      " 0.4727802037845706\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7277  413]\n",
      " [1398  812]]\n",
      "[12:12:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LIMIT_BAL', 'EDUCATION', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',\n",
      "       'PAY_6', 'BILL_AMT1', 'PAY_AMT3'],\n",
      "      dtype='object')\n",
      "Logistic Regression From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "SVM From XGboost Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "RM From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      7690\n",
      "           1       0.60      0.36      0.45      2210\n",
      "\n",
      "    accuracy                           0.80      9900\n",
      "   macro avg       0.72      0.64      0.66      9900\n",
      "weighted avg       0.78      0.80      0.78      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.34343434343434\n",
      "\n",
      " Precision of event Happening: \n",
      " 60.04566210045662\n",
      "\n",
      " Recall of event Happening: \n",
      " 35.70135746606335\n",
      "\n",
      " AUC: \n",
      " 0.6443715467581451\n",
      "\n",
      " F-Score:\n",
      " 0.44778660612939847\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7165  525]\n",
      " [1421  789]]\n",
      "Xgboost From XGboost Selection\n",
      "[12:13:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      7690\n",
      "           1       0.68      0.35      0.46      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.76      0.65      0.68      9900\n",
      "weighted avg       0.80      0.82      0.80      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.7979797979798\n",
      "\n",
      " Precision of event Happening: \n",
      " 67.64705882352942\n",
      "\n",
      " Recall of event Happening: \n",
      " 35.38461538461539\n",
      "\n",
      " AUC: \n",
      " 0.6526057817345204\n",
      "\n",
      " F-Score:\n",
      " 0.46464646464646464\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7316  374]\n",
      " [1428  782]]\n",
      "[12:13:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LIMIT_BAL', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3',\n",
      "       'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT4',\n",
      "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4'],\n",
      "      dtype='object')\n",
      "Logistic Regression From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.64646464646464\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.49980494148244475\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7687    3]\n",
      " [2210    0]]\n",
      "SVM From XGboost Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "RM From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      7690\n",
      "           1       0.61      0.35      0.44      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.72      0.64      0.66      9900\n",
      "weighted avg       0.78      0.81      0.78      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.56565656565657\n",
      "\n",
      " Precision of event Happening: \n",
      " 61.40350877192983\n",
      "\n",
      " Recall of event Happening: \n",
      " 34.841628959276015\n",
      "\n",
      " AUC: \n",
      " 0.6427387039641304\n",
      "\n",
      " F-Score:\n",
      " 0.44457274826789833\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7206  484]\n",
      " [1440  770]]\n",
      "Xgboost From XGboost Selection\n",
      "[12:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      7690\n",
      "           1       0.68      0.34      0.46      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.76      0.65      0.67      9900\n",
      "weighted avg       0.80      0.82      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.68686868686869\n",
      "\n",
      " Precision of event Happening: \n",
      " 67.64444444444445\n",
      "\n",
      " Recall of event Happening: \n",
      " 34.43438914027149\n",
      "\n",
      " AUC: \n",
      " 0.6485048455713185\n",
      "\n",
      " F-Score:\n",
      " 0.4563718140929534\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7326  364]\n",
      " [1449  761]]\n",
      "[12:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LIMIT_BAL', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3',\n",
      "       'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3',\n",
      "       'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2',\n",
      "       'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT6'],\n",
      "      dtype='object')\n",
      "Logistic Regression From XGboost Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "SVM From XGboost Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "RM From XGboost Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      7690\n",
      "           1       0.64      0.35      0.45      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.74      0.65      0.67      9900\n",
      "weighted avg       0.79      0.81      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.04040404040404\n",
      "\n",
      " Precision of event Happening: \n",
      " 63.56968215158925\n",
      "\n",
      " Recall of event Happening: \n",
      " 35.294117647058826\n",
      "\n",
      " AUC: \n",
      " 0.6474068691195595\n",
      "\n",
      " F-Score:\n",
      " 0.45388420133837654\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7243  447]\n",
      " [1430  780]]\n",
      "Xgboost From XGboost Selection\n",
      "[12:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      7690\n",
      "           1       0.67      0.35      0.46      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.75      0.65      0.67      9900\n",
      "weighted avg       0.80      0.82      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.66666666666667\n",
      "\n",
      " Precision of event Happening: \n",
      " 67.4315975286849\n",
      "\n",
      " Recall of event Happening: \n",
      " 34.57013574660633\n",
      "\n",
      " AUC: \n",
      " 0.648858481073734\n",
      "\n",
      " F-Score:\n",
      " 0.4570744839964104\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7321  369]\n",
      " [1446  764]]\n"
     ]
    }
   ],
   "source": [
    "def select_features(X_train, y_train, X_test,n):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectFromModel(XGBClassifier(n_estimators=100),threshold=-np.inf, max_features=n)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    selected_feat= X_train.columns[(fs.get_support())]\n",
    "    print(selected_feat)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(5,25,5):\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test,n)\n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From XGboost Selection\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From XGboost Selection\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From XGboost Selection\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From XGboost Selection\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dfdda3",
   "metadata": {},
   "source": [
    "Logistic Regression with xgboost feature selection doesnot perform well on the less number of features it perform well on 20 features with the accuracy 89, precision 79 and recall 98.\n",
    "SVM with xgboost feature selection perform almost same with more or less features so its better to select with less features. (accuracy 78.4, precision 79, recall 98.48)\n",
    "RF with xgboost selection performs well on 20 features with accuracy 86.6, precision 90.04 and recall 95.95.\n",
    "Xgboost with xgboost selection performs well on 10 features with accuracy 84.39, precision 89.16, recall 91.41.\n",
    "We concluded that from xgboost selection RF model (with 10 features) performs well from all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8753e0",
   "metadata": {},
   "source": [
    "# RFE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f549c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc6ac828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PAY_0', 'BILL_AMT1', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT6'], dtype='object')\n",
      "Logistic Regression From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.87      7690\n",
      "           1       0.35      0.05      0.08      2210\n",
      "\n",
      "    accuracy                           0.77      9900\n",
      "   macro avg       0.57      0.51      0.48      9900\n",
      "weighted avg       0.68      0.77      0.69      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 76.75757575757575\n",
      "\n",
      " Precision of event Happening: \n",
      " 34.98349834983499\n",
      "\n",
      " Recall of event Happening: \n",
      " 4.796380090497738\n",
      "\n",
      " AUC: \n",
      " 0.5111730577996929\n",
      "\n",
      " F-Score:\n",
      " 0.08436132113012336\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7493  197]\n",
      " [2104  106]]\n",
      "SVM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.66666666666666\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.49993498049414825\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7689    1]\n",
      " [2210    0]]\n",
      "RM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      7690\n",
      "           1       0.62      0.32      0.42      2210\n",
      "\n",
      "    accuracy                           0.80      9900\n",
      "   macro avg       0.72      0.63      0.65      9900\n",
      "weighted avg       0.78      0.80      0.78      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.43434343434343\n",
      "\n",
      " Precision of event Happening: \n",
      " 61.85925282363163\n",
      "\n",
      " Recall of event Happening: \n",
      " 32.217194570135746\n",
      "\n",
      " AUC: \n",
      " 0.632542409781758\n",
      "\n",
      " F-Score:\n",
      " 0.42368342755132404\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7251  439]\n",
      " [1498  712]]\n",
      "Xgboost From RFE Selection\n",
      "[12:16:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      7690\n",
      "           1       0.69      0.32      0.44      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.76      0.64      0.66      9900\n",
      "weighted avg       0.80      0.82      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.61616161616162\n",
      "\n",
      " Precision of event Happening: \n",
      " 69.11764705882352\n",
      "\n",
      " Recall of event Happening: \n",
      " 31.90045248868778\n",
      "\n",
      " AUC: \n",
      " 0.6390211181001358\n",
      "\n",
      " F-Score:\n",
      " 0.43653250773993807\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7375  315]\n",
      " [1505  705]]\n",
      "Index(['LIMIT_BAL', 'AGE', 'PAY_0', 'BILL_AMT1', 'BILL_AMT3', 'BILL_AMT4',\n",
      "       'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT3', 'PAY_AMT5'],\n",
      "      dtype='object')\n",
      "Logistic Regression From RFE Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "SVM From RFE Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "RM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      7690\n",
      "           1       0.64      0.34      0.45      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.74      0.64      0.67      9900\n",
      "weighted avg       0.79      0.81      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.12121212121211\n",
      "\n",
      " Precision of event Happening: \n",
      " 64.48598130841121\n",
      "\n",
      " Recall of event Happening: \n",
      " 34.34389140271493\n",
      "\n",
      " AUC: \n",
      " 0.6445413035675409\n",
      "\n",
      " F-Score:\n",
      " 0.4481842338352524\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7272  418]\n",
      " [1451  759]]\n",
      "Xgboost From RFE Selection\n",
      "[12:18:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      7690\n",
      "           1       0.70      0.33      0.45      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.76      0.64      0.67      9900\n",
      "weighted avg       0.80      0.82      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.81818181818183\n",
      "\n",
      " Precision of event Happening: \n",
      " 69.7495183044316\n",
      "\n",
      " Recall of event Happening: \n",
      " 32.76018099547511\n",
      "\n",
      " AUC: \n",
      " 0.6433847801399243\n",
      "\n",
      " F-Score:\n",
      " 0.4458128078817734\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7376  314]\n",
      " [1486  724]]\n",
      "Index(['LIMIT_BAL', 'AGE', 'PAY_0', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3',\n",
      "       'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2',\n",
      "       'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6'],\n",
      "      dtype='object')\n",
      "Logistic Regression From RFE Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "SVM From RFE Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "RM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      7690\n",
      "           1       0.65      0.35      0.46      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.74      0.65      0.67      9900\n",
      "weighted avg       0.79      0.81      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.31313131313132\n",
      "\n",
      " Precision of event Happening: \n",
      " 65.1006711409396\n",
      "\n",
      " Recall of event Happening: \n",
      " 35.1131221719457\n",
      "\n",
      " AUC: \n",
      " 0.6485174964253982\n",
      "\n",
      " F-Score:\n",
      " 0.45620223398001175\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7274  416]\n",
      " [1434  776]]\n",
      "Xgboost From RFE Selection\n",
      "[12:19:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      7690\n",
      "           1       0.70      0.33      0.45      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.77      0.65      0.67      9900\n",
      "weighted avg       0.80      0.82      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.87878787878789\n",
      "\n",
      " Precision of event Happening: \n",
      " 69.77186311787072\n",
      "\n",
      " Recall of event Happening: \n",
      " 33.212669683257914\n",
      "\n",
      " AUC: \n",
      " 0.6453871455554313\n",
      "\n",
      " F-Score:\n",
      " 0.4500306560392397\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7372  318]\n",
      " [1476  734]]\n",
      "Index(['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2',\n",
      "       'PAY_4', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4',\n",
      "       'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
      "       'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6'],\n",
      "      dtype='object')\n",
      "Logistic Regression From RFE Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.33      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.56      0.50      0.44      9900\n",
      "weighted avg       0.68      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.66666666666666\n",
      "\n",
      " Precision of event Happening: \n",
      " 33.33333333333333\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.04524886877828054\n",
      "\n",
      " AUC: \n",
      " 0.5000962053321879\n",
      "\n",
      " F-Score:\n",
      " 0.0009037505648441032\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7688    2]\n",
      " [2209    1]]\n",
      "SVM From RFE Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "RM From RFE Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.89      7690\n",
      "           1       0.64      0.35      0.45      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.74      0.65      0.67      9900\n",
      "weighted avg       0.79      0.81      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.10101010101009\n",
      "\n",
      " Precision of event Happening: \n",
      " 64.11323896752707\n",
      "\n",
      " Recall of event Happening: \n",
      " 34.841628959276015\n",
      "\n",
      " AUC: \n",
      " 0.6461847377742734\n",
      "\n",
      " F-Score:\n",
      " 0.4514805042509528\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7259  431]\n",
      " [1440  770]]\n",
      "Xgboost From RFE Selection\n",
      "[12:20:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      7690\n",
      "           1       0.68      0.34      0.45      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.76      0.65      0.67      9900\n",
      "weighted avg       0.80      0.82      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.73737373737374\n",
      "\n",
      " Precision of event Happening: \n",
      " 68.33941605839416\n",
      "\n",
      " Recall of event Happening: \n",
      " 33.89140271493213\n",
      "\n",
      " AUC: \n",
      " 0.6468952450441015\n",
      "\n",
      " F-Score:\n",
      " 0.45311554748941324\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7343  347]\n",
      " [1461  749]]\n"
     ]
    }
   ],
   "source": [
    "def select_features(X_train, y_train, X_test,n):\n",
    "    # configure to select a subset of features\n",
    "    fs = RFE(estimator = DecisionTreeClassifier(), n_features_to_select = n)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    selected_feat= X_train.columns[(fs.get_support())]\n",
    "    print(selected_feat)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(5,25,5):\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test,n)\n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From RFE Selection\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From RFE Selection\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From RFE Selection\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From RFE Selection\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7b608e",
   "metadata": {},
   "source": [
    "Logistic Regression with RFE selection perform well with 10 features with an accuracy of 79, precision 79.67, recall 98.9.\n",
    "SVM with RFE selection perform well with 5 features with an accuracy 78, precision 79, recall 98.\n",
    "RF with RFE selection perform well with 10 features with an accuracy of 86.6, precision 91.45, recall 91.9.\n",
    "Xgboost with RFE selection performs well with 20 features with an accuracy of 82.39, precision 88.5, recall 89.39\n",
    "We concluded that from RFE selection RF performs (with 10 features) model performs well from all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f406d32",
   "metadata": {},
   "source": [
    "# LASSO SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "323bc3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0798e781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2'], dtype='object')\n",
      "Logistic Regression From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.89      7690\n",
      "           1       0.72      0.23      0.35      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.77      0.60      0.62      9900\n",
      "weighted avg       0.79      0.81      0.77      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.83838383838385\n",
      "\n",
      " Precision of event Happening: \n",
      " 72.32524964336662\n",
      "\n",
      " Recall of event Happening: \n",
      " 22.941176470588236\n",
      "\n",
      " AUC: \n",
      " 0.6020920982177007\n",
      "\n",
      " F-Score:\n",
      " 0.34833390587427\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7496  194]\n",
      " [1703  507]]\n",
      "SVM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      7690\n",
      "           1       0.70      0.31      0.43      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.77      0.64      0.66      9900\n",
      "weighted avg       0.80      0.82      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 70.32854209445586\n",
      "\n",
      " Recall of event Happening: \n",
      " 30.995475113122172\n",
      "\n",
      " AUC: \n",
      " 0.6361867383744535\n",
      "\n",
      " F-Score:\n",
      " 0.43027638190954776\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7401  289]\n",
      " [1525  685]]\n",
      "RM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      7690\n",
      "           1       0.68      0.32      0.43      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.76      0.64      0.66      9900\n",
      "weighted avg       0.80      0.82      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.5050505050505\n",
      "\n",
      " Precision of event Happening: \n",
      " 68.45180136319377\n",
      "\n",
      " Recall of event Happening: \n",
      " 31.80995475113122\n",
      "\n",
      " AUC: \n",
      " 0.6379834538596874\n",
      "\n",
      " F-Score:\n",
      " 0.43435279579857883\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7366  324]\n",
      " [1507  703]]\n",
      "Xgboost From L1 Based Feature Selection\n",
      "[12:21:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      7690\n",
      "           1       0.69      0.32      0.44      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.76      0.64      0.67      9900\n",
      "weighted avg       0.80      0.82      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.71717171717172\n",
      "\n",
      " Precision of event Happening: \n",
      " 69.34235976789168\n",
      "\n",
      " Recall of event Happening: \n",
      " 32.44343891402715\n",
      "\n",
      " AUC: \n",
      " 0.6416060112151292\n",
      "\n",
      " F-Score:\n",
      " 0.4420468557336621\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7373  317]\n",
      " [1493  717]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3',\n",
      "       'PAY_4', 'PAY_5', 'PAY_AMT1'],\n",
      "      dtype='object')\n",
      "Logistic Regression From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.89      7690\n",
      "           1       0.71      0.21      0.33      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.76      0.59      0.61      9900\n",
      "weighted avg       0.79      0.81      0.76      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.51515151515152\n",
      "\n",
      " Precision of event Happening: \n",
      " 71.06446776611695\n",
      "\n",
      " Recall of event Happening: \n",
      " 21.447963800904976\n",
      "\n",
      " AUC: \n",
      " 0.594691054375136\n",
      "\n",
      " F-Score:\n",
      " 0.3295099061522419\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7497  193]\n",
      " [1736  474]]\n",
      "SVM From L1 Based Feature Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "RM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      7690\n",
      "           1       0.55      0.37      0.44      2210\n",
      "\n",
      "    accuracy                           0.79      9900\n",
      "   macro avg       0.69      0.64      0.66      9900\n",
      "weighted avg       0.77      0.79      0.78      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.29292929292929\n",
      "\n",
      " Precision of event Happening: \n",
      " 55.44217687074829\n",
      "\n",
      " Recall of event Happening: \n",
      " 36.87782805429865\n",
      "\n",
      " AUC: \n",
      " 0.6418013639385933\n",
      "\n",
      " F-Score:\n",
      " 0.4429347826086957\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7035  655]\n",
      " [1395  815]]\n",
      "Xgboost From L1 Based Feature Selection\n",
      "[12:22:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      7690\n",
      "           1       0.68      0.35      0.46      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.76      0.65      0.68      9900\n",
      "weighted avg       0.80      0.82      0.80      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.82828282828282\n",
      "\n",
      " Precision of event Happening: \n",
      " 68.10572687224669\n",
      "\n",
      " Recall of event Happening: \n",
      " 34.977375565610856\n",
      "\n",
      " AUC: \n",
      " 0.6513498167097189\n",
      "\n",
      " F-Score:\n",
      " 0.4621823617339312\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7328  362]\n",
      " [1437  773]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3',\n",
      "       'PAY_4', 'PAY_5', 'BILL_AMT1', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
      "       'PAY_AMT4', 'PAY_AMT5'],\n",
      "      dtype='object')\n",
      "Logistic Regression From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88      7690\n",
      "           1       0.67      0.20      0.31      2210\n",
      "\n",
      "    accuracy                           0.80      9900\n",
      "   macro avg       0.74      0.59      0.60      9900\n",
      "weighted avg       0.78      0.80      0.76      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.02020202020202\n",
      "\n",
      " Precision of event Happening: \n",
      " 67.26190476190477\n",
      "\n",
      " Recall of event Happening: \n",
      " 20.452488687782804\n",
      "\n",
      " AUC: \n",
      " 0.5879581521515278\n",
      "\n",
      " F-Score:\n",
      " 0.31367106176266485\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7470  220]\n",
      " [1758  452]]\n",
      "SVM From L1 Based Feature Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "RM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      7690\n",
      "           1       0.65      0.37      0.47      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.74      0.66      0.68      9900\n",
      "weighted avg       0.80      0.81      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.47474747474747\n",
      "\n",
      " Precision of event Happening: \n",
      " 65.01597444089457\n",
      "\n",
      " Recall of event Happening: \n",
      " 36.832579185520366\n",
      "\n",
      " AUC: \n",
      " 0.6556843523645329\n",
      "\n",
      " F-Score:\n",
      " 0.47024841132293477\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7252  438]\n",
      " [1396  814]]\n",
      "Xgboost From L1 Based Feature Selection\n",
      "[12:23:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      7690\n",
      "           1       0.68      0.35      0.46      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.76      0.65      0.68      9900\n",
      "weighted avg       0.80      0.82      0.80      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.8080808080808\n",
      "\n",
      " Precision of event Happening: \n",
      " 67.8915135608049\n",
      "\n",
      " Recall of event Happening: \n",
      " 35.1131221719457\n",
      "\n",
      " AUC: \n",
      " 0.6517034522121343\n",
      "\n",
      " F-Score:\n",
      " 0.46286907247241277\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7323  367]\n",
      " [1434  776]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2',\n",
      "       'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
      "       'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5',\n",
      "       'PAY_AMT6'],\n",
      "      dtype='object')\n",
      "Logistic Regression From L1 Based Feature Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "SVM From L1 Based Feature Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "RM From L1 Based Feature Selection\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      7690\n",
      "           1       0.64      0.36      0.46      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.74      0.65      0.67      9900\n",
      "weighted avg       0.79      0.81      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.27272727272728\n",
      "\n",
      " Precision of event Happening: \n",
      " 64.3317230273752\n",
      "\n",
      " Recall of event Happening: \n",
      " 36.15384615384615\n",
      "\n",
      " AUC: \n",
      " 0.6519655896769031\n",
      "\n",
      " F-Score:\n",
      " 0.46292004634994205\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7247  443]\n",
      " [1411  799]]\n",
      "Xgboost From L1 Based Feature Selection\n",
      "[12:24:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      7690\n",
      "           1       0.68      0.35      0.46      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.76      0.65      0.68      9900\n",
      "weighted avg       0.80      0.82      0.80      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.87878787878789\n",
      "\n",
      " Precision of event Happening: \n",
      " 68.40707964601769\n",
      "\n",
      " Recall of event Happening: \n",
      " 34.977375565610856\n",
      "\n",
      " AUC: \n",
      " 0.6516749142389776\n",
      "\n",
      " F-Score:\n",
      " 0.46287425149700595\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7333  357]\n",
      " [1437  773]]\n"
     ]
    }
   ],
   "source": [
    "def select_features(X_train, y_train, X_test,n):\n",
    "    # configure to select a subset of features\n",
    "    # Use L1 penalty\n",
    "    estimator = LassoCV(cv=5, normalize = True)\n",
    "    fs = SelectFromModel(estimator,threshold=-np.inf, max_features=n)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    selected_feat= X_train.columns[(fs.get_support())]\n",
    "    print(selected_feat)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(5,25,5):\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test,n)\n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From L1 Based Feature Selection\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From L1 Based Feature Selection\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From L1 Based Feature Selection\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From L1 Based Feature Selection\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba2bbf",
   "metadata": {},
   "source": [
    "Logistic Regression with lasso selection performs well with 5 features with an accuracy of 79, precision 79, recall 100.\n",
    "SVM with lasso selection performs well with 20 features with an accuracy of 80, precision 85, recall 90.\n",
    "RF with lasso selection performs well with 20 features with an accuracy of 84, precision 89, recall 90.\n",
    "Xgboost with lasso selection performs well with 20 features with an accuracy of 80, precision 85, recall 90.\n",
    "We concluded that lasso selection of less features doesnot perform with classifiers. RF from lasso selection (20 features) performs well from all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1f4c1",
   "metadata": {},
   "source": [
    "# PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab211142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28498137 0.17725127 0.0663793  0.05874819 0.04443755 0.04287519\n",
      " 0.04042738 0.0396448  0.03819943 0.03683116 0.03326009 0.02919461\n",
      " 0.02486697 0.02271439 0.01759449 0.01140019 0.01062747 0.0081627\n",
      " 0.00578254 0.00296442 0.0016675  0.00105798 0.00093101]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAApGElEQVR4nO3dfVRU5d4+8GsGLDBEBVRsIEaNZWFJypuGRVqK2DLq6FHUlNSH0CMaJ3Wxek6+dTzPyepU5iFAVMrKMBWOg4qgyZNvKTM4DBCgcBrUUVR8AfGNB4b9+4OfcyIY9qAObJnrs9asxey575vvbGmu7r333FsGQAAREZHEyDu7ACIiotYwoIiISJIYUEREJEkMKCIikiQGFBERSZJ9ZxfwIF26dAmnT5/u7DKIiKgdvLy80Ldv3xbbu1RAnT59GgEBAZ1dBhERtYNarW51Ow/xERGRJDGgiIhIkhhQREQkSV3qHBRRV9C7d2/ExsZCqVRCJpN1djlED4QgCKioqMDnn3+Oa9euWdSHAUUkMbGxsdBoNPjggw9gNBo7uxyiB8LOzg6vvvoqYmNjsWLFCov68BAfkcQolUrs2bOH4URditFoxO7du6FUKi3uw4AikhiZTMZwoi7JaDS267A1A4qIiCSJ56CIJG7c/LkPdLzshI2ibY4cOYLg4GCLxwwJCcGSJUswceJETJw4ET4+PlizZo3Z9qtWrcLBgwfx448/mh3nXuj1evj7++PKlSv31F9MTk4OlixZgry8PLNtkpOT8emnn6KkpOS+f5+13s+DrNGaGFBE1EJ7wun3MjIykJGR0WYbS0+SP4yioqI6u4Q2yeVyydd4Fw/x/ca4+XPb9SDqqmprawE0zWhycnKwbds2lJSU4NtvvzW1CQ0NRUlJCQ4dOoQ//OEPpu2RkZFYt24dnJ2dodfrTeccHB0dcebMGdjb2yMlJQWTJk1qc5wVK1Zg8eLFpueFhYXw8vICAKSnp0Oj0aCoqMiiD9uxY8fi6NGjyMvLww8//IDHHnsMTzzxBE6dOgVXV1fIZDIcPHgQY8eOhZeXF0pKSvDVV19Bp9Nh27ZtcHR0bDHml19+CbVajaKiIqxcudK0PScnB35+fqb9uHr1auTn5+Pnn382rTfn5uaG7du3Izc3F7m5uXj++ecBAC4uLsjKysKJEyeQmJjY6vmaefPmNZudRkZG4osvvmhzv9TW1mLVqlU4duwYRo4c2axGc+9Dr9dj5cqVyMvLQ0FBAQYPHgwAeOyxx7Bp0yYUFBRAp9OZ/s1a28f3iwFFRG0aNmwYYmNj4ePjg4EDByI4OBiPPvookpOTMXHiRLzwwgtwd3dv0e/69evQ6XQICQkBAEycOBFZWVloaGgwtbFknNbMmTMH/v7+8Pf3x6JFi+Di4mK2raurK95//3288sor8PPzg0ajwbvvvoszZ85gzZo1SExMxOLFi1FcXIx9+/YBAJ566imsX78evr6+uH79Ov70pz+1GPcvf/kLAgICMHToUISEhODZZ59t0cbJyQnHjh3Dc889h4MHD5pCY+3atfjss88QGBiISZMmYcOGDQCaQvnw4cMYPnw4VCqVKZB/a/v27c2CfOrUqdi6dWub+8XJyQlFRUUYMWIEjhw5YvH7uHz5Mvz8/JCQkIAlS5YAAJYtW4aamhoMHToUvr6+OHDggNl9fL8YUETUptzcXJw7dw6CICA/Px9KpRJPPfUU9Ho9ysvLAaDZzOq3tm7diqlTpwIAIiIiTB+kd1k6zu8tWrQI+fn5OHbsGDw9PeHt7W227YgRI+Dj44MjR45Aq9UiMjLS9MG/ceNG9OjRA/PmzTN9AAPAmTNncPToUVNNo0aNajHulClTkJeXB61WiyFDhsDHx6dFm7q6OuzatQsAkJeXZ7rE+pVXXsE///lPaLVaqFQqODs7w8nJCS+++KJpH+zZswdXr15tMebly5fx66+/IigoCC4uLhg8eLApdMztl4aGBuzYsaPV/dPW+0hLS2u19vj4eFOb6urqNvfx/eA5KCJqU11dnelno9EIe/umjw1BEET7qlQq/P3vf0fv3r3h5+eHAwcOtGhjbpyGhgbI5f/5f2gHBwcATYcdX3nlFYwcORK3b99GTk6O6bXWyGQy7Nu3D9OnT2/xmqOjIzw8PAA0zTJu3LjRak2/f65UKrFkyRIEBASguroaKSkprdZQX19v+vm3+04ul2PkyJG4c+dOiz6W7NetW7diypQpKC0tRXp6OoC298udO3fQ2NjYYhyx93H33/63tctkshY1trWP7wdnUETUbqWlpRgwYAAGDhwIAJg2bVqr7W7evInc3FysXbsWu3btavEh2dY4FRUVGD58OICmw4wDBgwAAPTs2RPXrl3D7du3MXjwYIwYMaLNWo8dO4bg4GAMGjQIQFMo3Z1ZrFmzBt999x2WL1+O5ORkUx8vLy/TuNOmTcPhw4ebjens7IybN2+ipqYGffv2RVhYWJs1/F52djZiYmJMz319fQEABw8exIwZMwAA48ePN3voMi0tDa+//jqmTZtmmpW2d7/c6/v4fe29evVqcx/fD86giCTOksvCO1pdXR3efvtt7N69G5cvX8bhw4fxzDPPtNp269at2L59u+lclKXj7NixA7NmzYJWq4VarcapU6cAAHv37sW8efOg0+lw8uRJHDt2rM1aL1++jLfeegvff/89Hn30UQDA+++/j/79+yMgIADBwcFobGzEpEmT8NZbbyEnJwfFxcWIjIxEUlISysrKkJCQ0GzMgoICaLVa/PLLL/j1119bnNcRs2jRIsTHx0On08He3h4HDx7E/PnzsWrVKnz//ff4wx/+gJ9++snsDVirq6tRXFwMHx8f072U2rtf7vV9rF69GvHx8SgsLITRaMSqVauQnp7e6j4uKytrx15pSQZAfD75kFCr1fd1w8L2XpknxQ8Oevht3rwZs2bN6uwybJaXlxd27drV6kUPdP9a+/s299nNQ3xERCRJDCgiot84ffo0Z08SwYAikhhBEGBnZ9fZZRA9cHZ2dhZdpXgXA4pIYioqKvDqq68ypKhLuXs/qIqKCov78Co+Ion5/PPPERsbi0mTJvGOutRl/PaOupZiQBFJzLVr17r0YqpEluIhPiIikiQGFBERSRIDioiIJIkBRUREksSAIiIiSWJAERGRJDGgiIhIkhhQREQkSQwoIiKSJAYUERFJEgOKiIgkyaoBFRoaitLSUpSVlSEuLq7F69OnT4dOp4NOp8ORI0cwdOhQ02t6vd50O+K7tzQmIiLbYbXFYuVyOeLj4zF27FgYDAao1WqoVCqUlJSY2uj1eoSEhKC6uhrjx4/H+vXrMWLECNPro0ePxpUrV6xVIhERSZjVZlCBgYEoLy+HXq9HfX09UlNTER4e3qzNzz//jOrqagDAsWPH4OHhYa1yiIjoIWO1gFIoFDh79qzpucFggEKhMNt+7ty5yMzMND0XBAHZ2dnQaDSIiooy2y8qKgpqtRpqtRpubm4PpngiIup0VjvE19qN1szd6vell17C3LlzMWrUKNO24OBgVFZWok+fPti3bx9KS0tx6NChFn2Tk5ORnJwMADxXRUTUhVhtBmUwGODp6Wl67uHhgfPnz7do9+yzz2LDhg0IDw/H1atXTdsrKysBAFVVVUhPT0dgYKC1SiUiIgmyWkCp1Wp4e3tDqVSiW7duiIiIgEqlatbG09MTaWlpmDlzJsrKykzbu3fvDicnJ9PP48aNQ1FRkbVKJSIiCbLaIT6j0YiYmBhkZWXBzs4OmzZtQnFxMaKjowEASUlJWL58OVxdXfHll18CABoaGhAQEIB+/fohPT29qUB7e2zZsgVZWVnWKpWIiCRIBqD1E0MPIbVajYCAgHvuP27+3Ha1z07YeM+/i4iImpj77OZKEkREJEkMKCIikiQGFBERSRIDioiIJIkBRUREksSAIiIiSWJAERGRJDGgiIhIkhhQREQkSQwoIiKSJAYUERFJEgOKiIgkiQFFRESSxIAiIiJJYkAREZEkiQaUQqFAWloaLl26hAsXLmD79u1QKBQdURsREdkw0YBKSUmBSqVC//79oVAokJGRgZSUlI6ojYiIbJhoQPXp0wdfffUVjEYjjEYjvv76a/Tp06cjaiMiIhsmGlCXL1/GjBkzIJfLIZfLMWPGDFy5cqUjaiMiIhsmGlBz5szBlClTcOHCBVRWVmLy5MmYM2dOR9RGREQ2zF6swdmzZxEeHt4RtRAREZmYDailS5fi448/xhdffAFBEFq8/s4771i1MCIism1mA6qkpAQAoNFoOqwYIiKiu8wG1K5duwAAt27dwvbt25u9NnnyZOtWRURENk/0Ion33nvPom1EREQPktkZ1Pjx4zFhwgQoFAqsXbvWtN3Z2RkNDQ0dUhwREdkuswF1/vx5aDQavPbaa8jLyzNtr62txZ///OcOKY6IiGyX2YAqKChAQUEBtmzZwhkTERF1ONHvQSmVSvz973+Hj48PHBwcTNsHDRpk1cKIiMi2WbRYbEJCAhoaGjB69Ghs3rwZ33zzTUfURkRENkw0oBwdHXHgwAHIZDKcOXMGq1atwpgxYywaPDQ0FKWlpSgrK0NcXFyL16dPnw6dTgedTocjR45g6NChFvclIqKuTfQQ3507dyCTyVBWVoYFCxbg3Llz6Nu3r+jAcrkc8fHxGDt2LAwGA9RqNVQqlekLwACg1+sREhKC6upqjB8/HuvXr8eIESMs6ktERF2b6AwqNjYW3bt3x6JFi+Dn54c333wTkZGRogMHBgaivLwcer0e9fX1SE1NbbGm388//4zq6moAwLFjx+Dh4WFxXyIi6traDCi5XI4pU6bg5s2bOHfuHObMmYPJkyfj+PHjogMrFAqcPXvW9NxgMLR5J965c+ciMzOz3X2joqKgVquhVqvh5uYmWhcRET0c2jzE19jYCD8/v3saWCaTtdjW2qKzAPDSSy9h7ty5GDVqVLv7JicnIzk5GQCgVqvvqVYiIpIe0XNQWq0WO3fuxLZt23Dz5k3T9vT09Db7GQwGeHp6mp57eHjg/PnzLdo9++yz2LBhA8LCwnD16tV29SUioq5LNKBcXFxw5cqVZlfuCYIgGlBqtRre3t5QKpU4d+4cIiIiMH369GZtPD09kZaWhpkzZ6KsrKxdfYmIqGsTDah7vXuu0WhETEwMsrKyYGdnh02bNqG4uBjR0dEAgKSkJCxfvhyurq748ssvAQANDQ0ICAgw25eIiGyHDEDrJ3ceQmq1GgEBAffcf9z8ue1qn52w8Z5/FxERNTH32S16mTkREVFnYEAREZEkiQZU3759sWHDBuzZswcA8PTTT9/zeSkiIiJLiQbUV199haysLDz++OMAgFOnTiE2NtbadRERkY0TDSg3Nzds27YNjY2NAJquzjMajVYvjIiIbJtoQN28eRMuLi6mlRyCgoJQU1Nj9cKIiMi2iX4P6t1334VKpcKgQYNw+PBh9OnTB5MnT+6I2oiIyIZZtNRRSEgIBg8eDJlMhpMnT/IW8EREZHWih/j+9Kc/wcnJCcXFxfjll1/g5OSE+fPnd0RtRERkw0QDKioqqtk5p+rqakRFRVm1KCIiItGAksvlLZ4/8sgjViuIiIgIsOAcVFZWFn744QckJiZCEATMmzcPe/fu7YjaiIjIhokGVFxcHKKjozF//nzIZDJkZ2djw4YNHVHbQ4ULzRIRPViiASUIAhITE5GYmNgR9RAREQGwIKCef/55rFy5El5eXrC3t4dMJoMgCBg0aFBH1EdERDZKNKA2btyIP//5z8jLy+MSR0RE1GFEA6qmpoYXRRARUYcTDaicnBx89NFHSEtLQ11dnWm7Vqu1amFERGTbRAMqKCgIAODv72/aJggCXn75ZetVRURENk80oMaMGdMRdRARETUjGlAAMGHCBAwZMgQODg6mbX/961+tVhQREZHoUkcJCQmYOnUqFi5cCJlMhj/+8Y/w8vLqiNqIiMiGiQbU888/j8jISFy7dg0ffPABRo4cCU9Pz46ojYiIbJhoQN2+fRsAcOvWLfTv3x/19fUYMGCA1QsjIiLbJnoOateuXejZsyc+/vhjnDhxAoIgcC0+IiKyOtGAWr16NQAgLS0Nu3btgoODA65fv271woiIyLaZDajRo0cjJycHb7zxRquvp6enW60oIiIiswEVEhKCnJwcTJw4scVrgiAwoIiIyKrMBtTKlSshk8mQmZmJbdu2dWRNREREbV/FJwgCYmJiOqoWIiIiE9HLzPft24fFixfDw8MDvXv3Nj2IiIisSTSg5syZgwULFuDgwYPIy8tDXl4eNBqNRYOHhoaitLQUZWVliIuLa/H64MGDcfToUdy5cweLFy9u9pper0dBQQG0Wi3UarWFb4eIiLoK0cvMBw4ceE8Dy+VyxMfHY+zYsTAYDFCr1VCpVCgpKTG1uXr1KhYtWoTXX3+91TFGjx6NK1eu3NPvJyKih5tFi8UOGTIEPj4+zRaL/eabb9rsExgYiPLycuj1egBAamoqwsPDmwVUVVUVqqqq8Oqrr95L7URE1IWJHuJbvnw51q1bh3Xr1mH06NH46KOP8Nprr4kOrFAocPbsWdNzg8EAhUJhcWGCICA7OxsajQZRUVFm20VFRUGtVkOtVsPNzc3i8YmISNpEA2ry5Ml4+eWXceHCBcyZMwe+vr549NFHRQeWyWQttgmCYHFhwcHB8PPzQ1hYGBYsWIAXXnih1XbJyckICAhAQEAALl++bPH4REQkbRYtFisIAhoaGtCjRw9cunTJovNSBoOh2arnHh4eOH/+vMWFVVZWAmg6DJieno7AwECL+xIR0cNPNKA0Gg169uyJ5ORk5OXl4cSJE8jNzRUdWK1Ww9vbG0qlEt26dUNERARUKpVFRXXv3h1OTk6mn8eNG4eioiKL+hIRUdcgepHEggULAABJSUnYu3cvnJ2dUVhYKDqw0WhETEwMsrKyYGdnh02bNqG4uBjR0dGm8fr16weNRgNnZ2c0NjYiNjYWPj4+cHNzMy2lZG9vjy1btiArK+t+3icRET1kRAPqX//6F7Zu3YqdO3fi9OnT7Ro8MzMTmZmZzbYlJSWZfr548WKrNz+sra3Fc889167fRUREXYvoIb5PP/0Uo0aNQnFxMX744QdMmjTJooskiIiI7odoQB08eBALFizAwIEDsX79ekyZMgWXLl3qiNqIiMiGWfRFXQcHB0ycOBFTp07F8OHD8fXXX1u7LiIisnGiAZWamoqgoCDs3bsX8fHx+N///d92fZ+JiIjoXogGVEpKCqZPn47GxsaOqIeIiAiABQHFy7uJiKgziF4kQURE1BkYUEREJElmD/ENGzaszY5arfaBF0NERHSX2YD6xz/+AaDpEnN/f3/odDrIZDIMHToUx48fN7u6OBER0YNg9hDfmDFjMGbMGJw+fRrDhw9HQEAA/P39MWzYMJSXl3dkjUREZINEz0E99dRTzVYS/+WXX7hOHhERWZ3oZeYlJSVITk7Gt99+C0EQ8Oabbza7bTsREZE1iAbU7NmzMX/+fLzzzjsAmtbmS0hIsHphRERk20QDqq6uDomJidizZw9OnTrVETURERGJn4OaOHEi8vPzsXfvXgCAr68vdu7cafXCiIjItokG1IoVKxAYGIjq6moAgE6ng1KptHJZRERk60QDqqGhAdevX++IWoiIiExEA6qoqAjTpk2DnZ0dnnzySXzxxRc4evRoR9RGREQ2TDSgFi5ciCFDhqCurg7ff/89rl+/jtjY2A4ojYiIbJnoVXy3b9/G+++/j/fff78j6iEiIgJgQUB5e3tjyZIlUCqVsLf/T/OXX37ZqoUREZFtEw2obdu2ITExERs2bIDRaOyImoiIiMQDqqGhAYmJiR1RCxERkYnoRRIZGRmYP38+3N3d0bt3b9ODiIjImkRnUJGRkQCApUuXmrYJgoBBgwZZryoiIrJ5ogE1cODAjqiDiIioGbMBNXr0aOTk5OCNN95o9fX09HSrFUVERGQ2oEJCQpCTk4OJEye2eE0QBAYUERFZldmAWrlyJQBgzpw5HVULERGRiehVfAAwYcIELF26FMuWLTM9LBEaGorS0lKUlZUhLi6uxeuDBw/G0aNHcefOHSxevLhdfYmIqGsTDaiEhARMnToVCxcuhEwmwx//+Ed4eXmJDyyXIz4+HmFhYfDx8cG0adPw9NNPN2tz9epVLFq0CJ988km7+xIRUdcmGlDPP/88IiMjce3aNXzwwQcYOXIkPD09RQcODAxEeXk59Ho96uvrkZqaivDw8GZtqqqqoNFoUF9f3+6+RETUtYkG1O3btwEAt27dQv/+/VFfX48BAwaIDqxQKHD27FnTc4PBAIVCYVFR7ekbFRUFtVoNtVoNNzc3i8YnIiLpEw2oXbt2oWfPnvj4449x4sQJVFRUIDU1VXRgmUzWYpsgCBYV1Z6+ycnJCAgIQEBAAC5fvmzR+EREJH2iX9RdvXo1ACAtLQ27du2Cg4ODRXfYNRgMzQ4Fenh44Pz58xYVdT99iYioazAbUOa+oHuX2Peg1Go1vL29oVQqce7cOURERGD69OkWFXU/fYmIqGswG1CtfUH3Lku+qGs0GhETE4OsrCzY2dlh06ZNKC4uRnR0NAAgKSkJ/fr1g0ajgbOzMxobGxEbGwsfHx/U1ta22peIiGyH2YB6EF/QzczMRGZmZrNtSUlJpp8vXrxo9orA1voSEZHtEL1IwsXFBWvXrkVeXh40Gg0+//xzuLi4dERtRERkw0QDKjU1FVVVVZg0aRImT56MqqoqbN26tSNqIyIiG2bRDGr16tWoqKhARUUF/va3v6FXr14dUBoREdky0YDKycnB1KlTIZPJTEsd7d69uyNqIyIiGyYaUNHR0diyZQvq6upQV1eH1NRUvPvuu7h+/Tpqamo6okYiIrJBol/UdXZ27og6iIiImhGdQf3+cnO5XI7ly5dbrSAiIiLAgoB6+eWXsXv3bri7u+OZZ57BsWPH0KNHj46ojYiIbJjoIb4ZM2ZgypQpKCwsxK1btzBt2jQcPXq0I2ojIiIbJjqDevLJJ/HOO+9gx44dqKiowMyZM+Ho6NgRtRERkQ0TDaiMjAwsW7YM8+bNQ0hICMrKyqBWqzuiNiIismGih/gCAwNRW1trev7pp59CpVJZtSgiIiKzM6ilS5cCAGprazF58uRmr82ePdu6VRERkc0zG1ARERGmn997771mr40fP956FREREaGNgPrtbdd/fwv21m7JTkRE9CCZDShBEFr9ubXnRERED5rZiyR8fX1RU1MDmUwGR0dH07p7MpkMDg4OHVYgERHZJrMBZW8veoEfERGR1Yh+D4qIiKgzMKCIiEiSGFBERCRJPNEkAePmz7W4bXbCRitWQkQkHZxBERGRJDGgiIhIkhhQREQkSQwoIiKSJAYUERFJEq/ie4i15+o/gFcAEtHDhTMoIiKSJAYUERFJklUDKjQ0FKWlpSgrK0NcXFyrbdauXYuysjLodDoMGzbMtF2v16OgoABarRZqtdqaZRIRkQRZ7RyUXC5HfHw8xo4dC4PBALVaDZVKhZKSElObsLAweHt7w9vbG0FBQUhISMCIESNMr48ePRpXrlyxVolERCRhVptBBQYGory8HHq9HvX19UhNTUV4eHizNuHh4di8eTMA4Pjx4+jVqxfc3d2tVRIRET1ErBZQCoUCZ8+eNT03GAxQKBQWtxEEAdnZ2dBoNIiKijL7e6KioqBWq6FWq+Hm5vaA3wUREXUWqx3ik8lkLbb9/lbxbbUJDg5GZWUl+vTpg3379qG0tBSHDh1q0T45ORnJyckAwHNVRERdiNVmUAaDAZ6enqbnHh4eOH/+vMVtKisrAQBVVVVIT09HYGCgtUolIiIJslpAqdVqeHt7Q6lUolu3boiIiIBKpWrWRqVSYdasWQCAoKAg1NTU4MKFC+jevTucnJwAAN27d8e4ceNQVFRkrVKJiEiCrHaIz2g0IiYmBllZWbCzs8OmTZtQXFyM6OhoAEBSUhL27NmDCRMmoLy8HLdu3cLs2bMBAP369UN6enpTgfb22LJlC7KysqxVKhERSZBVlzrKzMxEZmZms21JSUnNnsfExLTop9fr8dxzz1mzNJvHZZKISOq4Fh+1C4ONiDoKlzoiIiJJ4gyKOgxnX0TUHgwoeii0J9wYbERdAwOKujTO2ogeXgwoIjMYbkSdixdJEBGRJDGgiIhIkniIj8gKeFEH0f3jDIqIiCSJAUVERJLEQ3xEEsIrB4n+gzMoIiKSJAYUERFJEg/xEXURPDxIXQ1nUEREJEmcQRERv7dFksQZFBERSRIDioiIJIkBRUREksRzUER0z3jlIFkTZ1BERCRJDCgiIpIkBhQREUkSA4qIiCSJF0kQUae41y8H88IM28EZFBERSRJnUERkMzj7erhwBkVERJLEGRQRkQW4oG7H4wyKiIgkyaozqNDQUKxduxZ2dnbYsGED1qxZ06LN2rVrMWHCBNy6dQtvvfUWtFqtxX2JiKSO573undUCSi6XIz4+HmPHjoXBYIBarYZKpUJJSYmpTVhYGLy9veHt7Y2goCAkJCRgxIgRFvUlIurqbD3crBZQgYGBKC8vh16vBwCkpqYiPDy8WciEh4dj8+bNAIDjx4+jV69ecHd3h1KpFO1LRETmdYXvmckACNYYeNKkSRg/fjyioqIAAG+++SaCgoKwcOFCU5uMjAx8+OGHOHLkCABg//79iIuLg1KpFO17V1RUFN5++20AwODBg3Hy5MkH/l7c3Nxw+fLlBz5uV8J9JI77yDLcT+K62j7y8vJC3759W2y32gxKJpO12CYIgkVtLOl7V3JyMpKTk++xSsuo1WoEBARY9Xc87LiPxHEfWYb7SZyt7COrBZTBYICnp6fpuYeHB86fP29Rm0ceeUS0LxERdW1Wu8xcrVbD29sbSqUS3bp1Q0REBFQqVbM2KpUKs2bNAgAEBQWhpqYGFy5csKgvERF1fYK1HmFhYcLJkyeF8vJy4b//+78FAEJ0dLQQHR1tavPPf/5TKC8vFwoKCgQ/P782+3bWIyoqqlN//8Pw4D7iPuJ+4j560A+rXSRBRER0P7iSBBERSRIDioiIJIkBJSI0NBSlpaUoKytDXFxcZ5cjSXq9HgUFBdBqtVCr1Z1djiRs3LgRFy9eRGFhoWlb7969kZ2djVOnTiE7Oxu9evXqvAIloLV9tGLFChgMBmi1Wmi1WoSFhXVihZ3Pw8MDBw4cQHFxMYqKirBo0SIAtvW31OknwqT6kMvlQnl5uTBgwAChW7duQn5+vvD00093el1Se+j1esHV1bXT65DS44UXXhCGDRsmFBYWmratWbNGiIuLEwAIcXFxwocfftjpdUptH61YsUJYvHhxp9cmlYe7u7swbNgwAYDg5OQknDx5Unj66adt5m+JM6g2/Ha5pvr6etOSS0RiDh06hKtXrzbbFh4ejq+//hoA8PXXX+P111/vhMqko7V9RM1duHDBtID2jRs3UFJSAoVCYTN/SwyoNigUCpw9e9b03GAwQKFQdGJF0iQIArKzs6HRaEzLU1FL/fr1w4ULFwA0ffC0trQLATExMdDpdNi4cWOXPnTVXl5eXhg2bBiOHz9uM39LDKg2tGfJJVsWHBwMPz8/hIWFYcGCBXjhhRc6uyR6SCUkJGDQoEF47rnnUFlZiX/84x+dXZIkPPbYY9ixYwdiY2NRW1vb2eV0GAZUGyxZromAyspKAEBVVRXS09MRGBjYyRVJ08WLF+Hu7g4AcHd3x6VLlzq5Ium5dOkSGhsbIQgCkpOT+bcEwN7eHjt27MB3332H9PR0ALbzt8SAagOXXBLXvXt3ODk5mX4eN24cioqKOrkqaVKpVIiMjAQAREZGYufOnZ1ckfTc/dAFgDfeeIN/S2i62rGkpASfffaZaZst/S11+pUaUn5IacklKT4GDBgg5OfnC/n5+UJRURH30f9/bNmyRTh//rzwf//3f8LZs2eFOXPmCC4uLsL+/fuFU6dOCfv37xd69+7d6XVKbR9t3rxZKCgoEHQ6nbBz507B3d290+vszEdwcLAgCIKg0+kErVYraLVaISwszGb+lrjUERERSRIP8RERkSQxoIiISJIYUEREJEkMKCIikiQGFBERSRIDirqchoYGaLVaFBYW4ocffoCjo2Or7Y4cOXJP4/v5+WHt2rX3XJ+trATwzjvvmN33RJbgZebU5dTW1qJHjx4AgG+//RZ5eXnNvuQol8vR2NjYWeU1q68r0+v18Pf3x5UrVzq7FHpIcQZFXdqhQ4fw5JNPIiQkBAcOHMB3331nuv/Q3ZlMSEgIcnJysG3bNpSUlODbb7819ff398eRI0eQn5+P48ePw8nJCSEhIcjIyADQdP+izZs348cff8SpU6fwX//1XwCa1k7bv38/8vLyUFBQgNdee0201pkzZ0Kn0yE/Px+bN28GADzxxBPYv38/dDod9u/fb1p6KyUlBV9++SUOHDiAf//733jxxRexceNGFBcXIyUlxTRmbW0tPvnkE+Tl5WH//v1wc3MDAPj6+uLnn3+GTqdDWlqaaVHWnJwcfPjhhzh+/DhOnjyJUaNGAWgK9Y8++gi5ubnQ6XR4++2329x3CxcuxOOPP46cnBwcOHAAcrkcKSkpKCwsREFBAWJjY9v/j0k2qdO/LcwHHw/yUVtbKwAQ7OzshH/961/CvHnzhJCQEOHGjRuCUqls0S4kJESorq4WFAqFIJPJhKNHjwrBwcFCt27dhH//+9+Cv7+/AEDo0aOHYGdnJ4SEhAgZGRkC0HT/ovz8fMHBwUFwdXUVzpw5I/Tv31+ws7MTevToIQAQXF1dhbKysha/97cPHx8fobS01HRfrbsrA6hUKmHWrFkCAGH27NlCenq6AEBISUkRvv/+ewGA8Nprrwk1NTXCM888I8hkMkGj0Qi+vr4CAEEQBGH69OkCAGHZsmXCunXrBACCTqcTXnzxRQGAsGrVKuGzzz4TAAg5OTnCJ598IgBNq6js27dPACBERUUJf/nLXwQAwiOPPCKo1WpBqVSa3XdA8/uEDR8+XMjOzja93549e3b63wkf0n9wBkVdjqOjI7RaLTQaDc6cOYONGzcCAHJzc1FRUdFqn9zcXJw7dw6CICA/Px9KpRKDBw9GZWUlNBoNgKbZiNFobNF3586duHPnDq5cuYKcnBwEBgZCJpPhf/7nf0wzH4VCgX79+pmtecyYMdi+fbvpcNi1a9cAACNHjsSWLVsAAN98841pRgPANIsrLCzExYsXUVRUBEEQ8Msvv0CpVAIAjEYjtm7dCqDpcOeoUaPg7OyMXr164eDBgwCa7if04osvmsZNS0sDAOTl5ZnGGTduHGbNmgWtVovjx4/D1dUV3t7eZvfd7/36668YOHAgvvjiC4SGhuL69etm9wXRXfadXQDRg3b79m0MGzasxfabN2+a7VNXV2f62Wg0wt7eHjKZzKLbq/y+jSAImDFjBvr06QM/Pz80NDRAr9fDwcHB7Bj38rvu1tzY2Nis/sbGRtjbt/6ftiW/4+5Yd/fD3foWLlyI7OzsZm1DQkJa3Xe/V11dDV9fX4SGhmLBggWYMmUK5s6dK1oL2TbOoIjMKC0txeOPPw5/f38AgJOTE+zs7Fq0Cw8Px6OPPgoXFxe89NJLUKvV6NmzJy5duoSGhga89NJLrc4qfuvHH3/ElClT4OLiAgDo3bs3AODo0aOIiIgAAMyYMQOHDx9u13uws7PD5MmTAQDTp0/H4cOHcf36dVy7ds00G5s5cyZ++umnNsfJysrC/PnzTeHj7e2N7t27t9nntxeDuLq6Qi6XIy0tDcuWLcPw4cPb9T7INnEGRWRGfX09pk6dinXr1sHR0RG3b9/GK6+80qJdbm4udu/ejSeeeAJ//etfUVlZie+++w4ZGRlQq9XIz89HSUlJm7+ruLgYf/vb3/DTTz/BaDRCq9Vi9uzZWLRoETZt2oSlS5eiqqoKs2fPbtd7uHHjBoYMGQKNRoOamhpMnToVQNMtGhITE9G9e3f8+uuvouNu2LABSqUSJ06cgEwmQ1VVlehtxtevX4/MzExUVlYiNjYWKSkpkMub/p/4vffea9f7INvEy8yJ7sOKFStw48YNyd751VYuaaeuiYf4iIhIkjiDIiIiSeIMioiIJIkBRUREksSAIiIiSWJAERGRJDGgiIhIkv4fiikLDRo+x6AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)\n",
    "with plt.style.context('dark_background'):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(range(len(explained_variance)), explained_variance, alpha=0.5, align='center',label='individual explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14d4158d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio of  5  Components:\n",
      "[0.28498137 0.17725126 0.06637927 0.05874814 0.04443741]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88      7690\n",
      "           1       0.70      0.14      0.23      2210\n",
      "\n",
      "    accuracy                           0.79      9900\n",
      "   macro avg       0.75      0.56      0.56      9900\n",
      "weighted avg       0.78      0.79      0.74      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.47474747474747\n",
      "\n",
      " Precision of event Happening: \n",
      " 70.41284403669725\n",
      "\n",
      " Recall of event Happening: \n",
      " 13.891402714932127\n",
      "\n",
      " AUC: \n",
      " 0.5610694973197842\n",
      "\n",
      " F-Score:\n",
      " 0.2320483749055178\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7561  129]\n",
      " [1903  307]]\n",
      "SVM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88      7690\n",
      "           1       0.66      0.23      0.34      2210\n",
      "\n",
      "    accuracy                           0.80      9900\n",
      "   macro avg       0.74      0.60      0.61      9900\n",
      "weighted avg       0.78      0.80      0.76      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.17171717171718\n",
      "\n",
      " Precision of event Happening: \n",
      " 66.01815823605706\n",
      "\n",
      " Recall of event Happening: \n",
      " 23.031674208144796\n",
      "\n",
      " AUC: \n",
      " 0.598123260507564\n",
      "\n",
      " F-Score:\n",
      " 0.3414961422341496\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7428  262]\n",
      " [1701  509]]\n",
      "RM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88      7690\n",
      "           1       0.60      0.30      0.40      2210\n",
      "\n",
      "    accuracy                           0.80      9900\n",
      "   macro avg       0.71      0.62      0.64      9900\n",
      "weighted avg       0.77      0.80      0.77      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.9090909090909\n",
      "\n",
      " Precision of event Happening: \n",
      " 59.94599459945995\n",
      "\n",
      " Recall of event Happening: \n",
      " 30.13574660633484\n",
      "\n",
      " AUC: \n",
      " 0.621745052927643\n",
      "\n",
      " F-Score:\n",
      " 0.40108401084010836\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7245  445]\n",
      " [1544  666]]\n",
      "Xgboost From PCA\n",
      "[12:33:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      7690\n",
      "           1       0.63      0.28      0.38      2210\n",
      "\n",
      "    accuracy                           0.80      9900\n",
      "   macro avg       0.73      0.61      0.63      9900\n",
      "weighted avg       0.78      0.80      0.77      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.25252525252526\n",
      "\n",
      " Precision of event Happening: \n",
      " 63.212435233160626\n",
      "\n",
      " Recall of event Happening: \n",
      " 27.601809954751133\n",
      "\n",
      " AUC: \n",
      " 0.6149271251963824\n",
      "\n",
      " F-Score:\n",
      " 0.38425196850393706\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7335  355]\n",
      " [1600  610]]\n",
      "Explained Variance Ratio of  10  Components:\n",
      "[0.28498137 0.17725127 0.0663793  0.05874819 0.04443755 0.04287519\n",
      " 0.04042738 0.0396448  0.03819943 0.03683116]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88      7690\n",
      "           1       0.70      0.16      0.26      2210\n",
      "\n",
      "    accuracy                           0.80      9900\n",
      "   macro avg       0.75      0.57      0.57      9900\n",
      "weighted avg       0.78      0.80      0.74      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.7070707070707\n",
      "\n",
      " Precision of event Happening: \n",
      " 70.14028056112225\n",
      "\n",
      " Recall of event Happening: \n",
      " 15.837104072398189\n",
      "\n",
      " AUC: \n",
      " 0.5694976139900793\n",
      "\n",
      " F-Score:\n",
      " 0.25839793281653745\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7541  149]\n",
      " [1860  350]]\n",
      "SVM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88      7690\n",
      "           1       0.66      0.25      0.36      2210\n",
      "\n",
      "    accuracy                           0.80      9900\n",
      "   macro avg       0.74      0.61      0.62      9900\n",
      "weighted avg       0.78      0.80      0.77      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.32323232323232\n",
      "\n",
      " Precision of event Happening: \n",
      " 65.52132701421802\n",
      "\n",
      " Recall of event Happening: \n",
      " 25.02262443438914\n",
      "\n",
      " AUC: \n",
      " 0.6061924459690848\n",
      "\n",
      " F-Score:\n",
      " 0.36214800261951535\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7399  291]\n",
      " [1657  553]]\n",
      "RM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      7690\n",
      "           1       0.62      0.30      0.40      2210\n",
      "\n",
      "    accuracy                           0.80      9900\n",
      "   macro avg       0.72      0.62      0.64      9900\n",
      "weighted avg       0.78      0.80      0.77      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.16161616161617\n",
      "\n",
      " Precision of event Happening: \n",
      " 61.56015037593985\n",
      "\n",
      " Recall of event Happening: \n",
      " 29.638009049773757\n",
      "\n",
      " AUC: \n",
      " 0.6215970673555008\n",
      "\n",
      " F-Score:\n",
      " 0.4001221747098351\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7281  409]\n",
      " [1555  655]]\n",
      "Xgboost From PCA\n",
      "[12:34:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      7690\n",
      "           1       0.64      0.28      0.39      2210\n",
      "\n",
      "    accuracy                           0.80      9900\n",
      "   macro avg       0.73      0.62      0.64      9900\n",
      "weighted avg       0.78      0.80      0.77      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.36363636363636\n",
      "\n",
      " Precision of event Happening: \n",
      " 63.57142857142857\n",
      "\n",
      " Recall of event Happening: \n",
      " 28.190045248868778\n",
      "\n",
      " AUC: \n",
      " 0.6177382626552671\n",
      "\n",
      " F-Score:\n",
      " 0.3905956112852665\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7333  357]\n",
      " [1587  623]]\n",
      "Explained Variance Ratio of  15  Components:\n",
      "[0.28498137 0.17725127 0.0663793  0.05874819 0.04443755 0.04287519\n",
      " 0.04042738 0.0396448  0.03819943 0.03683116 0.03326009 0.02919461\n",
      " 0.02486697 0.02271439 0.01759449]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.89      7690\n",
      "           1       0.71      0.22      0.34      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.76      0.60      0.61      9900\n",
      "weighted avg       0.79      0.81      0.76      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.62626262626263\n",
      "\n",
      " Precision of event Happening: \n",
      " 71.15942028985506\n",
      "\n",
      " Recall of event Happening: \n",
      " 22.217194570135746\n",
      "\n",
      " AUC: \n",
      " 0.5981470911861794\n",
      "\n",
      " F-Score:\n",
      " 0.3386206896551724\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7491  199]\n",
      " [1719  491]]\n",
      "SVM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      7690\n",
      "           1       0.65      0.34      0.45      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.74      0.64      0.67      9900\n",
      "weighted avg       0.79      0.81      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.2020202020202\n",
      "\n",
      " Precision of event Happening: \n",
      " 64.97854077253218\n",
      "\n",
      " Recall of event Happening: \n",
      " 34.25339366515837\n",
      "\n",
      " AUC: \n",
      " 0.6447390099382757\n",
      "\n",
      " F-Score:\n",
      " 0.4485925925925926\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7282  408]\n",
      " [1453  757]]\n",
      "RM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      7690\n",
      "           1       0.65      0.34      0.44      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.74      0.64      0.67      9900\n",
      "weighted avg       0.79      0.81      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.2020202020202\n",
      "\n",
      " Precision of event Happening: \n",
      " 65.26684164479441\n",
      "\n",
      " Recall of event Happening: \n",
      " 33.755656108597286\n",
      "\n",
      " AUC: \n",
      " 0.6429655367198395\n",
      "\n",
      " F-Score:\n",
      " 0.4449746495675515\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7293  397]\n",
      " [1464  746]]\n",
      "Xgboost From PCA\n",
      "[12:36:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      7690\n",
      "           1       0.67      0.34      0.45      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.75      0.65      0.67      9900\n",
      "weighted avg       0.80      0.82      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.55555555555556\n",
      "\n",
      " Precision of event Happening: \n",
      " 67.23518850987432\n",
      "\n",
      " Recall of event Happening: \n",
      " 33.89140271493213\n",
      "\n",
      " AUC: \n",
      " 0.6457248939387699\n",
      "\n",
      " F-Score:\n",
      " 0.45066185318892904\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7325  365]\n",
      " [1461  749]]\n",
      "Explained Variance Ratio of  20  Components:\n",
      "[0.28498137 0.17725127 0.0663793  0.05874819 0.04443755 0.04287519\n",
      " 0.04042738 0.0396448  0.03819943 0.03683116 0.03326009 0.02919461\n",
      " 0.02486697 0.02271439 0.01759449 0.01140019 0.01062747 0.0081627\n",
      " 0.00578254 0.00296442]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.89      7690\n",
      "           1       0.72      0.22      0.34      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.77      0.60      0.61      9900\n",
      "weighted avg       0.79      0.81      0.77      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.71717171717172\n",
      "\n",
      " Precision of event Happening: \n",
      " 71.90684133915575\n",
      "\n",
      " Recall of event Happening: \n",
      " 22.35294117647059\n",
      "\n",
      " AUC: \n",
      " 0.5992159412529642\n",
      "\n",
      " F-Score:\n",
      " 0.34104245771487746\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7497  193]\n",
      " [1716  494]]\n",
      "SVM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      7690\n",
      "           1       0.69      0.33      0.45      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.76      0.64      0.67      9900\n",
      "weighted avg       0.80      0.82      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.71717171717172\n",
      "\n",
      " Precision of event Happening: \n",
      " 68.93939393939394\n",
      "\n",
      " Recall of event Happening: \n",
      " 32.94117647058823\n",
      "\n",
      " AUC: \n",
      " 0.6433794844335653\n",
      "\n",
      " F-Score:\n",
      " 0.44580526638089407\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7362  328]\n",
      " [1482  728]]\n",
      "RM From PCA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      7690\n",
      "           1       0.65      0.34      0.45      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.74      0.64      0.67      9900\n",
      "weighted avg       0.79      0.81      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.1919191919192\n",
      "\n",
      " Precision of event Happening: \n",
      " 65.05190311418684\n",
      "\n",
      " Recall of event Happening: \n",
      " 34.02714932126697\n",
      "\n",
      " AUC: \n",
      " 0.6438678662422257\n",
      "\n",
      " F-Score:\n",
      " 0.44682115270350564\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7286  404]\n",
      " [1458  752]]\n",
      "Xgboost From PCA\n",
      "[12:37:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      7690\n",
      "           1       0.66      0.34      0.45      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.75      0.65      0.67      9900\n",
      "weighted avg       0.80      0.81      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.4040404040404\n",
      "\n",
      " Precision of event Happening: \n",
      " 66.14173228346458\n",
      "\n",
      " Recall of event Happening: \n",
      " 34.20814479638009\n",
      "\n",
      " AUC: \n",
      " 0.6458781752172712\n",
      "\n",
      " F-Score:\n",
      " 0.4509394572025053\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7303  387]\n",
      " [1454  756]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def select_features(X_train, X_test,n):\n",
    "    global pca\n",
    "    # configure to select a subset of features\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    pca = PCA(n_components = n)\n",
    "    X_train_fs = pca.fit_transform(X_train)\n",
    "    X_test_fs = pca.transform(X_test)\n",
    "    return X_train_fs, X_test_fs\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(5,25,5):\n",
    "    X_train_fs, X_test_fs = select_features(X_train, X_test,n)\n",
    "    \n",
    "    print (\"Explained Variance Ratio of \",n,\" Components:\")\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    print(explained_variance)\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(range(n), explained_variance, alpha=0.5, align='center',label='individual explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From PCA\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From PCA\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From PCA\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From PCA\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f64b61",
   "metadata": {},
   "source": [
    "Logistic Regression with PCA performs well with 5 components with an accuracy of 84, precision 88, recall 93.\n",
    "SVM with PCA performs well with 10 components with an accuracy of 84, precision 86, recall 95.\n",
    "RF with PCA performs well with 10 components with an accuracy of 86, precision 89, recall 93.\n",
    "Xgboost with PCA performs well with 20 components with an accuracy of 83, precision 88, recall 90.\n",
    "We concluded that PCA is useful in dimensionality reduction of the dataset as Logistic Regression with 5 componenets perform well from all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9276b6ec",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60d6be2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "sc = StandardScaler()\n",
    "y_train = y_train.to_numpy(dtype='int')\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "X_train = lda.fit_transform(X_train,y_train)\n",
    "X_test = lda.transform(X_test)\n",
    "explained_variance = lda.explained_variance_ratio_\n",
    "print(explained_variance)\n",
    "with plt.style.context('dark_background'):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(range(len(X_train)), explained_variance, alpha=0.5, align='center',label='individual explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d89199f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio\n",
      "[0.28498137 0.17725127 0.0663793  0.05874819 0.04443755 0.04287519\n",
      " 0.04042738 0.0396448  0.03819943 0.03683116 0.03326009 0.02919461\n",
      " 0.02486697 0.02271439 0.01759449 0.01140019 0.01062747 0.0081627\n",
      " 0.00578254 0.00296442]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From LDA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.89      7690\n",
      "           1       0.71      0.23      0.34      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.76      0.60      0.62      9900\n",
      "weighted avg       0.79      0.81      0.77      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.7070707070707\n",
      "\n",
      " Precision of event Happening: \n",
      " 71.42857142857143\n",
      "\n",
      " Recall of event Happening: \n",
      " 22.624434389140273\n",
      "\n",
      " AUC: \n",
      " 0.6001182707753503\n",
      "\n",
      " F-Score:\n",
      " 0.3436426116838488\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7490  200]\n",
      " [1710  500]]\n",
      "SVM From LDA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      7690\n",
      "           1       0.67      0.35      0.46      2210\n",
      "\n",
      "    accuracy                           0.82      9900\n",
      "   macro avg       0.75      0.65      0.68      9900\n",
      "weighted avg       0.80      0.82      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.60606060606061\n",
      "\n",
      " Precision of event Happening: \n",
      " 66.55319148936171\n",
      "\n",
      " Recall of event Happening: \n",
      " 35.38461538461539\n",
      "\n",
      " AUC: \n",
      " 0.651370411123337\n",
      "\n",
      " F-Score:\n",
      " 0.46203840472673563\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7297  393]\n",
      " [1428  782]]\n",
      "RM From LDA\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      7690\n",
      "           1       0.36      0.36      0.36      2210\n",
      "\n",
      "    accuracy                           0.71      9900\n",
      "   macro avg       0.59      0.59      0.59      9900\n",
      "weighted avg       0.71      0.71      0.71      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 71.2929292929293\n",
      "\n",
      " Precision of event Happening: \n",
      " 35.66243194192377\n",
      "\n",
      " Recall of event Happening: \n",
      " 35.56561085972851\n",
      "\n",
      " AUC: \n",
      " 0.5856303950008532\n",
      "\n",
      " F-Score:\n",
      " 0.3561395559583144\n",
      "\n",
      " Confusion Matrix: \n",
      " [[6272 1418]\n",
      " [1424  786]]\n",
      "Xgboost From LDA\n",
      "[12:40:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      7690\n",
      "           1       0.65      0.36      0.46      2210\n",
      "\n",
      "    accuracy                           0.81      9900\n",
      "   macro avg       0.74      0.65      0.68      9900\n",
      "weighted avg       0.80      0.81      0.79      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.41414141414141\n",
      "\n",
      " Precision of event Happening: \n",
      " 65.1888341543514\n",
      "\n",
      " Recall of event Happening: \n",
      " 35.92760180995475\n",
      "\n",
      " AUC: \n",
      " 0.6520697385686295\n",
      "\n",
      " F-Score:\n",
      " 0.46324387397899647\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7266  424]\n",
      " [1416  794]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.41414141414141,\n",
       " 'precision': 65.1888341543514,\n",
       " 'recall': 35.92760180995475,\n",
       " 'auc_val': 0.6520697385686295,\n",
       " 'f_score': 0.46324387397899647,\n",
       " 'model_obj': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "               gamma=0, gpu_id=-1, importance_type=None,\n",
       "               interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
       "               max_depth=6, min_child_weight=1, missing=nan,\n",
       "               monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "               num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "               reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "               tree_method='exact', validate_parameters=1, verbosity=None)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_features(X_train, X_test,y_train):\n",
    "    global lda\n",
    "    # configure to select a subset of features\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    y_train = y_train.to_numpy(dtype='int')\n",
    "    lda = LinearDiscriminantAnalysis(solver='svd')\n",
    "    X_train_fs = lda.fit_transform(X_train,y_train)\n",
    "    X_test_fs = lda.transform(X_test)\n",
    "    return X_train_fs, X_test_fs\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "\n",
    "X_train_fs, X_test_fs  = select_features(X_train, X_test,y_train)\n",
    "    \n",
    "print (\"Explained Variance Ratio\")\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(range(len(explained_variance)), explained_variance, alpha=0.5, align='center',label='individual explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "    # fit the model\n",
    "print (\"Logistic Regression From LDA\")\n",
    "LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "print (\"SVM From LDA\")\n",
    "SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "print (\"RM From LDA\")\n",
    "RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "print (\"Xgboost From LDA\")\n",
    "XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd15780",
   "metadata": {},
   "source": [
    "TSNE doesnot perform on less number of components. It doesnot reduce the dimensionality of dataset. Logistic Regression, Xgboost, RF all perform well with 20 components except SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4888cc0",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9b48180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "SVM From TSNE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "RM From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.78      7690\n",
      "           1       0.23      0.23      0.23      2210\n",
      "\n",
      "    accuracy                           0.65      9900\n",
      "   macro avg       0.50      0.50      0.50      9900\n",
      "weighted avg       0.65      0.65      0.65      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 1 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 65.28282828282829\n",
      "\n",
      " Precision of event Happening: \n",
      " 22.550335570469798\n",
      "\n",
      " Recall of event Happening: \n",
      " 22.805429864253394\n",
      "\n",
      " AUC: \n",
      " 0.5014783846918782\n",
      "\n",
      " F-Score:\n",
      " 0.22677165354330708\n",
      "\n",
      " Confusion Matrix: \n",
      " [[5959 1731]\n",
      " [1706  504]]\n",
      "Xgboost From TSNE\n",
      "[12:44:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.83      7690\n",
      "           1       0.24      0.11      0.16      2210\n",
      "\n",
      "    accuracy                           0.72      9900\n",
      "   macro avg       0.51      0.51      0.50      9900\n",
      "weighted avg       0.66      0.72      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 1 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 72.32323232323232\n",
      "\n",
      " Precision of event Happening: \n",
      " 24.42084942084942\n",
      "\n",
      " Recall of event Happening: \n",
      " 11.447963800904978\n",
      "\n",
      " AUC: \n",
      " 0.5063295459226004\n",
      "\n",
      " F-Score:\n",
      " 0.1558841651263093\n",
      "\n",
      " Confusion Matrix: \n",
      " [[6907  783]\n",
      " [1957  253]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.35      0.00      0.01      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.56      0.50      0.44      9900\n",
      "weighted avg       0.68      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.6060606060606\n",
      "\n",
      " Precision of event Happening: \n",
      " 34.78260869565217\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.36199095022624433\n",
      "\n",
      " AUC: \n",
      " 0.5008346621633548\n",
      "\n",
      " F-Score:\n",
      " 0.00716524854455889\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7675   15]\n",
      " [2202    8]]\n",
      "SVM From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84      7690\n",
      "           1       0.26      0.11      0.16      2210\n",
      "\n",
      "    accuracy                           0.73      9900\n",
      "   macro avg       0.52      0.51      0.50      9900\n",
      "weighted avg       0.66      0.73      0.69      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 73.04040404040404\n",
      "\n",
      " Precision of event Happening: \n",
      " 26.11862643080125\n",
      "\n",
      " Recall of event Happening: \n",
      " 11.357466063348417\n",
      "\n",
      " AUC: \n",
      " 0.5106234811619957\n",
      "\n",
      " F-Score:\n",
      " 0.15830968148848945\n",
      "\n",
      " Confusion Matrix: \n",
      " [[6980  710]\n",
      " [1959  251]]\n",
      "RM From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      7690\n",
      "           1       0.30      0.22      0.25      2210\n",
      "\n",
      "    accuracy                           0.71      9900\n",
      "   macro avg       0.54      0.53      0.54      9900\n",
      "weighted avg       0.68      0.71      0.69      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 70.79797979797979\n",
      "\n",
      " Precision of event Happening: \n",
      " 29.52495490078172\n",
      "\n",
      " Recall of event Happening: \n",
      " 22.217194570135746\n",
      "\n",
      " AUC: \n",
      " 0.5348831119924213\n",
      "\n",
      " F-Score:\n",
      " 0.25355021946811257\n",
      "\n",
      " Confusion Matrix: \n",
      " [[6518 1172]\n",
      " [1719  491]]\n",
      "Xgboost From TSNE\n",
      "[12:49:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83      7690\n",
      "           1       0.31      0.20      0.24      2210\n",
      "\n",
      "    accuracy                           0.72      9900\n",
      "   macro avg       0.55      0.54      0.54      9900\n",
      "weighted avg       0.68      0.72      0.70      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 71.86868686868686\n",
      "\n",
      " Precision of event Happening: \n",
      " 30.508474576271187\n",
      "\n",
      " Recall of event Happening: \n",
      " 20.361990950226243\n",
      "\n",
      " AUC: \n",
      " 0.5351649612530818\n",
      "\n",
      " F-Score:\n",
      " 0.24423337856173677\n",
      "\n",
      " Confusion Matrix: \n",
      " [[6665 1025]\n",
      " [1760  450]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.00      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.78      9900\n",
      "   macro avg       0.39      0.50      0.44      9900\n",
      "weighted avg       0.60      0.78      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67676767676768\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7690    0]\n",
      " [2210    0]]\n",
      "SVM From TSNE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      7690\n",
      "           1       0.14      0.00      0.00      2210\n",
      "\n",
      "    accuracy                           0.77      9900\n",
      "   macro avg       0.46      0.50      0.44      9900\n",
      "weighted avg       0.63      0.77      0.68      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.40404040404042\n",
      "\n",
      " Precision of event Happening: \n",
      " 13.513513513513514\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.22624434389140274\n",
      "\n",
      " AUC: \n",
      " 0.4990505975322008\n",
      "\n",
      " F-Score:\n",
      " 0.004450378282153984\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7658   32]\n",
      " [2205    5]]\n",
      "RM From TSNE\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85      7690\n",
      "           1       0.17      0.04      0.06      2210\n",
      "\n",
      "    accuracy                           0.74      9900\n",
      "   macro avg       0.47      0.49      0.46      9900\n",
      "weighted avg       0.64      0.74      0.67      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 74.19191919191918\n",
      "\n",
      " Precision of event Happening: \n",
      " 16.50485436893204\n",
      "\n",
      " Recall of event Happening: \n",
      " 3.8461538461538463\n",
      "\n",
      " AUC: \n",
      " 0.4912723817145144\n",
      "\n",
      " F-Score:\n",
      " 0.062385321100917435\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7260  430]\n",
      " [2125   85]]\n",
      "Xgboost From TSNE\n",
      "[13:02:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85      7690\n",
      "           1       0.16      0.03      0.05      2210\n",
      "\n",
      "    accuracy                           0.75      9900\n",
      "   macro avg       0.46      0.49      0.45      9900\n",
      "weighted avg       0.64      0.75      0.67      9900\n",
      "\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 74.58585858585859\n",
      "\n",
      " Precision of event Happening: \n",
      " 15.54054054054054\n",
      "\n",
      " Recall of event Happening: \n",
      " 3.1221719457013575\n",
      "\n",
      " AUC: \n",
      " 0.4912285450340984\n",
      "\n",
      " F-Score:\n",
      " 0.05199698568198945\n",
      "\n",
      " Confusion Matrix: \n",
      " [[7315  375]\n",
      " [2141   69]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "def select_features(X_train, X_test,n):\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    tsne = TSNE(n_components = n)\n",
    "    X_train_fs = tsne.fit_transform(X_train)\n",
    "    X_test_fs = tsne.fit_transform(X_test)\n",
    "    return X_train_fs, X_test_fs\n",
    " \n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "for n in range(1,4):\n",
    "    X_train_fs, X_test_fs  = select_features(X_train, X_test,n)\n",
    "    # fit the model\n",
    "    print (\"Logistic Regression From TSNE\")\n",
    "    LogReg(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"SVM From TSNE\")\n",
    "    SVM(X_train_fs, X_test_fs, y_train, y_test, svmtype=\"SVC\", verbose=True, clf=None)\n",
    "    print (\"RM From TSNE\")\n",
    "    RandomForest(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n",
    "    print (\"Xgboost From TSNE\")\n",
    "    XgBoost(X_train_fs, X_test_fs, y_train, y_test, verbose=True, clf=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6cc63f",
   "metadata": {},
   "source": [
    "Logistic Regression with TSNE performs well with 1 component with an accuracy of 79, precision 79, recall 100.\n",
    "SVM with TSNE performs well with 1 component with an accuracy of 79, precision 79, recall 100.\n",
    "RF with TSNE performs well with 3 components with an accuracy of 70, precision 80.3, recall 82.8.\n",
    "Xgboost with TSNE performs well with 3 components with an accuracy of 71, precision 82, recall 81.\n",
    "We concluded that TSNE is useful in dimensionality reduction of the dataset as Logistic Regression with 1 componenet perform well from all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b5e2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
